{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d50b642-80b3-4349-bf73-fd940660cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644aa4a-11f6-4dad-9946-4c21734f3a1c",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9367f706-ef31-4220-9f79-74947e8dba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_headlines(total_number, df):\n",
    "    n_reviews = df.sample(total_number)\n",
    "    for val in list(n_reviews.index):\n",
    "        print(\"News #{}\".format(val))\n",
    "        print(\" - Sentiment: {}\".format(df.iloc[val][\"Sentiment\"]))\n",
    "        print(\" - Headline: {}\".format(df.iloc[val][\"Title\"]))\n",
    "        print(\"\")\n",
    "        \n",
    "\n",
    "def show_headline_distribution(sequence_lengths, figsize=(15, 8)):\n",
    "    len_512_plus = [rev_len for rev_len in sequence_lengths if rev_len > 512]\n",
    "    percent = (len(len_512_plus) / len(sequence_lengths)) * 100\n",
    "    print(\"Max sequence length {}\".format(max(sequence_lengths)))\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.set(font_scale=1.3)\n",
    "    sns.displot(sequence_lengths, kde=False, rug=False)\n",
    "    plt.title('Distribution of lengths of headlines')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Number')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_random_headlines(total_number, df):\n",
    "    n_reviews = df.sample(total_number)\n",
    "    for val in list(n_reviews.index):\n",
    "        print(\"News #{}\".format(val))\n",
    "        print(\" - Sentiment: {}\".format(df.iloc[val][\"Sentiment\"]))\n",
    "        print(\" - Headlines: {}\".format(df.iloc[val][\"Title\"]))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "def get_headlines_len(df):\n",
    "    headlines_sequence_lengths = []\n",
    "    for headline in tqdm(df.Title):\n",
    "        encoded_headline = finbert_tokenizer.encode(headline, add_special_tokens=True)\n",
    "        headlines_sequence_lengths.append(len(encoded_headline))\n",
    "    print(\"Done\")\n",
    " \n",
    "    return headlines_sequence_lengths\n",
    "\n",
    "\n",
    "def encode_sentiments_values(df):\n",
    "    possible_sentiments = df.Sentiment.unique()\n",
    "    sentiment_dict = {}   \n",
    "    for index, possible_sentiment in enumerate(possible_sentiments):\n",
    "        sentiment_dict[possible_sentiment] = index  \n",
    "    df['label'] = df.Sentiment.replace(sentiment_dict)   \n",
    "    return df, sentiment_dict\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    " \n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in sentiment_dict.items()}\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    pred_nb = 0\n",
    "    true_nb = 0\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Label: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "        pred_nb += len(y_preds[y_preds==label])\n",
    "        true_nb += len(y_true)\n",
    "    print('accuracy: ', pred_nb/true_nb)\n",
    "\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)           \n",
    " \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)    \n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50689c34-1899-468c-9a8d-3f3dedae6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "df_pre = pd.read_csv('sentiment_gpt4_only.csv')\n",
    "replacements = {'- positive': 'positive', '- negative': 'negative', '- indecisive': 'indecisive'}\n",
    "df = df_pre.replace(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77ae294-1b33-4bc2-afbb-d1d92249cf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 0, 'negative': 1, 'indecisive': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode sentiments\n",
    "df_encoded, sentiment_dict = encode_sentiments_values(df)\n",
    "sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601a3689-bd6f-4500-8e5b-dbff71b6af58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">indecisive</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>test</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>553</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">negative</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>test</th>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>3468</td>\n",
       "      <td>3468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">positive</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>test</th>\n",
       "      <td>511</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>2897</td>\n",
       "      <td>2897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date  Title\n",
       "Sentiment  label data_type             \n",
       "indecisive 2     test         98     98\n",
       "                 train       553    553\n",
       "negative   1     test        612    612\n",
       "                 train      3468   3468\n",
       "positive   0     test        511    511\n",
       "                 train      2897   2897"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate train dataset and test dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_encoded.index.values,\n",
    "                                                  df_encoded.label.values,\n",
    "                                                  test_size = 0.15,\n",
    "                                                  random_state = 2022,\n",
    "                                                  stratify = df_encoded.label.values)\n",
    "# X_train is a list of the index of elements for training\n",
    "# Y_train is a list of the labels of elements for training\n",
    "\n",
    "#verify if the distribution of train dataset and test dataser is reasonable\n",
    "df_encoded['data_type'] = pd.Series(dtype='object')\n",
    "df_encoded.loc[X_train, 'data_type'] = 'train'\n",
    "df_encoded.loc[X_test, 'data_type'] = 'test'\n",
    "df_encoded.groupby(['Sentiment', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e57ab27-1977-4ad1-a91a-9018b12e7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\",  do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88411b63-bf7a-4159-9a64-718ff2fb146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8139/8139 [00:01<00:00, 4377.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Max sequence length 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headlines_sequence_lengths = get_headlines_len(df_encoded)\n",
    "show_headline_distribution(headlines_sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd00337-47a8-4585-911d-d761a5428597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparation for model train\n",
    "encoded_data_train = finbert_tokenizer.batch_encode_plus(\n",
    "    df_encoded[df_encoded.data_type=='train'].Title.values, \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length',\n",
    "    max_length=38, \n",
    "    truncation=True \n",
    ")\n",
    "\n",
    "encoded_data_test = finbert_tokenizer.batch_encode_plus(\n",
    "    df_encoded[df_encoded.data_type=='test'].Title.values, \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length',\n",
    "    max_length=38, \n",
    "    truncation=True \n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df_encoded[df_encoded.data_type=='train'].label.values)\n",
    " \n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "sentiments_test = torch.tensor(df_encoded[df_encoded.data_type=='test'].label.values)\n",
    " \n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, sentiments_test)\n",
    " \n",
    "len(sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce72299-8441-41b7-a6e0-acecdfb1b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-training model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\",\n",
    " \n",
    "                                                          num_labels=len(sentiment_dict),\n",
    " \n",
    "                                                          output_attentions=False,\n",
    " \n",
    "                                                          output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ffe4b5-b491-4f2e-94ee-282dcd5758f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "batch_size = 5\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    " \n",
    "dataloader_validation = DataLoader(dataset_test,\n",
    "                                   sampler=SequentialSampler(dataset_test),\n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb8ffcd-1c72-4a48-9aa9-9b38a24c628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer and the learning rate scheduler, and specify the total number of training epochs\n",
    "epochs = 2\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "total_steps = len(dataloader_train) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66402022-77f7-481b-815c-8d90a6b0f13c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                         | 0/1384 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|                    | 0/1384 [00:02<?, ?it/s, training_loss=0.592]\u001b[A\n",
      "Epoch 1:   0%|            | 1/1384 [00:02<46:17,  2.01s/it, training_loss=0.592]\u001b[A\n",
      "Epoch 1:   0%|            | 1/1384 [00:03<46:17,  2.01s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:   0%|            | 2/1384 [00:03<32:58,  1.43s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:   0%|            | 2/1384 [00:04<32:58,  1.43s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   0%|            | 3/1384 [00:04<28:36,  1.24s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   0%|            | 3/1384 [00:05<28:36,  1.24s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:   0%|            | 4/1384 [00:05<26:34,  1.16s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:   0%|            | 4/1384 [00:06<26:34,  1.16s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   0%|            | 5/1384 [00:06<26:08,  1.14s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   0%|            | 5/1384 [00:07<26:08,  1.14s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:   0%|            | 6/1384 [00:07<26:52,  1.17s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:   0%|            | 6/1384 [00:08<26:52,  1.17s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   1%|            | 7/1384 [00:08<26:59,  1.18s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   1%|            | 7/1384 [00:09<26:59,  1.18s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:   1%|            | 8/1384 [00:09<26:47,  1.17s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:   1%|            | 8/1384 [00:10<26:47,  1.17s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   1%|            | 9/1384 [00:10<26:11,  1.14s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   1%|            | 9/1384 [00:11<26:11,  1.14s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:   1%|           | 10/1384 [00:11<25:47,  1.13s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:   1%|           | 10/1384 [00:13<25:47,  1.13s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:   1%|           | 11/1384 [00:13<25:40,  1.12s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:   1%|           | 11/1384 [00:14<25:40,  1.12s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:   1%|           | 12/1384 [00:14<24:51,  1.09s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:   1%|           | 12/1384 [00:15<24:51,  1.09s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:   1%|           | 13/1384 [00:15<24:48,  1.09s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:   1%|           | 13/1384 [00:16<24:48,  1.09s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:   1%|           | 14/1384 [00:16<24:23,  1.07s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:   1%|           | 14/1384 [00:17<24:23,  1.07s/it, training_loss=0.644]\u001b[A\n",
      "Epoch 1:   1%|           | 15/1384 [00:17<24:54,  1.09s/it, training_loss=0.644]\u001b[A\n",
      "Epoch 1:   1%|           | 15/1384 [00:18<24:54,  1.09s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:   1%|▏          | 16/1384 [00:18<24:55,  1.09s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:   1%|▏          | 16/1384 [00:19<24:55,  1.09s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:   1%|▏          | 17/1384 [00:19<25:14,  1.11s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:   1%|▏          | 17/1384 [00:20<25:14,  1.11s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 1:   1%|▏          | 18/1384 [00:20<25:11,  1.11s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 1:   1%|▏          | 18/1384 [00:21<25:11,  1.11s/it, training_loss=0.508]\u001b[A\n",
      "Epoch 1:   1%|▏          | 19/1384 [00:21<24:29,  1.08s/it, training_loss=0.508]\u001b[A\n",
      "Epoch 1:   1%|▏          | 19/1384 [00:22<24:29,  1.08s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:   1%|▏          | 20/1384 [00:22<24:46,  1.09s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:   1%|▏          | 20/1384 [00:23<24:46,  1.09s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:   2%|▏          | 21/1384 [00:23<25:30,  1.12s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:   2%|▏          | 21/1384 [00:25<25:30,  1.12s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:   2%|▏          | 22/1384 [00:25<26:16,  1.16s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:   2%|▏          | 22/1384 [00:26<26:16,  1.16s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:   2%|▏          | 23/1384 [00:26<26:49,  1.18s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:   2%|▏          | 23/1384 [00:27<26:49,  1.18s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   2%|▏          | 24/1384 [00:27<26:17,  1.16s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   2%|▏          | 24/1384 [00:28<26:17,  1.16s/it, training_loss=0.388]\u001b[A\n",
      "Epoch 1:   2%|▏          | 25/1384 [00:28<25:29,  1.13s/it, training_loss=0.388]\u001b[A\n",
      "Epoch 1:   2%|▏          | 25/1384 [00:29<25:29,  1.13s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:   2%|▏          | 26/1384 [00:29<24:46,  1.09s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:   2%|▏          | 26/1384 [00:30<24:46,  1.09s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   2%|▏          | 27/1384 [00:30<25:10,  1.11s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   2%|▏          | 27/1384 [00:31<25:10,  1.11s/it, training_loss=0.504]\u001b[A\n",
      "Epoch 1:   2%|▏          | 28/1384 [00:31<25:07,  1.11s/it, training_loss=0.504]\u001b[A\n",
      "Epoch 1:   2%|▏          | 28/1384 [00:32<25:07,  1.11s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:   2%|▏          | 29/1384 [00:32<24:38,  1.09s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:   2%|▏          | 29/1384 [00:33<24:38,  1.09s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:   2%|▏          | 30/1384 [00:33<24:04,  1.07s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:   2%|▏          | 30/1384 [00:34<24:04,  1.07s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:   2%|▏          | 31/1384 [00:34<23:47,  1.06s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:   2%|▏          | 31/1384 [00:36<23:47,  1.06s/it, training_loss=0.194]\u001b[A\n",
      "Epoch 1:   2%|▎          | 32/1384 [00:36<24:00,  1.07s/it, training_loss=0.194]\u001b[A\n",
      "Epoch 1:   2%|▎          | 32/1384 [00:37<24:00,  1.07s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:   2%|▎          | 33/1384 [00:37<24:15,  1.08s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:   2%|▎          | 33/1384 [00:38<24:15,  1.08s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 1:   2%|▎          | 34/1384 [00:38<25:19,  1.13s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 1:   2%|▎          | 34/1384 [00:39<25:19,  1.13s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:   3%|▎          | 35/1384 [00:39<25:50,  1.15s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:   3%|▎          | 35/1384 [00:40<25:50,  1.15s/it, training_loss=0.556]\u001b[A\n",
      "Epoch 1:   3%|▎          | 36/1384 [00:40<25:15,  1.12s/it, training_loss=0.556]\u001b[A\n",
      "Epoch 1:   3%|▎          | 36/1384 [00:41<25:15,  1.12s/it, training_loss=0.496]\u001b[A\n",
      "Epoch 1:   3%|▎          | 37/1384 [00:41<25:45,  1.15s/it, training_loss=0.496]\u001b[A\n",
      "Epoch 1:   3%|▎          | 37/1384 [00:43<25:45,  1.15s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:   3%|▎          | 38/1384 [00:43<26:24,  1.18s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:   3%|▎          | 38/1384 [00:44<26:24,  1.18s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:   3%|▎          | 39/1384 [00:44<26:04,  1.16s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:   3%|▎          | 39/1384 [00:45<26:04,  1.16s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:   3%|▎          | 40/1384 [00:45<25:39,  1.15s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:   3%|▎          | 40/1384 [00:46<25:39,  1.15s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:   3%|▎          | 41/1384 [00:46<26:27,  1.18s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:   3%|▎          | 41/1384 [00:47<26:27,  1.18s/it, training_loss=0.452]\u001b[A\n",
      "Epoch 1:   3%|▎          | 42/1384 [00:47<26:34,  1.19s/it, training_loss=0.452]\u001b[A\n",
      "Epoch 1:   3%|▎          | 42/1384 [00:48<26:34,  1.19s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   3%|▎          | 43/1384 [00:48<26:14,  1.17s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   3%|▎          | 43/1384 [00:50<26:14,  1.17s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:   3%|▎          | 44/1384 [00:50<25:16,  1.13s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:   3%|▎          | 44/1384 [00:51<25:16,  1.13s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:   3%|▎          | 45/1384 [00:51<24:57,  1.12s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:   3%|▎          | 45/1384 [00:52<24:57,  1.12s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:   3%|▎          | 46/1384 [00:52<24:56,  1.12s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:   3%|▎          | 46/1384 [00:53<24:56,  1.12s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:   3%|▎          | 47/1384 [00:53<25:43,  1.15s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:   3%|▎          | 47/1384 [00:54<25:43,  1.15s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:   3%|▍          | 48/1384 [00:54<25:22,  1.14s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:   3%|▍          | 48/1384 [00:55<25:22,  1.14s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:   4%|▍          | 49/1384 [00:55<25:07,  1.13s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:   4%|▍          | 49/1384 [00:56<25:07,  1.13s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:   4%|▍          | 50/1384 [00:56<25:17,  1.14s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:   4%|▍          | 50/1384 [00:57<25:17,  1.14s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:   4%|▍          | 51/1384 [00:57<25:07,  1.13s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:   4%|▍          | 51/1384 [00:58<25:07,  1.13s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:   4%|▍          | 52/1384 [00:58<24:39,  1.11s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:   4%|▍          | 52/1384 [01:00<24:39,  1.11s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:   4%|▍          | 53/1384 [01:00<24:29,  1.10s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:   4%|▍          | 53/1384 [01:01<24:29,  1.10s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:   4%|▍          | 54/1384 [01:01<25:05,  1.13s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:   4%|▍          | 54/1384 [01:02<25:05,  1.13s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:   4%|▍          | 55/1384 [01:02<25:47,  1.16s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:   4%|▍          | 55/1384 [01:03<25:47,  1.16s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   4%|▍          | 56/1384 [01:03<26:22,  1.19s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   4%|▍          | 56/1384 [01:04<26:22,  1.19s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:   4%|▍          | 57/1384 [01:04<25:59,  1.18s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:   4%|▍          | 57/1384 [01:06<25:59,  1.18s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:   4%|▍          | 58/1384 [01:06<25:37,  1.16s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:   4%|▍          | 58/1384 [01:07<25:37,  1.16s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:   4%|▍          | 59/1384 [01:07<26:20,  1.19s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:   4%|▍          | 59/1384 [01:08<26:20,  1.19s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   4%|▍          | 60/1384 [01:08<26:01,  1.18s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   4%|▍          | 60/1384 [01:09<26:01,  1.18s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:   4%|▍          | 61/1384 [01:09<25:55,  1.18s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:   4%|▍          | 61/1384 [01:10<25:55,  1.18s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:   4%|▍          | 62/1384 [01:10<27:11,  1.23s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:   4%|▍          | 62/1384 [01:12<27:11,  1.23s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:   5%|▌          | 63/1384 [01:12<27:47,  1.26s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:   5%|▌          | 63/1384 [01:13<27:47,  1.26s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:   5%|▌          | 64/1384 [01:13<29:51,  1.36s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:   5%|▌          | 64/1384 [01:15<29:51,  1.36s/it, training_loss=0.486]\u001b[A\n",
      "Epoch 1:   5%|▌          | 65/1384 [01:15<30:21,  1.38s/it, training_loss=0.486]\u001b[A\n",
      "Epoch 1:   5%|▌          | 65/1384 [01:16<30:21,  1.38s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:   5%|▌          | 66/1384 [01:16<29:46,  1.36s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:   5%|▌          | 66/1384 [01:17<29:46,  1.36s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:   5%|▌          | 67/1384 [01:17<28:06,  1.28s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:   5%|▌          | 67/1384 [01:19<28:06,  1.28s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:   5%|▌          | 68/1384 [01:19<28:19,  1.29s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:   5%|▌          | 68/1384 [01:20<28:19,  1.29s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:   5%|▌          | 69/1384 [01:20<28:21,  1.29s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:   5%|▌          | 69/1384 [01:21<28:21,  1.29s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   5%|▌          | 70/1384 [01:21<27:36,  1.26s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   5%|▌          | 70/1384 [01:22<27:36,  1.26s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:   5%|▌          | 71/1384 [01:22<27:33,  1.26s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:   5%|▌          | 71/1384 [01:23<27:33,  1.26s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:   5%|▌          | 72/1384 [01:23<26:59,  1.23s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:   5%|▌          | 72/1384 [01:25<26:59,  1.23s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:   5%|▌          | 73/1384 [01:25<27:18,  1.25s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:   5%|▌          | 73/1384 [01:26<27:18,  1.25s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:   5%|▌          | 74/1384 [01:26<26:52,  1.23s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:   5%|▌          | 74/1384 [01:27<26:52,  1.23s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   5%|▌          | 75/1384 [01:27<26:18,  1.21s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   5%|▌          | 75/1384 [01:28<26:18,  1.21s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:   5%|▌          | 76/1384 [01:28<26:17,  1.21s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:   5%|▌          | 76/1384 [01:30<26:17,  1.21s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:   6%|▌          | 77/1384 [01:30<26:30,  1.22s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:   6%|▌          | 77/1384 [01:31<26:30,  1.22s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:   6%|▌          | 78/1384 [01:31<26:11,  1.20s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:   6%|▌          | 78/1384 [01:32<26:11,  1.20s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:   6%|▋          | 79/1384 [01:32<25:53,  1.19s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:   6%|▋          | 79/1384 [01:33<25:53,  1.19s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   6%|▋          | 80/1384 [01:33<26:34,  1.22s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   6%|▋          | 80/1384 [01:34<26:34,  1.22s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:   6%|▋          | 81/1384 [01:34<26:45,  1.23s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:   6%|▋          | 81/1384 [01:36<26:45,  1.23s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:   6%|▋          | 82/1384 [01:36<26:48,  1.24s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:   6%|▋          | 82/1384 [01:37<26:48,  1.24s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 1:   6%|▋          | 83/1384 [01:37<26:20,  1.21s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 1:   6%|▋          | 83/1384 [01:38<26:20,  1.21s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:   6%|▋          | 84/1384 [01:38<26:08,  1.21s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:   6%|▋          | 84/1384 [01:39<26:08,  1.21s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:   6%|▋          | 85/1384 [01:39<26:18,  1.22s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:   6%|▋          | 85/1384 [01:40<26:18,  1.22s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:   6%|▋          | 86/1384 [01:40<26:16,  1.21s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:   6%|▋          | 86/1384 [01:42<26:16,  1.21s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:   6%|▋          | 87/1384 [01:42<25:59,  1.20s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:   6%|▋          | 87/1384 [01:43<25:59,  1.20s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:   6%|▋          | 88/1384 [01:43<25:47,  1.19s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:   6%|▋          | 88/1384 [01:44<25:47,  1.19s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 1:   6%|▋          | 89/1384 [01:44<25:42,  1.19s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 1:   6%|▋          | 89/1384 [01:45<25:42,  1.19s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:   7%|▋          | 90/1384 [01:45<25:52,  1.20s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:   7%|▋          | 90/1384 [01:46<25:52,  1.20s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   7%|▋          | 91/1384 [01:46<26:06,  1.21s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:   7%|▋          | 91/1384 [01:48<26:06,  1.21s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:   7%|▋          | 92/1384 [01:48<26:43,  1.24s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:   7%|▋          | 92/1384 [01:49<26:43,  1.24s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:   7%|▋          | 93/1384 [01:49<27:58,  1.30s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:   7%|▋          | 93/1384 [01:51<27:58,  1.30s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:   7%|▋          | 94/1384 [01:51<29:10,  1.36s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:   7%|▋          | 94/1384 [01:52<29:10,  1.36s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:   7%|▊          | 95/1384 [01:52<29:01,  1.35s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:   7%|▊          | 95/1384 [01:53<29:01,  1.35s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   7%|▊          | 96/1384 [01:53<28:14,  1.32s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:   7%|▊          | 96/1384 [01:55<28:14,  1.32s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:   7%|▊          | 97/1384 [01:55<27:39,  1.29s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:   7%|▊          | 97/1384 [01:56<27:39,  1.29s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:   7%|▊          | 98/1384 [01:56<27:28,  1.28s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:   7%|▊          | 98/1384 [01:57<27:28,  1.28s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   7%|▊          | 99/1384 [01:57<27:39,  1.29s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   7%|▊          | 99/1384 [01:59<27:39,  1.29s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:   7%|▋         | 100/1384 [01:59<28:29,  1.33s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:   7%|▋         | 100/1384 [02:00<28:29,  1.33s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:   7%|▋         | 101/1384 [02:00<28:23,  1.33s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:   7%|▋         | 101/1384 [02:01<28:23,  1.33s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:   7%|▋         | 102/1384 [02:01<28:49,  1.35s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:   7%|▋         | 102/1384 [02:02<28:49,  1.35s/it, training_loss=0.526]\u001b[A\n",
      "Epoch 1:   7%|▋         | 103/1384 [02:02<27:59,  1.31s/it, training_loss=0.526]\u001b[A\n",
      "Epoch 1:   7%|▋         | 103/1384 [02:04<27:59,  1.31s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:   8%|▊         | 104/1384 [02:04<27:25,  1.29s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:   8%|▊         | 104/1384 [02:05<27:25,  1.29s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:   8%|▊         | 105/1384 [02:05<27:07,  1.27s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:   8%|▊         | 105/1384 [02:06<27:07,  1.27s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:   8%|▊         | 106/1384 [02:06<26:55,  1.26s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:   8%|▊         | 106/1384 [02:07<26:55,  1.26s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:   8%|▊         | 107/1384 [02:07<26:40,  1.25s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:   8%|▊         | 107/1384 [02:09<26:40,  1.25s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   8%|▊         | 108/1384 [02:09<26:38,  1.25s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   8%|▊         | 108/1384 [02:10<26:38,  1.25s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:   8%|▊         | 109/1384 [02:10<26:52,  1.26s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:   8%|▊         | 109/1384 [02:11<26:52,  1.26s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:   8%|▊         | 110/1384 [02:11<26:17,  1.24s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:   8%|▊         | 110/1384 [02:12<26:17,  1.24s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:   8%|▊         | 111/1384 [02:12<25:49,  1.22s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:   8%|▊         | 111/1384 [02:13<25:49,  1.22s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:   8%|▊         | 112/1384 [02:13<25:29,  1.20s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:   8%|▊         | 112/1384 [02:15<25:29,  1.20s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:   8%|▊         | 113/1384 [02:15<24:49,  1.17s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:   8%|▊         | 113/1384 [02:16<24:49,  1.17s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:   8%|▊         | 114/1384 [02:16<24:45,  1.17s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:   8%|▊         | 114/1384 [02:17<24:45,  1.17s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:   8%|▊         | 115/1384 [02:17<24:44,  1.17s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:   8%|▊         | 115/1384 [02:18<24:44,  1.17s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:   8%|▊         | 116/1384 [02:18<24:26,  1.16s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:   8%|▊         | 116/1384 [02:19<24:26,  1.16s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:   8%|▊         | 117/1384 [02:19<24:12,  1.15s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:   8%|▊         | 117/1384 [02:20<24:12,  1.15s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:   9%|▊         | 118/1384 [02:20<24:21,  1.15s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:   9%|▊         | 118/1384 [02:21<24:21,  1.15s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:   9%|▊         | 119/1384 [02:21<24:35,  1.17s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:   9%|▊         | 119/1384 [02:23<24:35,  1.17s/it, training_loss=0.450]\u001b[A\n",
      "Epoch 1:   9%|▊         | 120/1384 [02:23<24:54,  1.18s/it, training_loss=0.450]\u001b[A\n",
      "Epoch 1:   9%|▊         | 120/1384 [02:24<24:54,  1.18s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:   9%|▊         | 121/1384 [02:24<25:30,  1.21s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:   9%|▊         | 121/1384 [02:25<25:30,  1.21s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:   9%|▉         | 122/1384 [02:25<24:44,  1.18s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:   9%|▉         | 122/1384 [02:26<24:44,  1.18s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:   9%|▉         | 123/1384 [02:26<24:06,  1.15s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:   9%|▉         | 123/1384 [02:27<24:06,  1.15s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   9%|▉         | 124/1384 [02:27<23:33,  1.12s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   9%|▉         | 124/1384 [02:28<23:33,  1.12s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:   9%|▉         | 125/1384 [02:28<23:11,  1.11s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:   9%|▉         | 125/1384 [02:29<23:11,  1.11s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 1:   9%|▉         | 126/1384 [02:29<23:00,  1.10s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 1:   9%|▉         | 126/1384 [02:30<23:00,  1.10s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:   9%|▉         | 127/1384 [02:30<22:47,  1.09s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:   9%|▉         | 127/1384 [02:32<22:47,  1.09s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   9%|▉         | 128/1384 [02:32<22:41,  1.08s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   9%|▉         | 128/1384 [02:33<22:41,  1.08s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:   9%|▉         | 129/1384 [02:33<22:33,  1.08s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:   9%|▉         | 129/1384 [02:34<22:33,  1.08s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 1:   9%|▉         | 130/1384 [02:34<22:33,  1.08s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 1:   9%|▉         | 130/1384 [02:35<22:33,  1.08s/it, training_loss=0.492]\u001b[A\n",
      "Epoch 1:   9%|▉         | 131/1384 [02:35<22:25,  1.07s/it, training_loss=0.492]\u001b[A\n",
      "Epoch 1:   9%|▉         | 131/1384 [02:36<22:25,  1.07s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  10%|▉         | 132/1384 [02:36<23:22,  1.12s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  10%|▉         | 132/1384 [02:37<23:22,  1.12s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  10%|▉         | 133/1384 [02:37<24:01,  1.15s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  10%|▉         | 133/1384 [02:39<24:01,  1.15s/it, training_loss=0.560]\u001b[A\n",
      "Epoch 1:  10%|▉         | 134/1384 [02:39<25:25,  1.22s/it, training_loss=0.560]\u001b[A\n",
      "Epoch 1:  10%|▉         | 134/1384 [02:40<25:25,  1.22s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  10%|▉         | 135/1384 [02:40<26:36,  1.28s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  10%|▉         | 135/1384 [02:41<26:36,  1.28s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  10%|▉         | 136/1384 [02:41<27:26,  1.32s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  10%|▉         | 136/1384 [02:43<27:26,  1.32s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  10%|▉         | 137/1384 [02:43<26:30,  1.28s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  10%|▉         | 137/1384 [02:44<26:30,  1.28s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  10%|▉         | 138/1384 [02:44<25:16,  1.22s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  10%|▉         | 138/1384 [02:45<25:16,  1.22s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  10%|█         | 139/1384 [02:45<24:25,  1.18s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  10%|█         | 139/1384 [02:46<24:25,  1.18s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  10%|█         | 140/1384 [02:46<23:47,  1.15s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  10%|█         | 140/1384 [02:47<23:47,  1.15s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  10%|█         | 141/1384 [02:47<23:24,  1.13s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  10%|█         | 141/1384 [02:48<23:24,  1.13s/it, training_loss=0.396]\u001b[A\n",
      "Epoch 1:  10%|█         | 142/1384 [02:48<23:31,  1.14s/it, training_loss=0.396]\u001b[A\n",
      "Epoch 1:  10%|█         | 142/1384 [02:49<23:31,  1.14s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  10%|█         | 143/1384 [02:49<23:11,  1.12s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  10%|█         | 143/1384 [02:51<23:11,  1.12s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  10%|█         | 144/1384 [02:51<25:16,  1.22s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  10%|█         | 144/1384 [02:52<25:16,  1.22s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  10%|█         | 145/1384 [02:52<26:30,  1.28s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  10%|█         | 145/1384 [02:53<26:30,  1.28s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  11%|█         | 146/1384 [02:53<25:38,  1.24s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  11%|█         | 146/1384 [02:54<25:38,  1.24s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  11%|█         | 147/1384 [02:54<24:36,  1.19s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  11%|█         | 147/1384 [02:55<24:36,  1.19s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  11%|█         | 148/1384 [02:55<23:58,  1.16s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  11%|█         | 148/1384 [02:56<23:58,  1.16s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  11%|█         | 149/1384 [02:56<23:27,  1.14s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  11%|█         | 149/1384 [02:58<23:27,  1.14s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  11%|█         | 150/1384 [02:58<23:52,  1.16s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  11%|█         | 150/1384 [02:59<23:52,  1.16s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  11%|█         | 151/1384 [02:59<24:30,  1.19s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  11%|█         | 151/1384 [03:00<24:30,  1.19s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  11%|█         | 152/1384 [03:00<24:04,  1.17s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  11%|█         | 152/1384 [03:01<24:04,  1.17s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  11%|█         | 153/1384 [03:01<23:20,  1.14s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  11%|█         | 153/1384 [03:02<23:20,  1.14s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  11%|█         | 154/1384 [03:02<23:03,  1.12s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  11%|█         | 154/1384 [03:04<23:03,  1.12s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  11%|█         | 155/1384 [03:04<24:24,  1.19s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  11%|█         | 155/1384 [03:05<24:24,  1.19s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 156/1384 [03:05<23:47,  1.16s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 156/1384 [03:06<23:47,  1.16s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 157/1384 [03:06<23:09,  1.13s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 157/1384 [03:07<23:09,  1.13s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 158/1384 [03:07<22:52,  1.12s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 158/1384 [03:08<22:52,  1.12s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 159/1384 [03:08<22:37,  1.11s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 159/1384 [03:09<22:37,  1.11s/it, training_loss=0.436]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 160/1384 [03:09<22:29,  1.10s/it, training_loss=0.436]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 160/1384 [03:10<22:29,  1.10s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 161/1384 [03:10<22:15,  1.09s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 161/1384 [03:11<22:15,  1.09s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 162/1384 [03:11<22:03,  1.08s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 162/1384 [03:12<22:03,  1.08s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 163/1384 [03:12<22:05,  1.09s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 163/1384 [03:13<22:05,  1.09s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 164/1384 [03:13<21:59,  1.08s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 164/1384 [03:14<21:59,  1.08s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 165/1384 [03:14<21:51,  1.08s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 165/1384 [03:15<21:51,  1.08s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 166/1384 [03:15<21:46,  1.07s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 166/1384 [03:16<21:46,  1.07s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 167/1384 [03:16<21:48,  1.08s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 167/1384 [03:18<21:48,  1.08s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 168/1384 [03:18<22:05,  1.09s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 168/1384 [03:19<22:05,  1.09s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 169/1384 [03:19<22:03,  1.09s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 169/1384 [03:20<22:03,  1.09s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 170/1384 [03:20<21:54,  1.08s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 170/1384 [03:21<21:54,  1.08s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 171/1384 [03:21<22:04,  1.09s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 171/1384 [03:22<22:04,  1.09s/it, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 172/1384 [03:22<22:02,  1.09s/it, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 172/1384 [03:23<22:02,  1.09s/it, training_loss=0.444]\u001b[A\n",
      "Epoch 1:  12%|█▎        | 173/1384 [03:23<21:59,  1.09s/it, training_loss=0.444]\u001b[A\n",
      "Epoch 1:  12%|█▎        | 173/1384 [03:24<21:59,  1.09s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 174/1384 [03:24<21:48,  1.08s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 174/1384 [03:25<21:48,  1.08s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 175/1384 [03:25<21:55,  1.09s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 175/1384 [03:26<21:55,  1.09s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 176/1384 [03:26<21:47,  1.08s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 176/1384 [03:27<21:47,  1.08s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 177/1384 [03:27<21:51,  1.09s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 177/1384 [03:28<21:51,  1.09s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 178/1384 [03:28<21:49,  1.09s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 178/1384 [03:30<21:49,  1.09s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 179/1384 [03:30<22:08,  1.10s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 179/1384 [03:31<22:08,  1.10s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 180/1384 [03:31<22:00,  1.10s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 180/1384 [03:32<22:00,  1.10s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 181/1384 [03:32<21:52,  1.09s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 181/1384 [03:33<21:52,  1.09s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 182/1384 [03:33<21:50,  1.09s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 182/1384 [03:34<21:50,  1.09s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 183/1384 [03:34<21:42,  1.08s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 183/1384 [03:35<21:42,  1.08s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 184/1384 [03:35<21:34,  1.08s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 184/1384 [03:36<21:34,  1.08s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 185/1384 [03:36<21:29,  1.08s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 185/1384 [03:37<21:29,  1.08s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 186/1384 [03:37<21:33,  1.08s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 186/1384 [03:38<21:33,  1.08s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 187/1384 [03:38<21:35,  1.08s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 187/1384 [03:39<21:35,  1.08s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 188/1384 [03:39<21:25,  1.07s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 188/1384 [03:40<21:25,  1.07s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 189/1384 [03:40<21:31,  1.08s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 189/1384 [03:41<21:31,  1.08s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 190/1384 [03:41<21:30,  1.08s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 190/1384 [03:43<21:30,  1.08s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 191/1384 [03:43<21:40,  1.09s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 191/1384 [03:44<21:40,  1.09s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 192/1384 [03:44<21:34,  1.09s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 192/1384 [03:45<21:34,  1.09s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 193/1384 [03:45<21:27,  1.08s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 193/1384 [03:46<21:27,  1.08s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 194/1384 [03:46<21:22,  1.08s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 194/1384 [03:47<21:22,  1.08s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 195/1384 [03:47<21:16,  1.07s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 195/1384 [03:48<21:16,  1.07s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 196/1384 [03:48<21:27,  1.08s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 196/1384 [03:49<21:27,  1.08s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 197/1384 [03:49<21:31,  1.09s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 197/1384 [03:50<21:31,  1.09s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 198/1384 [03:50<21:23,  1.08s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 198/1384 [03:51<21:23,  1.08s/it, training_loss=0.493]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 199/1384 [03:51<21:19,  1.08s/it, training_loss=0.493]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 199/1384 [03:52<21:19,  1.08s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 200/1384 [03:52<21:25,  1.09s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 200/1384 [03:53<21:25,  1.09s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 201/1384 [03:53<21:24,  1.09s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 201/1384 [03:54<21:24,  1.09s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 202/1384 [03:54<21:38,  1.10s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 202/1384 [03:56<21:38,  1.10s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 203/1384 [03:56<23:45,  1.21s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 203/1384 [03:57<23:45,  1.21s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 204/1384 [03:57<24:32,  1.25s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 204/1384 [03:59<24:32,  1.25s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 205/1384 [03:59<25:31,  1.30s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 205/1384 [04:00<25:31,  1.30s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 206/1384 [04:00<25:42,  1.31s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 206/1384 [04:01<25:42,  1.31s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 207/1384 [04:01<25:32,  1.30s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 207/1384 [04:02<25:32,  1.30s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 208/1384 [04:02<24:18,  1.24s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 208/1384 [04:04<24:18,  1.24s/it, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 209/1384 [04:04<23:27,  1.20s/it, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 209/1384 [04:05<23:27,  1.20s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 210/1384 [04:05<22:56,  1.17s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 210/1384 [04:06<22:56,  1.17s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 211/1384 [04:06<22:26,  1.15s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 211/1384 [04:07<22:26,  1.15s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 212/1384 [04:07<22:07,  1.13s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 212/1384 [04:08<22:07,  1.13s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 213/1384 [04:08<21:55,  1.12s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 213/1384 [04:09<21:55,  1.12s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 214/1384 [04:09<21:44,  1.11s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 214/1384 [04:10<21:44,  1.11s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 215/1384 [04:10<21:34,  1.11s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 215/1384 [04:11<21:34,  1.11s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 216/1384 [04:11<21:28,  1.10s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 216/1384 [04:12<21:28,  1.10s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 217/1384 [04:12<21:20,  1.10s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 217/1384 [04:13<21:20,  1.10s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 218/1384 [04:13<21:20,  1.10s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 218/1384 [04:14<21:20,  1.10s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 219/1384 [04:14<21:15,  1.09s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 219/1384 [04:16<21:15,  1.09s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 220/1384 [04:16<21:12,  1.09s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 220/1384 [04:17<21:12,  1.09s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 221/1384 [04:17<22:00,  1.14s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 221/1384 [04:18<22:00,  1.14s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 222/1384 [04:18<22:16,  1.15s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 222/1384 [04:19<22:16,  1.15s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 223/1384 [04:19<22:13,  1.15s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 223/1384 [04:20<22:13,  1.15s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 224/1384 [04:20<22:02,  1.14s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 224/1384 [04:21<22:02,  1.14s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 225/1384 [04:21<21:45,  1.13s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 225/1384 [04:22<21:45,  1.13s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 226/1384 [04:22<21:36,  1.12s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 226/1384 [04:24<21:36,  1.12s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 227/1384 [04:24<21:23,  1.11s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 227/1384 [04:25<21:23,  1.11s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 228/1384 [04:25<21:14,  1.10s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 228/1384 [04:26<21:14,  1.10s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 229/1384 [04:26<21:03,  1.09s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 229/1384 [04:27<21:03,  1.09s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 230/1384 [04:27<21:02,  1.09s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 230/1384 [04:28<21:02,  1.09s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 231/1384 [04:28<21:05,  1.10s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 231/1384 [04:29<21:05,  1.10s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 232/1384 [04:29<21:14,  1.11s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 232/1384 [04:30<21:14,  1.11s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 233/1384 [04:30<21:07,  1.10s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 233/1384 [04:31<21:07,  1.10s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 234/1384 [04:31<20:58,  1.09s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 234/1384 [04:32<20:58,  1.09s/it, training_loss=0.497]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 235/1384 [04:32<21:23,  1.12s/it, training_loss=0.497]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 235/1384 [04:33<21:23,  1.12s/it, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 236/1384 [04:33<21:14,  1.11s/it, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 236/1384 [04:35<21:14,  1.11s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 237/1384 [04:35<21:10,  1.11s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 237/1384 [04:36<21:10,  1.11s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 238/1384 [04:36<20:57,  1.10s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 238/1384 [04:37<20:57,  1.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 239/1384 [04:37<20:56,  1.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 239/1384 [04:38<20:56,  1.10s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 240/1384 [04:38<20:56,  1.10s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 240/1384 [04:39<20:56,  1.10s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 241/1384 [04:39<20:59,  1.10s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 241/1384 [04:40<20:59,  1.10s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 242/1384 [04:40<21:03,  1.11s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 242/1384 [04:41<21:03,  1.11s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 243/1384 [04:41<20:55,  1.10s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 243/1384 [04:42<20:55,  1.10s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 244/1384 [04:42<20:44,  1.09s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 244/1384 [04:43<20:44,  1.09s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 245/1384 [04:43<20:54,  1.10s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 245/1384 [04:44<20:54,  1.10s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 246/1384 [04:44<21:05,  1.11s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 246/1384 [04:46<21:05,  1.11s/it, training_loss=0.418]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 247/1384 [04:46<21:06,  1.11s/it, training_loss=0.418]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 247/1384 [04:47<21:06,  1.11s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 248/1384 [04:47<21:10,  1.12s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 248/1384 [04:48<21:10,  1.12s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 249/1384 [04:48<21:21,  1.13s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 249/1384 [04:49<21:21,  1.13s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 250/1384 [04:49<21:14,  1.12s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 250/1384 [04:50<21:14,  1.12s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 251/1384 [04:50<21:07,  1.12s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 251/1384 [04:51<21:07,  1.12s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 252/1384 [04:51<20:55,  1.11s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 252/1384 [04:52<20:55,  1.11s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 253/1384 [04:52<20:44,  1.10s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 253/1384 [04:53<20:44,  1.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 254/1384 [04:53<20:46,  1.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 254/1384 [04:54<20:46,  1.10s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 255/1384 [04:54<20:39,  1.10s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 255/1384 [04:56<20:39,  1.10s/it, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 256/1384 [04:56<20:41,  1.10s/it, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 256/1384 [04:57<20:41,  1.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 257/1384 [04:57<20:34,  1.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 257/1384 [04:58<20:34,  1.10s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 258/1384 [04:58<20:32,  1.09s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 258/1384 [04:59<20:32,  1.09s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 259/1384 [04:59<20:32,  1.10s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 259/1384 [05:00<20:32,  1.10s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 260/1384 [05:00<20:32,  1.10s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 260/1384 [05:01<20:32,  1.10s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 261/1384 [05:01<20:28,  1.09s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 261/1384 [05:02<20:28,  1.09s/it, training_loss=0.850]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 262/1384 [05:02<20:20,  1.09s/it, training_loss=0.850]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 262/1384 [05:03<20:20,  1.09s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 263/1384 [05:03<20:28,  1.10s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 263/1384 [05:04<20:28,  1.10s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 264/1384 [05:04<20:36,  1.10s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 264/1384 [05:05<20:36,  1.10s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 265/1384 [05:05<20:32,  1.10s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 265/1384 [05:07<20:32,  1.10s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 266/1384 [05:07<20:27,  1.10s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 266/1384 [05:08<20:27,  1.10s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 267/1384 [05:08<20:26,  1.10s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 267/1384 [05:09<20:26,  1.10s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 268/1384 [05:09<20:21,  1.09s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 268/1384 [05:10<20:21,  1.09s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 269/1384 [05:10<20:21,  1.10s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 269/1384 [05:11<20:21,  1.10s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 270/1384 [05:11<20:25,  1.10s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 270/1384 [05:12<20:25,  1.10s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 271/1384 [05:12<21:00,  1.13s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 271/1384 [05:13<21:00,  1.13s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 272/1384 [05:13<21:07,  1.14s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 272/1384 [05:14<21:07,  1.14s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 273/1384 [05:14<20:52,  1.13s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 273/1384 [05:16<20:52,  1.13s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 274/1384 [05:16<22:00,  1.19s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 274/1384 [05:17<22:00,  1.19s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 275/1384 [05:17<23:09,  1.25s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 275/1384 [05:19<23:09,  1.25s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 276/1384 [05:19<24:31,  1.33s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 276/1384 [05:20<24:31,  1.33s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  20%|██        | 277/1384 [05:20<24:38,  1.34s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  20%|██        | 277/1384 [05:21<24:38,  1.34s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  20%|██        | 278/1384 [05:21<23:27,  1.27s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  20%|██        | 278/1384 [05:22<23:27,  1.27s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  20%|██        | 279/1384 [05:22<22:26,  1.22s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  20%|██        | 279/1384 [05:23<22:26,  1.22s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  20%|██        | 280/1384 [05:23<22:00,  1.20s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  20%|██        | 280/1384 [05:25<22:00,  1.20s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  20%|██        | 281/1384 [05:25<24:01,  1.31s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  20%|██        | 281/1384 [05:26<24:01,  1.31s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  20%|██        | 282/1384 [05:26<24:28,  1.33s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  20%|██        | 282/1384 [05:28<24:28,  1.33s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  20%|██        | 283/1384 [05:28<24:24,  1.33s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  20%|██        | 283/1384 [05:29<24:24,  1.33s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  21%|██        | 284/1384 [05:29<24:14,  1.32s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  21%|██        | 284/1384 [05:30<24:14,  1.32s/it, training_loss=0.515]\u001b[A\n",
      "Epoch 1:  21%|██        | 285/1384 [05:30<24:10,  1.32s/it, training_loss=0.515]\u001b[A\n",
      "Epoch 1:  21%|██        | 285/1384 [05:31<24:10,  1.32s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  21%|██        | 286/1384 [05:31<23:21,  1.28s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  21%|██        | 286/1384 [05:33<23:21,  1.28s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  21%|██        | 287/1384 [05:33<22:32,  1.23s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  21%|██        | 287/1384 [05:34<22:32,  1.23s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  21%|██        | 288/1384 [05:34<22:01,  1.21s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  21%|██        | 288/1384 [05:35<22:01,  1.21s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  21%|██        | 289/1384 [05:35<21:26,  1.17s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  21%|██        | 289/1384 [05:36<21:26,  1.17s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  21%|██        | 290/1384 [05:36<20:54,  1.15s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  21%|██        | 290/1384 [05:37<20:54,  1.15s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  21%|██        | 291/1384 [05:37<21:13,  1.17s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  21%|██        | 291/1384 [05:38<21:13,  1.17s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  21%|██        | 292/1384 [05:38<20:53,  1.15s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  21%|██        | 292/1384 [05:39<20:53,  1.15s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  21%|██        | 293/1384 [05:39<20:31,  1.13s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  21%|██        | 293/1384 [05:40<20:31,  1.13s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  21%|██        | 294/1384 [05:40<20:21,  1.12s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  21%|██        | 294/1384 [05:41<20:21,  1.12s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 295/1384 [05:41<20:07,  1.11s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 295/1384 [05:43<20:07,  1.11s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 296/1384 [05:43<19:59,  1.10s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 296/1384 [05:44<19:59,  1.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 297/1384 [05:44<20:19,  1.12s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 297/1384 [05:45<20:19,  1.12s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 298/1384 [05:45<20:37,  1.14s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 298/1384 [05:46<20:37,  1.14s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 299/1384 [05:46<20:27,  1.13s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 299/1384 [05:47<20:27,  1.13s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 300/1384 [05:47<20:36,  1.14s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 300/1384 [05:48<20:36,  1.14s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 301/1384 [05:48<20:26,  1.13s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 301/1384 [05:49<20:26,  1.13s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 302/1384 [05:49<20:06,  1.11s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 302/1384 [05:50<20:06,  1.11s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 303/1384 [05:50<19:47,  1.10s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 303/1384 [05:51<19:47,  1.10s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 304/1384 [05:51<19:31,  1.09s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 304/1384 [05:52<19:31,  1.09s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 305/1384 [05:52<19:16,  1.07s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 305/1384 [05:54<19:16,  1.07s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 306/1384 [05:54<19:09,  1.07s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 306/1384 [05:55<19:09,  1.07s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 307/1384 [05:55<19:02,  1.06s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 307/1384 [05:56<19:02,  1.06s/it, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 308/1384 [05:56<19:10,  1.07s/it, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 308/1384 [05:57<19:10,  1.07s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 309/1384 [05:57<20:55,  1.17s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 309/1384 [05:58<20:55,  1.17s/it, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 310/1384 [05:58<21:00,  1.17s/it, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 310/1384 [06:00<21:00,  1.17s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 311/1384 [06:00<21:56,  1.23s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 311/1384 [06:01<21:56,  1.23s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 312/1384 [06:01<22:28,  1.26s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 312/1384 [06:02<22:28,  1.26s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 313/1384 [06:02<22:53,  1.28s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 313/1384 [06:04<22:53,  1.28s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 314/1384 [06:04<22:48,  1.28s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 314/1384 [06:05<22:48,  1.28s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 315/1384 [06:05<23:14,  1.30s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 315/1384 [06:06<23:14,  1.30s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 316/1384 [06:06<23:06,  1.30s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 316/1384 [06:07<23:06,  1.30s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 317/1384 [06:07<21:59,  1.24s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 317/1384 [06:08<21:59,  1.24s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 318/1384 [06:08<21:11,  1.19s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 318/1384 [06:09<21:11,  1.19s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 319/1384 [06:09<20:35,  1.16s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 319/1384 [06:11<20:35,  1.16s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 320/1384 [06:11<20:20,  1.15s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 320/1384 [06:12<20:20,  1.15s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 321/1384 [06:12<20:05,  1.13s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 321/1384 [06:13<20:05,  1.13s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 322/1384 [06:13<19:47,  1.12s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 322/1384 [06:14<19:47,  1.12s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 323/1384 [06:14<19:57,  1.13s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 323/1384 [06:15<19:57,  1.13s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 324/1384 [06:15<20:21,  1.15s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 324/1384 [06:16<20:21,  1.15s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 325/1384 [06:16<20:11,  1.14s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 325/1384 [06:17<20:11,  1.14s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 326/1384 [06:17<19:56,  1.13s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 326/1384 [06:18<19:56,  1.13s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 327/1384 [06:18<19:48,  1.12s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 327/1384 [06:20<19:48,  1.12s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 328/1384 [06:20<19:38,  1.12s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 328/1384 [06:21<19:38,  1.12s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 329/1384 [06:21<19:30,  1.11s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 329/1384 [06:22<19:30,  1.11s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 330/1384 [06:22<19:24,  1.10s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 330/1384 [06:23<19:24,  1.10s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 331/1384 [06:23<19:20,  1.10s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 331/1384 [06:24<19:20,  1.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 332/1384 [06:24<19:29,  1.11s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 332/1384 [06:25<19:29,  1.11s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 333/1384 [06:25<19:30,  1.11s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 333/1384 [06:26<19:30,  1.11s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 334/1384 [06:26<19:22,  1.11s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 334/1384 [06:27<19:22,  1.11s/it, training_loss=0.585]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 335/1384 [06:27<19:17,  1.10s/it, training_loss=0.585]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 335/1384 [06:28<19:17,  1.10s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 336/1384 [06:28<19:13,  1.10s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 336/1384 [06:29<19:13,  1.10s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 337/1384 [06:29<19:10,  1.10s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 337/1384 [06:31<19:10,  1.10s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 338/1384 [06:31<19:12,  1.10s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 338/1384 [06:32<19:12,  1.10s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 339/1384 [06:32<19:30,  1.12s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 339/1384 [06:33<19:30,  1.12s/it, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 340/1384 [06:33<19:26,  1.12s/it, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 340/1384 [06:34<19:26,  1.12s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 341/1384 [06:34<19:21,  1.11s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 341/1384 [06:35<19:21,  1.11s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 342/1384 [06:35<19:20,  1.11s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 342/1384 [06:36<19:20,  1.11s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 343/1384 [06:36<19:19,  1.11s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 343/1384 [06:37<19:19,  1.11s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 344/1384 [06:37<19:14,  1.11s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 344/1384 [06:38<19:14,  1.11s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 345/1384 [06:38<19:11,  1.11s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 345/1384 [06:39<19:11,  1.11s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 346/1384 [06:39<19:04,  1.10s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 346/1384 [06:41<19:04,  1.10s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 347/1384 [06:41<19:13,  1.11s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 347/1384 [06:42<19:13,  1.11s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 348/1384 [06:42<19:09,  1.11s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 348/1384 [06:43<19:09,  1.11s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 349/1384 [06:43<19:06,  1.11s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 349/1384 [06:44<19:06,  1.11s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 350/1384 [06:44<19:05,  1.11s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 350/1384 [06:45<19:05,  1.11s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 351/1384 [06:45<19:08,  1.11s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 351/1384 [06:46<19:08,  1.11s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 352/1384 [06:46<19:16,  1.12s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 352/1384 [06:47<19:16,  1.12s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 353/1384 [06:47<19:54,  1.16s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 353/1384 [06:49<19:54,  1.16s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 354/1384 [06:49<19:49,  1.15s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 354/1384 [06:50<19:49,  1.15s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 355/1384 [06:50<19:33,  1.14s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 355/1384 [06:51<19:33,  1.14s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 356/1384 [06:51<19:24,  1.13s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 356/1384 [06:52<19:24,  1.13s/it, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 357/1384 [06:52<19:59,  1.17s/it, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 357/1384 [06:53<19:59,  1.17s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 358/1384 [06:53<20:29,  1.20s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 358/1384 [06:55<20:29,  1.20s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 359/1384 [06:55<20:39,  1.21s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 359/1384 [06:56<20:39,  1.21s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 360/1384 [06:56<20:39,  1.21s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 360/1384 [06:57<20:39,  1.21s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 361/1384 [06:57<20:18,  1.19s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 361/1384 [06:58<20:18,  1.19s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 362/1384 [06:58<20:05,  1.18s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 362/1384 [06:59<20:05,  1.18s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 363/1384 [06:59<20:59,  1.23s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 363/1384 [07:01<20:59,  1.23s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 364/1384 [07:01<20:53,  1.23s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 364/1384 [07:02<20:53,  1.23s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 365/1384 [07:02<20:50,  1.23s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 365/1384 [07:03<20:50,  1.23s/it, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 366/1384 [07:03<20:50,  1.23s/it, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 366/1384 [07:04<20:50,  1.23s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 367/1384 [07:04<20:44,  1.22s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 367/1384 [07:06<20:44,  1.22s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 368/1384 [07:06<20:48,  1.23s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 368/1384 [07:07<20:48,  1.23s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 369/1384 [07:07<20:50,  1.23s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 369/1384 [07:08<20:50,  1.23s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 370/1384 [07:08<20:53,  1.24s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 370/1384 [07:09<20:53,  1.24s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 371/1384 [07:09<20:47,  1.23s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 371/1384 [07:10<20:47,  1.23s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 372/1384 [07:10<20:38,  1.22s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 372/1384 [07:12<20:38,  1.22s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 373/1384 [07:12<20:47,  1.23s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 373/1384 [07:13<20:47,  1.23s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 374/1384 [07:13<20:48,  1.24s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 374/1384 [07:14<20:48,  1.24s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 375/1384 [07:14<20:18,  1.21s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 375/1384 [07:15<20:18,  1.21s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 376/1384 [07:15<20:23,  1.21s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 376/1384 [07:17<20:23,  1.21s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 377/1384 [07:17<20:22,  1.21s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 377/1384 [07:18<20:22,  1.21s/it, training_loss=0.652]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 378/1384 [07:18<20:29,  1.22s/it, training_loss=0.652]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 378/1384 [07:19<20:29,  1.22s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 379/1384 [07:19<21:06,  1.26s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 379/1384 [07:21<21:06,  1.26s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 380/1384 [07:21<21:44,  1.30s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 380/1384 [07:22<21:44,  1.30s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 381/1384 [07:22<22:08,  1.32s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 381/1384 [07:23<22:08,  1.32s/it, training_loss=0.699]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 382/1384 [07:23<22:13,  1.33s/it, training_loss=0.699]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 382/1384 [07:25<22:13,  1.33s/it, training_loss=0.473]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 383/1384 [07:25<21:56,  1.32s/it, training_loss=0.473]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 383/1384 [07:26<21:56,  1.32s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 384/1384 [07:26<21:33,  1.29s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 384/1384 [07:27<21:33,  1.29s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 385/1384 [07:27<21:08,  1.27s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 385/1384 [07:28<21:08,  1.27s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 386/1384 [07:28<21:23,  1.29s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 386/1384 [07:30<21:23,  1.29s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 387/1384 [07:30<22:18,  1.34s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 387/1384 [07:31<22:18,  1.34s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 388/1384 [07:31<22:29,  1.36s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 388/1384 [07:32<22:29,  1.36s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 389/1384 [07:32<22:14,  1.34s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 389/1384 [07:34<22:14,  1.34s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 390/1384 [07:34<21:55,  1.32s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 390/1384 [07:35<21:55,  1.32s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 391/1384 [07:35<21:52,  1.32s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 391/1384 [07:36<21:52,  1.32s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 392/1384 [07:36<21:22,  1.29s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 392/1384 [07:37<21:22,  1.29s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 393/1384 [07:37<20:39,  1.25s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 393/1384 [07:39<20:39,  1.25s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 394/1384 [07:39<20:13,  1.23s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 394/1384 [07:40<20:13,  1.23s/it, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 395/1384 [07:40<20:17,  1.23s/it, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 395/1384 [07:41<20:17,  1.23s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 396/1384 [07:41<19:56,  1.21s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 396/1384 [07:42<19:56,  1.21s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 397/1384 [07:42<19:59,  1.21s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 397/1384 [07:43<19:59,  1.21s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 398/1384 [07:43<19:42,  1.20s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 398/1384 [07:45<19:42,  1.20s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 399/1384 [07:45<19:42,  1.20s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 399/1384 [07:46<19:42,  1.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 400/1384 [07:46<19:39,  1.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 400/1384 [07:47<19:39,  1.20s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 401/1384 [07:47<19:18,  1.18s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 401/1384 [07:48<19:18,  1.18s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 402/1384 [07:48<18:57,  1.16s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 402/1384 [07:49<18:57,  1.16s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 403/1384 [07:49<18:49,  1.15s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 403/1384 [07:50<18:49,  1.15s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 404/1384 [07:50<18:34,  1.14s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 404/1384 [07:51<18:34,  1.14s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 405/1384 [07:51<18:23,  1.13s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 405/1384 [07:53<18:23,  1.13s/it, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 406/1384 [07:53<18:16,  1.12s/it, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 406/1384 [07:54<18:16,  1.12s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 407/1384 [07:54<18:19,  1.13s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 407/1384 [07:55<18:19,  1.13s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 408/1384 [07:55<18:17,  1.12s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 408/1384 [07:56<18:17,  1.12s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 409/1384 [07:56<18:21,  1.13s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 409/1384 [07:57<18:21,  1.13s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 410/1384 [07:57<18:35,  1.14s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 410/1384 [07:58<18:35,  1.14s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 411/1384 [07:58<19:13,  1.19s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 411/1384 [08:00<19:13,  1.19s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 412/1384 [08:00<19:08,  1.18s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 412/1384 [08:01<19:08,  1.18s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 413/1384 [08:01<19:27,  1.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 413/1384 [08:02<19:27,  1.20s/it, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 414/1384 [08:02<19:11,  1.19s/it, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 414/1384 [08:03<19:11,  1.19s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 415/1384 [08:03<18:40,  1.16s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 415/1384 [08:04<18:40,  1.16s/it, training_loss=0.408]\u001b[A\n",
      "Epoch 1:  30%|███       | 416/1384 [08:04<18:50,  1.17s/it, training_loss=0.408]\u001b[A\n",
      "Epoch 1:  30%|███       | 416/1384 [08:05<18:50,  1.17s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  30%|███       | 417/1384 [08:05<18:52,  1.17s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  30%|███       | 417/1384 [08:07<18:52,  1.17s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  30%|███       | 418/1384 [08:07<18:54,  1.17s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  30%|███       | 418/1384 [08:08<18:54,  1.17s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  30%|███       | 419/1384 [08:08<18:45,  1.17s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  30%|███       | 419/1384 [08:09<18:45,  1.17s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  30%|███       | 420/1384 [08:09<18:55,  1.18s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  30%|███       | 420/1384 [08:10<18:55,  1.18s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  30%|███       | 421/1384 [08:10<18:54,  1.18s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  30%|███       | 421/1384 [08:11<18:54,  1.18s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  30%|███       | 422/1384 [08:11<19:11,  1.20s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  30%|███       | 422/1384 [08:13<19:11,  1.20s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  31%|███       | 423/1384 [08:13<19:07,  1.19s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  31%|███       | 423/1384 [08:14<19:07,  1.19s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  31%|███       | 424/1384 [08:14<19:03,  1.19s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  31%|███       | 424/1384 [08:15<19:03,  1.19s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  31%|███       | 425/1384 [08:15<19:43,  1.23s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  31%|███       | 425/1384 [08:16<19:43,  1.23s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  31%|███       | 426/1384 [08:16<19:44,  1.24s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  31%|███       | 426/1384 [08:18<19:44,  1.24s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  31%|███       | 427/1384 [08:18<20:03,  1.26s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  31%|███       | 427/1384 [08:19<20:03,  1.26s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  31%|███       | 428/1384 [08:19<20:25,  1.28s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  31%|███       | 428/1384 [08:20<20:25,  1.28s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  31%|███       | 429/1384 [08:20<20:36,  1.29s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  31%|███       | 429/1384 [08:22<20:36,  1.29s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  31%|███       | 430/1384 [08:22<20:56,  1.32s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  31%|███       | 430/1384 [08:23<20:56,  1.32s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  31%|███       | 431/1384 [08:23<21:02,  1.32s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  31%|███       | 431/1384 [08:24<21:02,  1.32s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  31%|███       | 432/1384 [08:24<20:45,  1.31s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  31%|███       | 432/1384 [08:25<20:45,  1.31s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 433/1384 [08:25<20:03,  1.27s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 433/1384 [08:27<20:03,  1.27s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 434/1384 [08:27<19:41,  1.24s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 434/1384 [08:28<19:41,  1.24s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 435/1384 [08:28<19:36,  1.24s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 435/1384 [08:29<19:36,  1.24s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 436/1384 [08:29<19:34,  1.24s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 436/1384 [08:30<19:34,  1.24s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 437/1384 [08:30<19:50,  1.26s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 437/1384 [08:32<19:50,  1.26s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 438/1384 [08:32<19:39,  1.25s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 438/1384 [08:33<19:39,  1.25s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 439/1384 [08:33<19:46,  1.26s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 439/1384 [08:34<19:46,  1.26s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 440/1384 [08:34<19:27,  1.24s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 440/1384 [08:35<19:27,  1.24s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 441/1384 [08:35<19:03,  1.21s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 441/1384 [08:36<19:03,  1.21s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 442/1384 [08:36<18:14,  1.16s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 442/1384 [08:37<18:14,  1.16s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 443/1384 [08:37<17:56,  1.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 443/1384 [08:39<17:56,  1.14s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 444/1384 [08:39<17:53,  1.14s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 444/1384 [08:40<17:53,  1.14s/it, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 445/1384 [08:40<18:15,  1.17s/it, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 445/1384 [08:41<18:15,  1.17s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 446/1384 [08:41<18:22,  1.18s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 446/1384 [08:42<18:22,  1.18s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 447/1384 [08:42<18:57,  1.21s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 447/1384 [08:44<18:57,  1.21s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 448/1384 [08:44<19:39,  1.26s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 448/1384 [08:45<19:39,  1.26s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 449/1384 [08:45<19:13,  1.23s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 449/1384 [08:46<19:13,  1.23s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 450/1384 [08:46<19:41,  1.26s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 450/1384 [08:47<19:41,  1.26s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 451/1384 [08:47<19:51,  1.28s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 451/1384 [08:49<19:51,  1.28s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 452/1384 [08:49<20:02,  1.29s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 452/1384 [08:50<20:02,  1.29s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 453/1384 [08:50<20:26,  1.32s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 453/1384 [08:52<20:26,  1.32s/it, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 454/1384 [08:52<21:14,  1.37s/it, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 454/1384 [08:53<21:14,  1.37s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 455/1384 [08:53<21:21,  1.38s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 455/1384 [08:54<21:21,  1.38s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 456/1384 [08:54<21:15,  1.37s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 456/1384 [08:56<21:15,  1.37s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 457/1384 [08:56<21:17,  1.38s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 457/1384 [08:57<21:17,  1.38s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 458/1384 [08:57<21:12,  1.37s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 458/1384 [08:58<21:12,  1.37s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 459/1384 [08:58<20:57,  1.36s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 459/1384 [09:00<20:57,  1.36s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 460/1384 [09:00<20:35,  1.34s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 460/1384 [09:01<20:35,  1.34s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 461/1384 [09:01<20:10,  1.31s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 461/1384 [09:02<20:10,  1.31s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 462/1384 [09:02<19:53,  1.29s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 462/1384 [09:04<19:53,  1.29s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 463/1384 [09:04<19:45,  1.29s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 463/1384 [09:05<19:45,  1.29s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 464/1384 [09:05<19:50,  1.29s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 464/1384 [09:06<19:50,  1.29s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 465/1384 [09:06<19:39,  1.28s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 465/1384 [09:07<19:39,  1.28s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 466/1384 [09:07<19:35,  1.28s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 466/1384 [09:09<19:35,  1.28s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 467/1384 [09:09<19:33,  1.28s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 467/1384 [09:10<19:33,  1.28s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 468/1384 [09:10<19:25,  1.27s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 468/1384 [09:11<19:25,  1.27s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 469/1384 [09:11<19:19,  1.27s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 469/1384 [09:12<19:19,  1.27s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 470/1384 [09:12<19:12,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 470/1384 [09:14<19:12,  1.26s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 471/1384 [09:14<19:13,  1.26s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 471/1384 [09:15<19:13,  1.26s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 472/1384 [09:15<19:09,  1.26s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 472/1384 [09:16<19:09,  1.26s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 473/1384 [09:16<18:46,  1.24s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 473/1384 [09:17<18:46,  1.24s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 474/1384 [09:17<18:40,  1.23s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 474/1384 [09:19<18:40,  1.23s/it, training_loss=0.624]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 475/1384 [09:19<18:51,  1.24s/it, training_loss=0.624]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 475/1384 [09:20<18:51,  1.24s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 476/1384 [09:20<18:42,  1.24s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 476/1384 [09:21<18:42,  1.24s/it, training_loss=0.515]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 477/1384 [09:21<18:49,  1.25s/it, training_loss=0.515]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 477/1384 [09:22<18:49,  1.25s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 478/1384 [09:22<18:23,  1.22s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 478/1384 [09:23<18:23,  1.22s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 479/1384 [09:23<18:06,  1.20s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 479/1384 [09:25<18:06,  1.20s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 480/1384 [09:25<17:59,  1.19s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 480/1384 [09:26<17:59,  1.19s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 481/1384 [09:26<17:46,  1.18s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 481/1384 [09:27<17:46,  1.18s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 482/1384 [09:27<17:30,  1.17s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 482/1384 [09:28<17:30,  1.17s/it, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 483/1384 [09:28<17:33,  1.17s/it, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 483/1384 [09:29<17:33,  1.17s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 484/1384 [09:29<18:15,  1.22s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 484/1384 [09:31<18:15,  1.22s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 485/1384 [09:31<18:39,  1.25s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 485/1384 [09:32<18:39,  1.25s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 486/1384 [09:32<18:33,  1.24s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 486/1384 [09:33<18:33,  1.24s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 487/1384 [09:33<18:31,  1.24s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 487/1384 [09:34<18:31,  1.24s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 488/1384 [09:34<18:30,  1.24s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 488/1384 [09:36<18:30,  1.24s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 489/1384 [09:36<18:07,  1.22s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 489/1384 [09:37<18:07,  1.22s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 490/1384 [09:37<17:47,  1.19s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 490/1384 [09:38<17:47,  1.19s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 491/1384 [09:38<17:32,  1.18s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 491/1384 [09:39<17:32,  1.18s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 492/1384 [09:39<17:54,  1.20s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 492/1384 [09:40<17:54,  1.20s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 493/1384 [09:40<17:39,  1.19s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 493/1384 [09:41<17:39,  1.19s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 494/1384 [09:41<17:29,  1.18s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 494/1384 [09:43<17:29,  1.18s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 495/1384 [09:43<17:48,  1.20s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 495/1384 [09:44<17:48,  1.20s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 496/1384 [09:44<17:32,  1.19s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 496/1384 [09:45<17:32,  1.19s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 497/1384 [09:45<17:26,  1.18s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 497/1384 [09:46<17:26,  1.18s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 498/1384 [09:46<17:47,  1.21s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 498/1384 [09:48<17:47,  1.21s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 499/1384 [09:48<18:05,  1.23s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 499/1384 [09:49<18:05,  1.23s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 500/1384 [09:49<18:05,  1.23s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 500/1384 [09:50<18:05,  1.23s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 501/1384 [09:50<17:44,  1.21s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 501/1384 [09:51<17:44,  1.21s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 502/1384 [09:51<18:26,  1.25s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 502/1384 [09:52<18:26,  1.25s/it, training_loss=0.525]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 503/1384 [09:52<18:15,  1.24s/it, training_loss=0.525]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 503/1384 [09:54<18:15,  1.24s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 504/1384 [09:54<17:50,  1.22s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 504/1384 [09:55<17:50,  1.22s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 505/1384 [09:55<17:40,  1.21s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 505/1384 [09:56<17:40,  1.21s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 506/1384 [09:56<17:28,  1.19s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 506/1384 [09:57<17:28,  1.19s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 507/1384 [09:57<17:10,  1.18s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 507/1384 [09:58<17:10,  1.18s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 508/1384 [09:58<17:02,  1.17s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 508/1384 [09:59<17:02,  1.17s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 509/1384 [09:59<16:52,  1.16s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 509/1384 [10:01<16:52,  1.16s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 510/1384 [10:01<16:48,  1.15s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 510/1384 [10:02<16:48,  1.15s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 511/1384 [10:02<18:01,  1.24s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 511/1384 [10:03<18:01,  1.24s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 512/1384 [10:03<18:38,  1.28s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 512/1384 [10:05<18:38,  1.28s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 513/1384 [10:05<18:58,  1.31s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 513/1384 [10:06<18:58,  1.31s/it, training_loss=0.593]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 514/1384 [10:06<19:24,  1.34s/it, training_loss=0.593]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 514/1384 [10:07<19:24,  1.34s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 515/1384 [10:07<18:36,  1.29s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 515/1384 [10:08<18:36,  1.29s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 516/1384 [10:08<17:54,  1.24s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 516/1384 [10:10<17:54,  1.24s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 517/1384 [10:10<17:51,  1.24s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 517/1384 [10:11<17:51,  1.24s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 518/1384 [10:11<17:50,  1.24s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 518/1384 [10:12<17:50,  1.24s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 519/1384 [10:12<17:52,  1.24s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 519/1384 [10:13<17:52,  1.24s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 520/1384 [10:13<18:00,  1.25s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 520/1384 [10:15<18:00,  1.25s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 521/1384 [10:15<17:57,  1.25s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 521/1384 [10:16<17:57,  1.25s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 522/1384 [10:16<18:05,  1.26s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 522/1384 [10:17<18:05,  1.26s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 523/1384 [10:17<18:23,  1.28s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 523/1384 [10:18<18:23,  1.28s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 524/1384 [10:18<18:01,  1.26s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 524/1384 [10:20<18:01,  1.26s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 525/1384 [10:20<17:44,  1.24s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 525/1384 [10:21<17:44,  1.24s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 526/1384 [10:21<17:45,  1.24s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 526/1384 [10:22<17:45,  1.24s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 527/1384 [10:22<17:54,  1.25s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 527/1384 [10:23<17:54,  1.25s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 528/1384 [10:23<17:54,  1.26s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 528/1384 [10:25<17:54,  1.26s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 529/1384 [10:25<18:15,  1.28s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 529/1384 [10:26<18:15,  1.28s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 530/1384 [10:26<17:59,  1.26s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 530/1384 [10:27<17:59,  1.26s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 531/1384 [10:27<17:32,  1.23s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 531/1384 [10:28<17:32,  1.23s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 532/1384 [10:28<17:04,  1.20s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 532/1384 [10:29<17:04,  1.20s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 533/1384 [10:29<16:52,  1.19s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 533/1384 [10:31<16:52,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 534/1384 [10:31<16:45,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 534/1384 [10:32<16:45,  1.18s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 535/1384 [10:32<16:27,  1.16s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 535/1384 [10:33<16:27,  1.16s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 536/1384 [10:33<16:13,  1.15s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 536/1384 [10:34<16:13,  1.15s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 537/1384 [10:34<16:31,  1.17s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 537/1384 [10:35<16:31,  1.17s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 538/1384 [10:35<16:25,  1.17s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 538/1384 [10:36<16:25,  1.17s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 539/1384 [10:36<16:26,  1.17s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 539/1384 [10:38<16:26,  1.17s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 540/1384 [10:38<16:29,  1.17s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 540/1384 [10:39<16:29,  1.17s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 541/1384 [10:39<16:22,  1.16s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 541/1384 [10:40<16:22,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 542/1384 [10:40<16:25,  1.17s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 542/1384 [10:41<16:25,  1.17s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 543/1384 [10:41<16:28,  1.17s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 543/1384 [10:42<16:28,  1.17s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 544/1384 [10:42<16:20,  1.17s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 544/1384 [10:43<16:20,  1.17s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 545/1384 [10:43<16:24,  1.17s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 545/1384 [10:45<16:24,  1.17s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 546/1384 [10:45<16:25,  1.18s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 546/1384 [10:46<16:25,  1.18s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 547/1384 [10:46<16:19,  1.17s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 547/1384 [10:47<16:19,  1.17s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 548/1384 [10:47<16:30,  1.18s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 548/1384 [10:48<16:30,  1.18s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 549/1384 [10:48<16:36,  1.19s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 549/1384 [10:50<16:36,  1.19s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 550/1384 [10:50<18:17,  1.32s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 550/1384 [10:51<18:17,  1.32s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 551/1384 [10:51<18:04,  1.30s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 551/1384 [10:52<18:04,  1.30s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 552/1384 [10:52<17:47,  1.28s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 552/1384 [10:54<17:47,  1.28s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 553/1384 [10:54<17:33,  1.27s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 553/1384 [10:55<17:33,  1.27s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  40%|████      | 554/1384 [10:55<17:56,  1.30s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  40%|████      | 554/1384 [10:56<17:56,  1.30s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  40%|████      | 555/1384 [10:56<17:54,  1.30s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  40%|████      | 555/1384 [10:58<17:54,  1.30s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  40%|████      | 556/1384 [10:58<17:44,  1.29s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  40%|████      | 556/1384 [10:59<17:44,  1.29s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  40%|████      | 557/1384 [10:59<17:30,  1.27s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  40%|████      | 557/1384 [11:00<17:30,  1.27s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  40%|████      | 558/1384 [11:00<17:19,  1.26s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  40%|████      | 558/1384 [11:01<17:19,  1.26s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  40%|████      | 559/1384 [11:01<18:14,  1.33s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  40%|████      | 559/1384 [11:03<18:14,  1.33s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  40%|████      | 560/1384 [11:03<18:02,  1.31s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  40%|████      | 560/1384 [11:04<18:02,  1.31s/it, training_loss=0.591]\u001b[A\n",
      "Epoch 1:  41%|████      | 561/1384 [11:04<18:38,  1.36s/it, training_loss=0.591]\u001b[A\n",
      "Epoch 1:  41%|████      | 561/1384 [11:05<18:38,  1.36s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  41%|████      | 562/1384 [11:05<17:42,  1.29s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  41%|████      | 562/1384 [11:07<17:42,  1.29s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  41%|████      | 563/1384 [11:07<17:29,  1.28s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  41%|████      | 563/1384 [11:08<17:29,  1.28s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  41%|████      | 564/1384 [11:08<17:20,  1.27s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  41%|████      | 564/1384 [11:09<17:20,  1.27s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  41%|████      | 565/1384 [11:09<17:17,  1.27s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  41%|████      | 565/1384 [11:10<17:17,  1.27s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  41%|████      | 566/1384 [11:10<17:15,  1.27s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  41%|████      | 566/1384 [11:12<17:15,  1.27s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  41%|████      | 567/1384 [11:12<17:23,  1.28s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  41%|████      | 567/1384 [11:13<17:23,  1.28s/it, training_loss=0.495]\u001b[A\n",
      "Epoch 1:  41%|████      | 568/1384 [11:13<17:30,  1.29s/it, training_loss=0.495]\u001b[A\n",
      "Epoch 1:  41%|████      | 568/1384 [11:14<17:30,  1.29s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  41%|████      | 569/1384 [11:14<17:29,  1.29s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  41%|████      | 569/1384 [11:16<17:29,  1.29s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  41%|████      | 570/1384 [11:16<17:20,  1.28s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  41%|████      | 570/1384 [11:17<17:20,  1.28s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 571/1384 [11:17<17:25,  1.29s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 571/1384 [11:18<17:25,  1.29s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 572/1384 [11:18<17:25,  1.29s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 572/1384 [11:19<17:25,  1.29s/it, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 573/1384 [11:19<17:20,  1.28s/it, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 573/1384 [11:21<17:20,  1.28s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 574/1384 [11:21<17:03,  1.26s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 574/1384 [11:22<17:03,  1.26s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 575/1384 [11:22<17:30,  1.30s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 575/1384 [11:23<17:30,  1.30s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 576/1384 [11:23<17:24,  1.29s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 576/1384 [11:25<17:24,  1.29s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 577/1384 [11:25<17:33,  1.31s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 577/1384 [11:26<17:33,  1.31s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 578/1384 [11:26<16:55,  1.26s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 578/1384 [11:27<16:55,  1.26s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 579/1384 [11:27<16:30,  1.23s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 579/1384 [11:28<16:30,  1.23s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 580/1384 [11:28<16:08,  1.20s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 580/1384 [11:29<16:08,  1.20s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 581/1384 [11:29<15:57,  1.19s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 581/1384 [11:30<15:57,  1.19s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 582/1384 [11:30<15:42,  1.18s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 582/1384 [11:31<15:42,  1.18s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 583/1384 [11:31<15:30,  1.16s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 583/1384 [11:33<15:30,  1.16s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 584/1384 [11:33<15:24,  1.16s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 584/1384 [11:34<15:24,  1.16s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 585/1384 [11:34<15:18,  1.15s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 585/1384 [11:35<15:18,  1.15s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 586/1384 [11:35<15:15,  1.15s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 586/1384 [11:36<15:15,  1.15s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 587/1384 [11:36<15:15,  1.15s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 587/1384 [11:37<15:15,  1.15s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 588/1384 [11:37<15:13,  1.15s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 588/1384 [11:38<15:13,  1.15s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 589/1384 [11:38<15:08,  1.14s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 589/1384 [11:39<15:08,  1.14s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 590/1384 [11:40<15:11,  1.15s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 590/1384 [11:41<15:11,  1.15s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 591/1384 [11:41<15:09,  1.15s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 591/1384 [11:42<15:09,  1.15s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 592/1384 [11:42<15:05,  1.14s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 592/1384 [11:43<15:05,  1.14s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 593/1384 [11:43<15:04,  1.14s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 593/1384 [11:44<15:04,  1.14s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 594/1384 [11:44<15:03,  1.14s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 594/1384 [11:45<15:03,  1.14s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 595/1384 [11:45<14:56,  1.14s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 595/1384 [11:46<14:56,  1.14s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 596/1384 [11:46<14:56,  1.14s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 596/1384 [11:47<14:56,  1.14s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 597/1384 [11:47<14:56,  1.14s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 597/1384 [11:49<14:56,  1.14s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 598/1384 [11:49<14:58,  1.14s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 598/1384 [11:50<14:58,  1.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 599/1384 [11:50<14:58,  1.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 599/1384 [11:51<14:58,  1.14s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 600/1384 [11:51<14:54,  1.14s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 600/1384 [11:52<14:54,  1.14s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 601/1384 [11:52<14:50,  1.14s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 601/1384 [11:53<14:50,  1.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 602/1384 [11:53<14:49,  1.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 602/1384 [11:54<14:49,  1.14s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 603/1384 [11:54<14:51,  1.14s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 603/1384 [11:55<14:51,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 604/1384 [11:55<14:50,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 604/1384 [11:57<14:50,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 605/1384 [11:57<14:49,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 605/1384 [11:58<14:49,  1.14s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 606/1384 [11:58<14:45,  1.14s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 606/1384 [11:59<14:45,  1.14s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 607/1384 [11:59<14:49,  1.15s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 607/1384 [12:00<14:49,  1.15s/it, training_loss=0.473]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 608/1384 [12:00<14:46,  1.14s/it, training_loss=0.473]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 608/1384 [12:01<14:46,  1.14s/it, training_loss=0.617]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 609/1384 [12:01<14:43,  1.14s/it, training_loss=0.617]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 609/1384 [12:02<14:43,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 610/1384 [12:02<14:40,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 610/1384 [12:03<14:40,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 611/1384 [12:03<14:41,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 611/1384 [12:05<14:41,  1.14s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 612/1384 [12:05<14:38,  1.14s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 612/1384 [12:06<14:38,  1.14s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 613/1384 [12:06<14:34,  1.13s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 613/1384 [12:07<14:34,  1.13s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 614/1384 [12:07<14:36,  1.14s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 614/1384 [12:08<14:36,  1.14s/it, training_loss=0.506]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 615/1384 [12:08<14:34,  1.14s/it, training_loss=0.506]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 615/1384 [12:09<14:34,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 616/1384 [12:09<14:32,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 616/1384 [12:10<14:32,  1.14s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 617/1384 [12:10<14:31,  1.14s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 617/1384 [12:11<14:31,  1.14s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 618/1384 [12:11<14:33,  1.14s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 618/1384 [12:13<14:33,  1.14s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 619/1384 [12:13<14:30,  1.14s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 619/1384 [12:14<14:30,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 620/1384 [12:14<14:31,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 620/1384 [12:15<14:31,  1.14s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 621/1384 [12:15<14:31,  1.14s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 621/1384 [12:16<14:31,  1.14s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 622/1384 [12:16<14:32,  1.14s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 622/1384 [12:17<14:32,  1.14s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 623/1384 [12:17<14:29,  1.14s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 623/1384 [12:18<14:29,  1.14s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 624/1384 [12:18<14:24,  1.14s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 624/1384 [12:19<14:24,  1.14s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 625/1384 [12:19<14:24,  1.14s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 625/1384 [12:21<14:24,  1.14s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 626/1384 [12:21<14:25,  1.14s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 626/1384 [12:22<14:25,  1.14s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 627/1384 [12:22<14:24,  1.14s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 627/1384 [12:23<14:24,  1.14s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 628/1384 [12:23<14:23,  1.14s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 628/1384 [12:24<14:23,  1.14s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 629/1384 [12:24<14:23,  1.14s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 629/1384 [12:25<14:23,  1.14s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 630/1384 [12:25<14:26,  1.15s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 630/1384 [12:26<14:26,  1.15s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 631/1384 [12:26<14:22,  1.15s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 631/1384 [12:27<14:22,  1.15s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 632/1384 [12:27<14:22,  1.15s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 632/1384 [12:29<14:22,  1.15s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 633/1384 [12:29<14:27,  1.15s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 633/1384 [12:30<14:27,  1.15s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 634/1384 [12:30<14:26,  1.16s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 634/1384 [12:31<14:26,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 635/1384 [12:31<14:30,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 635/1384 [12:32<14:30,  1.16s/it, training_loss=0.564]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 636/1384 [12:32<14:40,  1.18s/it, training_loss=0.564]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 636/1384 [12:33<14:40,  1.18s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 637/1384 [12:33<14:39,  1.18s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 637/1384 [12:34<14:39,  1.18s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 638/1384 [12:34<14:38,  1.18s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 638/1384 [12:36<14:38,  1.18s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 639/1384 [12:36<14:40,  1.18s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 639/1384 [12:37<14:40,  1.18s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 640/1384 [12:37<14:37,  1.18s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 640/1384 [12:38<14:37,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 641/1384 [12:38<14:36,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 641/1384 [12:39<14:36,  1.18s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 642/1384 [12:39<14:36,  1.18s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 642/1384 [12:40<14:36,  1.18s/it, training_loss=0.526]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 643/1384 [12:40<14:46,  1.20s/it, training_loss=0.526]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 643/1384 [12:42<14:46,  1.20s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 644/1384 [12:42<14:42,  1.19s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 644/1384 [12:43<14:42,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 645/1384 [12:43<14:43,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 645/1384 [12:44<14:43,  1.20s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 646/1384 [12:44<14:41,  1.19s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 646/1384 [12:45<14:41,  1.19s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 647/1384 [12:45<14:41,  1.20s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 647/1384 [12:46<14:41,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 648/1384 [12:46<14:36,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 648/1384 [12:48<14:36,  1.19s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 649/1384 [12:48<14:28,  1.18s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 649/1384 [12:49<14:28,  1.18s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 650/1384 [12:49<14:32,  1.19s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 650/1384 [12:50<14:32,  1.19s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 651/1384 [12:50<14:24,  1.18s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 651/1384 [12:51<14:24,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 652/1384 [12:51<14:24,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 652/1384 [12:52<14:24,  1.18s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 653/1384 [12:52<14:17,  1.17s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 653/1384 [12:53<14:17,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 654/1384 [12:53<14:13,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 654/1384 [12:55<14:13,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 655/1384 [12:55<14:07,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 655/1384 [12:56<14:07,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 656/1384 [12:56<14:03,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 656/1384 [12:57<14:03,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 657/1384 [12:57<14:05,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 657/1384 [12:58<14:05,  1.16s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 658/1384 [12:58<14:01,  1.16s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 658/1384 [12:59<14:01,  1.16s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 659/1384 [12:59<14:02,  1.16s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 659/1384 [13:00<14:02,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 660/1384 [13:00<13:58,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 660/1384 [13:02<13:58,  1.16s/it, training_loss=0.653]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 661/1384 [13:02<13:56,  1.16s/it, training_loss=0.653]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 661/1384 [13:03<13:56,  1.16s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 662/1384 [13:03<13:56,  1.16s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 662/1384 [13:04<13:56,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 663/1384 [13:04<13:54,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 663/1384 [13:05<13:54,  1.16s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 664/1384 [13:05<13:59,  1.17s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 664/1384 [13:06<13:59,  1.17s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 665/1384 [13:06<13:56,  1.16s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 665/1384 [13:07<13:56,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 666/1384 [13:07<13:54,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 666/1384 [13:08<13:54,  1.16s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 667/1384 [13:08<13:50,  1.16s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 667/1384 [13:10<13:50,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 668/1384 [13:10<13:50,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 668/1384 [13:11<13:50,  1.16s/it, training_loss=0.933]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 669/1384 [13:11<13:46,  1.16s/it, training_loss=0.933]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 669/1384 [13:12<13:46,  1.16s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 670/1384 [13:12<13:50,  1.16s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 670/1384 [13:13<13:50,  1.16s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 671/1384 [13:13<13:52,  1.17s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 671/1384 [13:14<13:52,  1.17s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 672/1384 [13:14<13:57,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 672/1384 [13:16<13:57,  1.18s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 673/1384 [13:16<13:52,  1.17s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 673/1384 [13:17<13:52,  1.17s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 674/1384 [13:17<13:46,  1.16s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 674/1384 [13:18<13:46,  1.16s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 675/1384 [13:18<13:44,  1.16s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 675/1384 [13:19<13:44,  1.16s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 676/1384 [13:19<13:44,  1.16s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 676/1384 [13:20<13:44,  1.16s/it, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 677/1384 [13:20<13:41,  1.16s/it, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 677/1384 [13:21<13:41,  1.16s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 678/1384 [13:21<13:38,  1.16s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 678/1384 [13:22<13:38,  1.16s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 679/1384 [13:22<13:41,  1.16s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 679/1384 [13:24<13:41,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 680/1384 [13:24<13:39,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 680/1384 [13:25<13:39,  1.16s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 681/1384 [13:25<13:37,  1.16s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 681/1384 [13:26<13:37,  1.16s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 682/1384 [13:26<13:36,  1.16s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 682/1384 [13:27<13:36,  1.16s/it, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 683/1384 [13:27<13:36,  1.16s/it, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 683/1384 [13:28<13:36,  1.16s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 684/1384 [13:28<13:33,  1.16s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 684/1384 [13:30<13:33,  1.16s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 685/1384 [13:30<13:48,  1.18s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 685/1384 [13:31<13:48,  1.18s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 686/1384 [13:31<13:44,  1.18s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 686/1384 [13:32<13:44,  1.18s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 687/1384 [13:32<13:45,  1.18s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 687/1384 [13:33<13:45,  1.18s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 688/1384 [13:33<13:39,  1.18s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 688/1384 [13:34<13:39,  1.18s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 689/1384 [13:34<13:37,  1.18s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 689/1384 [13:35<13:37,  1.18s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 690/1384 [13:35<13:34,  1.17s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 690/1384 [13:37<13:34,  1.17s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 691/1384 [13:37<13:28,  1.17s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 691/1384 [13:38<13:28,  1.17s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  50%|█████     | 692/1384 [13:38<13:28,  1.17s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  50%|█████     | 692/1384 [13:39<13:28,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  50%|█████     | 693/1384 [13:39<13:25,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  50%|█████     | 693/1384 [13:40<13:25,  1.17s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 1:  50%|█████     | 694/1384 [13:40<13:24,  1.17s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 1:  50%|█████     | 694/1384 [13:41<13:24,  1.17s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  50%|█████     | 695/1384 [13:41<13:23,  1.17s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  50%|█████     | 695/1384 [13:42<13:23,  1.17s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  50%|█████     | 696/1384 [13:42<13:30,  1.18s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  50%|█████     | 696/1384 [13:44<13:30,  1.18s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  50%|█████     | 697/1384 [13:44<13:26,  1.17s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  50%|█████     | 697/1384 [13:45<13:26,  1.17s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  50%|█████     | 698/1384 [13:45<13:24,  1.17s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  50%|█████     | 698/1384 [13:46<13:24,  1.17s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  51%|█████     | 699/1384 [13:46<13:21,  1.17s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  51%|█████     | 699/1384 [13:47<13:21,  1.17s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  51%|█████     | 700/1384 [13:47<13:20,  1.17s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  51%|█████     | 700/1384 [13:48<13:20,  1.17s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  51%|█████     | 701/1384 [13:48<13:19,  1.17s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  51%|█████     | 701/1384 [13:49<13:19,  1.17s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  51%|█████     | 702/1384 [13:49<13:18,  1.17s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  51%|█████     | 702/1384 [13:51<13:18,  1.17s/it, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  51%|█████     | 703/1384 [13:51<13:16,  1.17s/it, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  51%|█████     | 703/1384 [13:52<13:16,  1.17s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  51%|█████     | 704/1384 [13:52<13:21,  1.18s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  51%|█████     | 704/1384 [13:53<13:21,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  51%|█████     | 705/1384 [13:53<13:17,  1.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  51%|█████     | 705/1384 [13:54<13:17,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  51%|█████     | 706/1384 [13:54<13:14,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  51%|█████     | 706/1384 [13:55<13:14,  1.17s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  51%|█████     | 707/1384 [13:55<13:11,  1.17s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  51%|█████     | 707/1384 [13:56<13:11,  1.17s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  51%|█████     | 708/1384 [13:56<13:16,  1.18s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  51%|█████     | 708/1384 [13:58<13:16,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  51%|█████     | 709/1384 [13:58<13:11,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  51%|█████     | 709/1384 [13:59<13:11,  1.17s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 710/1384 [13:59<13:09,  1.17s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 710/1384 [14:00<13:09,  1.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 711/1384 [14:00<13:07,  1.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 711/1384 [14:01<13:07,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 712/1384 [14:01<13:06,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 712/1384 [14:02<13:06,  1.17s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 713/1384 [14:02<13:05,  1.17s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 713/1384 [14:03<13:05,  1.17s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 714/1384 [14:03<13:03,  1.17s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 714/1384 [14:05<13:03,  1.17s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 715/1384 [14:05<13:03,  1.17s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 715/1384 [14:06<13:03,  1.17s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 716/1384 [14:06<13:00,  1.17s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 716/1384 [14:07<13:00,  1.17s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 717/1384 [14:07<12:57,  1.17s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 717/1384 [14:08<12:57,  1.17s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 718/1384 [14:08<12:59,  1.17s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 718/1384 [14:09<12:59,  1.17s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 719/1384 [14:09<12:55,  1.17s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 719/1384 [14:11<12:55,  1.17s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 720/1384 [14:11<13:00,  1.17s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 720/1384 [14:12<13:00,  1.17s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 721/1384 [14:12<12:58,  1.17s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 721/1384 [14:13<12:58,  1.17s/it, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 722/1384 [14:13<12:58,  1.18s/it, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 722/1384 [14:14<12:58,  1.18s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 723/1384 [14:14<13:00,  1.18s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 723/1384 [14:15<13:00,  1.18s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 724/1384 [14:15<12:58,  1.18s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 724/1384 [14:16<12:58,  1.18s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 725/1384 [14:16<12:55,  1.18s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 725/1384 [14:18<12:55,  1.18s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 726/1384 [14:18<12:54,  1.18s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 726/1384 [14:19<12:54,  1.18s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 727/1384 [14:19<12:53,  1.18s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 727/1384 [14:20<12:53,  1.18s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 728/1384 [14:20<12:51,  1.18s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 728/1384 [14:21<12:51,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 729/1384 [14:21<12:47,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 729/1384 [14:22<12:47,  1.17s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 730/1384 [14:22<12:48,  1.18s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 730/1384 [14:23<12:48,  1.18s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 731/1384 [14:23<12:46,  1.17s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 731/1384 [14:25<12:46,  1.17s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 732/1384 [14:25<12:53,  1.19s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 732/1384 [14:26<12:53,  1.19s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 733/1384 [14:26<12:55,  1.19s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 733/1384 [14:27<12:55,  1.19s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 734/1384 [14:27<12:51,  1.19s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 734/1384 [14:28<12:51,  1.19s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 735/1384 [14:28<12:46,  1.18s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 735/1384 [14:29<12:46,  1.18s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 736/1384 [14:29<12:46,  1.18s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 736/1384 [14:31<12:46,  1.18s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 737/1384 [14:31<12:43,  1.18s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 737/1384 [14:32<12:43,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 738/1384 [14:32<12:39,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 738/1384 [14:33<12:39,  1.18s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 739/1384 [14:33<12:41,  1.18s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 739/1384 [14:34<12:41,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 740/1384 [14:34<12:40,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 740/1384 [14:35<12:40,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 741/1384 [14:35<12:37,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 741/1384 [14:36<12:37,  1.18s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 742/1384 [14:36<12:37,  1.18s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 742/1384 [14:38<12:37,  1.18s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 743/1384 [14:38<12:35,  1.18s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 743/1384 [14:39<12:35,  1.18s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 744/1384 [14:39<12:37,  1.18s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 744/1384 [14:40<12:37,  1.18s/it, training_loss=0.898]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 745/1384 [14:40<12:32,  1.18s/it, training_loss=0.898]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 745/1384 [14:41<12:32,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 746/1384 [14:41<12:31,  1.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 746/1384 [14:42<12:31,  1.18s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 747/1384 [14:42<12:32,  1.18s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 747/1384 [14:44<12:32,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 748/1384 [14:44<12:34,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 748/1384 [14:45<12:34,  1.19s/it, training_loss=0.480]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 749/1384 [14:45<12:33,  1.19s/it, training_loss=0.480]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 749/1384 [14:46<12:33,  1.19s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 750/1384 [14:46<12:30,  1.18s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 750/1384 [14:47<12:30,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 751/1384 [14:47<12:32,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 751/1384 [14:48<12:32,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 752/1384 [14:48<12:32,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 752/1384 [14:50<12:32,  1.19s/it, training_loss=0.457]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 753/1384 [14:50<12:29,  1.19s/it, training_loss=0.457]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 753/1384 [14:51<12:29,  1.19s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 754/1384 [14:51<12:28,  1.19s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 754/1384 [14:52<12:28,  1.19s/it, training_loss=0.638]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 755/1384 [14:52<12:25,  1.18s/it, training_loss=0.638]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 755/1384 [14:53<12:25,  1.18s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 756/1384 [14:53<12:24,  1.18s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 756/1384 [14:54<12:24,  1.18s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 757/1384 [14:54<12:21,  1.18s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 757/1384 [14:55<12:21,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 758/1384 [14:55<12:18,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 758/1384 [14:57<12:18,  1.18s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 759/1384 [14:57<12:17,  1.18s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 759/1384 [14:58<12:17,  1.18s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 760/1384 [14:58<12:16,  1.18s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 760/1384 [14:59<12:16,  1.18s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 761/1384 [14:59<12:14,  1.18s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 761/1384 [15:00<12:14,  1.18s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 762/1384 [15:00<12:14,  1.18s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 762/1384 [15:01<12:14,  1.18s/it, training_loss=0.665]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 763/1384 [15:01<12:13,  1.18s/it, training_loss=0.665]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 763/1384 [15:03<12:13,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 764/1384 [15:03<12:15,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 764/1384 [15:04<12:15,  1.19s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 765/1384 [15:04<12:14,  1.19s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 765/1384 [15:05<12:14,  1.19s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 766/1384 [15:05<12:12,  1.18s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 766/1384 [15:06<12:12,  1.18s/it, training_loss=0.532]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 767/1384 [15:06<12:11,  1.18s/it, training_loss=0.532]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 767/1384 [15:07<12:11,  1.18s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 768/1384 [15:07<12:09,  1.18s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 768/1384 [15:08<12:09,  1.18s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 769/1384 [15:08<12:07,  1.18s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 769/1384 [15:10<12:07,  1.18s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 770/1384 [15:10<12:05,  1.18s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 770/1384 [15:11<12:05,  1.18s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 771/1384 [15:11<12:04,  1.18s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 771/1384 [15:12<12:04,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 772/1384 [15:12<12:02,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 772/1384 [15:13<12:02,  1.18s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 773/1384 [15:13<12:03,  1.18s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 773/1384 [15:14<12:03,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 774/1384 [15:14<12:01,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 774/1384 [15:16<12:01,  1.18s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 775/1384 [15:16<12:01,  1.18s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 775/1384 [15:17<12:01,  1.18s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 776/1384 [15:17<11:58,  1.18s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 776/1384 [15:18<11:58,  1.18s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 777/1384 [15:18<11:57,  1.18s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 777/1384 [15:19<11:57,  1.18s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 778/1384 [15:19<11:56,  1.18s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 778/1384 [15:20<11:56,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 779/1384 [15:20<11:53,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 779/1384 [15:21<11:53,  1.18s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 780/1384 [15:21<11:53,  1.18s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 780/1384 [15:23<11:53,  1.18s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 781/1384 [15:23<11:52,  1.18s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 781/1384 [15:24<11:52,  1.18s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 782/1384 [15:24<11:51,  1.18s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 782/1384 [15:25<11:51,  1.18s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 783/1384 [15:25<12:04,  1.21s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 783/1384 [15:26<12:04,  1.21s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 784/1384 [15:26<12:03,  1.21s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 784/1384 [15:27<12:03,  1.21s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 785/1384 [15:27<11:59,  1.20s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 785/1384 [15:29<11:59,  1.20s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 786/1384 [15:29<12:00,  1.20s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 786/1384 [15:30<12:00,  1.20s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 787/1384 [15:30<12:06,  1.22s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 787/1384 [15:31<12:06,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 788/1384 [15:31<12:00,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 788/1384 [15:32<12:00,  1.21s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 789/1384 [15:32<11:56,  1.20s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 789/1384 [15:33<11:56,  1.20s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 790/1384 [15:33<11:52,  1.20s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 790/1384 [15:35<11:52,  1.20s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 791/1384 [15:35<11:50,  1.20s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 791/1384 [15:36<11:50,  1.20s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 792/1384 [15:36<11:47,  1.20s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 792/1384 [15:37<11:47,  1.20s/it, training_loss=0.521]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 793/1384 [15:37<11:46,  1.19s/it, training_loss=0.521]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 793/1384 [15:38<11:46,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 794/1384 [15:38<11:43,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 794/1384 [15:39<11:43,  1.19s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 795/1384 [15:39<11:40,  1.19s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 795/1384 [15:41<11:40,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 796/1384 [15:41<11:39,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 796/1384 [15:42<11:39,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 797/1384 [15:42<11:38,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 797/1384 [15:43<11:38,  1.19s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 798/1384 [15:43<11:40,  1.20s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 798/1384 [15:44<11:40,  1.20s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 799/1384 [15:44<11:37,  1.19s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 799/1384 [15:45<11:37,  1.19s/it, training_loss=0.459]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 800/1384 [15:45<11:35,  1.19s/it, training_loss=0.459]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 800/1384 [15:47<11:35,  1.19s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 801/1384 [15:47<11:34,  1.19s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 801/1384 [15:48<11:34,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 802/1384 [15:48<11:34,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 802/1384 [15:49<11:34,  1.19s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 803/1384 [15:49<11:33,  1.19s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 803/1384 [15:50<11:33,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 804/1384 [15:50<11:30,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 804/1384 [15:51<11:30,  1.19s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 805/1384 [15:51<11:30,  1.19s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 805/1384 [15:53<11:30,  1.19s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 806/1384 [15:53<11:29,  1.19s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 806/1384 [15:54<11:29,  1.19s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 807/1384 [15:54<11:28,  1.19s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 807/1384 [15:55<11:28,  1.19s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 808/1384 [15:55<11:25,  1.19s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 808/1384 [15:56<11:25,  1.19s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 809/1384 [15:56<11:25,  1.19s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 809/1384 [15:57<11:25,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 810/1384 [15:57<11:22,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 810/1384 [15:59<11:22,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 811/1384 [15:59<11:31,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 811/1384 [16:00<11:31,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 812/1384 [16:00<11:32,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 812/1384 [16:01<11:32,  1.21s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 813/1384 [16:01<11:30,  1.21s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 813/1384 [16:02<11:30,  1.21s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 814/1384 [16:02<11:28,  1.21s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 814/1384 [16:03<11:28,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 815/1384 [16:03<11:24,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 815/1384 [16:05<11:24,  1.20s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 816/1384 [16:05<11:18,  1.20s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 816/1384 [16:06<11:18,  1.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 817/1384 [16:06<11:17,  1.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 817/1384 [16:07<11:17,  1.20s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 818/1384 [16:07<11:16,  1.20s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 818/1384 [16:08<11:16,  1.20s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 819/1384 [16:08<11:14,  1.19s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 819/1384 [16:09<11:14,  1.19s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 820/1384 [16:09<11:12,  1.19s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 820/1384 [16:11<11:12,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 821/1384 [16:11<11:12,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 821/1384 [16:12<11:12,  1.19s/it, training_loss=0.828]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 822/1384 [16:12<11:11,  1.19s/it, training_loss=0.828]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 822/1384 [16:13<11:11,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 823/1384 [16:13<11:11,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 823/1384 [16:14<11:11,  1.20s/it, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 824/1384 [16:14<11:11,  1.20s/it, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 824/1384 [16:15<11:11,  1.20s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 825/1384 [16:15<11:11,  1.20s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 825/1384 [16:17<11:11,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 826/1384 [16:17<11:08,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 826/1384 [16:18<11:08,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 827/1384 [16:18<11:08,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 827/1384 [16:19<11:08,  1.20s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 828/1384 [16:19<11:07,  1.20s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 828/1384 [16:20<11:07,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 829/1384 [16:20<11:04,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 829/1384 [16:21<11:04,  1.20s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 830/1384 [16:21<11:00,  1.19s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 830/1384 [16:23<11:00,  1.19s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  60%|██████    | 831/1384 [16:23<11:01,  1.20s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  60%|██████    | 831/1384 [16:24<11:01,  1.20s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  60%|██████    | 832/1384 [16:24<11:27,  1.25s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  60%|██████    | 832/1384 [16:25<11:27,  1.25s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  60%|██████    | 833/1384 [16:25<11:25,  1.24s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  60%|██████    | 833/1384 [16:26<11:25,  1.24s/it, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  60%|██████    | 834/1384 [16:26<11:40,  1.27s/it, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  60%|██████    | 834/1384 [16:28<11:40,  1.27s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  60%|██████    | 835/1384 [16:28<11:41,  1.28s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  60%|██████    | 835/1384 [16:29<11:41,  1.28s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  60%|██████    | 836/1384 [16:29<11:50,  1.30s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  60%|██████    | 836/1384 [16:30<11:50,  1.30s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 1:  60%|██████    | 837/1384 [16:30<11:46,  1.29s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 1:  60%|██████    | 837/1384 [16:32<11:46,  1.29s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  61%|██████    | 838/1384 [16:32<11:51,  1.30s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  61%|██████    | 838/1384 [16:33<11:51,  1.30s/it, training_loss=0.621]\u001b[A\n",
      "Epoch 1:  61%|██████    | 839/1384 [16:33<11:45,  1.30s/it, training_loss=0.621]\u001b[A\n",
      "Epoch 1:  61%|██████    | 839/1384 [16:34<11:45,  1.30s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  61%|██████    | 840/1384 [16:34<11:44,  1.30s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  61%|██████    | 840/1384 [16:35<11:44,  1.30s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  61%|██████    | 841/1384 [16:35<11:27,  1.27s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  61%|██████    | 841/1384 [16:37<11:27,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  61%|██████    | 842/1384 [16:37<11:14,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  61%|██████    | 842/1384 [16:38<11:14,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  61%|██████    | 843/1384 [16:38<11:01,  1.22s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  61%|██████    | 843/1384 [16:39<11:01,  1.22s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  61%|██████    | 844/1384 [16:39<10:55,  1.21s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  61%|██████    | 844/1384 [16:40<10:55,  1.21s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  61%|██████    | 845/1384 [16:40<10:50,  1.21s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  61%|██████    | 845/1384 [16:41<10:50,  1.21s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  61%|██████    | 846/1384 [16:41<10:45,  1.20s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  61%|██████    | 846/1384 [16:43<10:45,  1.20s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  61%|██████    | 847/1384 [16:43<10:43,  1.20s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  61%|██████    | 847/1384 [16:44<10:43,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 848/1384 [16:44<10:42,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 848/1384 [16:45<10:42,  1.20s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 849/1384 [16:45<10:40,  1.20s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 849/1384 [16:46<10:40,  1.20s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 850/1384 [16:46<10:38,  1.20s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 850/1384 [16:47<10:38,  1.20s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 851/1384 [16:47<10:35,  1.19s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 851/1384 [16:49<10:35,  1.19s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 852/1384 [16:49<10:35,  1.19s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 852/1384 [16:50<10:35,  1.19s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 853/1384 [16:50<10:33,  1.19s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 853/1384 [16:51<10:33,  1.19s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 854/1384 [16:51<10:33,  1.19s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 854/1384 [16:52<10:33,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 855/1384 [16:52<10:31,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 855/1384 [16:53<10:31,  1.19s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 856/1384 [16:53<10:29,  1.19s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 856/1384 [16:55<10:29,  1.19s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 857/1384 [16:55<10:29,  1.20s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 857/1384 [16:56<10:29,  1.20s/it, training_loss=0.436]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 858/1384 [16:56<10:30,  1.20s/it, training_loss=0.436]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 858/1384 [16:57<10:30,  1.20s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 859/1384 [16:57<10:27,  1.19s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 859/1384 [16:58<10:27,  1.19s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 860/1384 [16:58<10:22,  1.19s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 860/1384 [16:59<10:22,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 861/1384 [16:59<10:23,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 861/1384 [17:00<10:23,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 862/1384 [17:00<10:21,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 862/1384 [17:02<10:21,  1.19s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 863/1384 [17:02<10:23,  1.20s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 863/1384 [17:03<10:23,  1.20s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 864/1384 [17:03<10:21,  1.19s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 864/1384 [17:04<10:21,  1.19s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  62%|██████▎   | 865/1384 [17:04<10:18,  1.19s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  62%|██████▎   | 865/1384 [17:05<10:18,  1.19s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 866/1384 [17:05<10:16,  1.19s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 866/1384 [17:06<10:16,  1.19s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 867/1384 [17:06<10:16,  1.19s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 867/1384 [17:08<10:16,  1.19s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 868/1384 [17:08<10:14,  1.19s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 868/1384 [17:09<10:14,  1.19s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 869/1384 [17:09<10:13,  1.19s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 869/1384 [17:10<10:13,  1.19s/it, training_loss=0.174]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 870/1384 [17:10<10:12,  1.19s/it, training_loss=0.174]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 870/1384 [17:11<10:12,  1.19s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 871/1384 [17:11<10:10,  1.19s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 871/1384 [17:12<10:10,  1.19s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 872/1384 [17:12<10:10,  1.19s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 872/1384 [17:14<10:10,  1.19s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 873/1384 [17:14<10:09,  1.19s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 873/1384 [17:15<10:09,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 874/1384 [17:15<10:08,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 874/1384 [17:16<10:08,  1.19s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 875/1384 [17:16<10:06,  1.19s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 875/1384 [17:17<10:06,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 876/1384 [17:17<10:05,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 876/1384 [17:18<10:05,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 877/1384 [17:18<10:05,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 877/1384 [17:20<10:05,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 878/1384 [17:20<10:05,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 878/1384 [17:21<10:05,  1.20s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 879/1384 [17:21<10:03,  1.20s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 879/1384 [17:22<10:03,  1.20s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 880/1384 [17:22<10:06,  1.20s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 880/1384 [17:23<10:06,  1.20s/it, training_loss=0.532]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 881/1384 [17:23<10:02,  1.20s/it, training_loss=0.532]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 881/1384 [17:24<10:02,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 882/1384 [17:24<10:02,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 882/1384 [17:26<10:02,  1.20s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 883/1384 [17:26<09:58,  1.20s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 883/1384 [17:27<09:58,  1.20s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 884/1384 [17:27<09:57,  1.19s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 884/1384 [17:28<09:57,  1.19s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 885/1384 [17:28<09:55,  1.19s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 885/1384 [17:29<09:55,  1.19s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 886/1384 [17:29<09:55,  1.20s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 886/1384 [17:30<09:55,  1.20s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 887/1384 [17:30<10:02,  1.21s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 887/1384 [17:32<10:02,  1.21s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 888/1384 [17:32<10:01,  1.21s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 888/1384 [17:33<10:01,  1.21s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 889/1384 [17:33<09:57,  1.21s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 889/1384 [17:34<09:57,  1.21s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 890/1384 [17:34<09:50,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 890/1384 [17:35<09:50,  1.20s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 891/1384 [17:35<09:51,  1.20s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 891/1384 [17:36<09:51,  1.20s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 892/1384 [17:36<09:48,  1.20s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 892/1384 [17:38<09:48,  1.20s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 893/1384 [17:38<09:46,  1.19s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 893/1384 [17:39<09:46,  1.19s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 894/1384 [17:39<09:44,  1.19s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 894/1384 [17:40<09:44,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 895/1384 [17:40<09:44,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 895/1384 [17:41<09:44,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 896/1384 [17:41<09:43,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 896/1384 [17:42<09:43,  1.20s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 897/1384 [17:42<09:43,  1.20s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 897/1384 [17:44<09:43,  1.20s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 898/1384 [17:44<09:42,  1.20s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 898/1384 [17:45<09:42,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 899/1384 [17:45<09:41,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 899/1384 [17:46<09:41,  1.20s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 900/1384 [17:46<09:38,  1.20s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 900/1384 [17:47<09:38,  1.20s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 901/1384 [17:47<09:41,  1.20s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 901/1384 [17:48<09:41,  1.20s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 902/1384 [17:48<09:41,  1.21s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 902/1384 [17:50<09:41,  1.21s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 903/1384 [17:50<09:41,  1.21s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 903/1384 [17:51<09:41,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 904/1384 [17:51<09:38,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 904/1384 [17:52<09:38,  1.21s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 905/1384 [17:52<09:36,  1.20s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 905/1384 [17:53<09:36,  1.20s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 906/1384 [17:53<09:36,  1.21s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 906/1384 [17:54<09:36,  1.21s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 907/1384 [17:54<09:34,  1.20s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 907/1384 [17:56<09:34,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 908/1384 [17:56<09:32,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 908/1384 [17:57<09:32,  1.20s/it, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 909/1384 [17:57<09:31,  1.20s/it, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 909/1384 [17:58<09:31,  1.20s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 910/1384 [17:58<09:28,  1.20s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 910/1384 [17:59<09:28,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 911/1384 [17:59<09:25,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 911/1384 [18:00<09:25,  1.20s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 912/1384 [18:00<09:25,  1.20s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 912/1384 [18:02<09:25,  1.20s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 913/1384 [18:02<09:22,  1.19s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 913/1384 [18:03<09:22,  1.19s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 914/1384 [18:03<09:20,  1.19s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 914/1384 [18:04<09:20,  1.19s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 915/1384 [18:04<09:19,  1.19s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 915/1384 [18:05<09:19,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 916/1384 [18:05<09:18,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 916/1384 [18:06<09:18,  1.19s/it, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 917/1384 [18:06<09:16,  1.19s/it, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 917/1384 [18:08<09:16,  1.19s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 918/1384 [18:08<09:22,  1.21s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 918/1384 [18:09<09:22,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 919/1384 [18:09<09:19,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 919/1384 [18:10<09:19,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 920/1384 [18:10<09:16,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 920/1384 [18:11<09:16,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 921/1384 [18:11<09:13,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 921/1384 [18:12<09:13,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 922/1384 [18:12<09:16,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 922/1384 [18:14<09:16,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 923/1384 [18:14<09:15,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 923/1384 [18:15<09:15,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 924/1384 [18:15<09:12,  1.20s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 924/1384 [18:16<09:12,  1.20s/it, training_loss=0.478]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 925/1384 [18:16<09:08,  1.20s/it, training_loss=0.478]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 925/1384 [18:17<09:08,  1.20s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 926/1384 [18:17<09:08,  1.20s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 926/1384 [18:18<09:08,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 927/1384 [18:18<09:08,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 927/1384 [18:20<09:08,  1.20s/it, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 928/1384 [18:20<09:05,  1.20s/it, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 928/1384 [18:21<09:05,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 929/1384 [18:21<09:05,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 929/1384 [18:22<09:05,  1.20s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 930/1384 [18:22<09:03,  1.20s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 930/1384 [18:23<09:03,  1.20s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 931/1384 [18:23<09:02,  1.20s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 931/1384 [18:24<09:02,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 932/1384 [18:24<09:03,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 932/1384 [18:26<09:03,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 933/1384 [18:26<09:01,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 933/1384 [18:27<09:01,  1.20s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 934/1384 [18:27<09:00,  1.20s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 934/1384 [18:28<09:00,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 935/1384 [18:28<08:56,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 935/1384 [18:29<08:56,  1.20s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 936/1384 [18:29<08:57,  1.20s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 936/1384 [18:30<08:57,  1.20s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 937/1384 [18:30<08:56,  1.20s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 937/1384 [18:32<08:56,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 938/1384 [18:32<08:53,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 938/1384 [18:33<08:53,  1.20s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 939/1384 [18:33<08:50,  1.19s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 939/1384 [18:34<08:50,  1.19s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 940/1384 [18:34<08:52,  1.20s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 940/1384 [18:35<08:52,  1.20s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 941/1384 [18:35<08:50,  1.20s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 941/1384 [18:36<08:50,  1.20s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 942/1384 [18:36<08:50,  1.20s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 942/1384 [18:38<08:50,  1.20s/it, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 943/1384 [18:38<08:49,  1.20s/it, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 943/1384 [18:39<08:49,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 944/1384 [18:39<08:47,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 944/1384 [18:40<08:47,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 945/1384 [18:40<08:46,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 945/1384 [18:41<08:46,  1.20s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 946/1384 [18:41<08:44,  1.20s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 946/1384 [18:42<08:44,  1.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 947/1384 [18:42<08:44,  1.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 947/1384 [18:44<08:44,  1.20s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 948/1384 [18:44<08:42,  1.20s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 948/1384 [18:45<08:42,  1.20s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 949/1384 [18:45<08:44,  1.21s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 949/1384 [18:46<08:44,  1.21s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 950/1384 [18:46<08:49,  1.22s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 950/1384 [18:47<08:49,  1.22s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 951/1384 [18:47<08:46,  1.22s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 951/1384 [18:48<08:46,  1.22s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 952/1384 [18:48<08:44,  1.21s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 952/1384 [18:50<08:44,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 953/1384 [18:50<08:43,  1.22s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 953/1384 [18:51<08:43,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 954/1384 [18:51<08:41,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 954/1384 [18:52<08:41,  1.21s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 955/1384 [18:52<08:46,  1.23s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 955/1384 [18:53<08:46,  1.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 956/1384 [18:53<09:01,  1.26s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 956/1384 [18:55<09:01,  1.26s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 957/1384 [18:55<08:58,  1.26s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 957/1384 [18:56<08:58,  1.26s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 958/1384 [18:56<09:06,  1.28s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 958/1384 [18:57<09:06,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 959/1384 [18:57<08:55,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 959/1384 [18:58<08:55,  1.26s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 960/1384 [18:58<08:49,  1.25s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 960/1384 [19:00<08:49,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 961/1384 [19:00<08:57,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 961/1384 [19:01<08:57,  1.27s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 962/1384 [19:01<08:59,  1.28s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 962/1384 [19:02<08:59,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 963/1384 [19:02<09:00,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 963/1384 [19:04<09:00,  1.28s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 964/1384 [19:04<09:05,  1.30s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 964/1384 [19:05<09:05,  1.30s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 965/1384 [19:05<09:05,  1.30s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 965/1384 [19:06<09:05,  1.30s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 966/1384 [19:06<09:11,  1.32s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 966/1384 [19:08<09:11,  1.32s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 967/1384 [19:08<09:36,  1.38s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 967/1384 [19:09<09:36,  1.38s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 968/1384 [19:09<09:28,  1.37s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 968/1384 [19:11<09:28,  1.37s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  70%|███████   | 969/1384 [19:11<09:21,  1.35s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  70%|███████   | 969/1384 [19:12<09:21,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  70%|███████   | 970/1384 [19:12<09:17,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  70%|███████   | 970/1384 [19:13<09:17,  1.35s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  70%|███████   | 971/1384 [19:13<09:03,  1.32s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  70%|███████   | 971/1384 [19:14<09:03,  1.32s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  70%|███████   | 972/1384 [19:14<08:50,  1.29s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  70%|███████   | 972/1384 [19:16<08:50,  1.29s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  70%|███████   | 973/1384 [19:16<08:38,  1.26s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  70%|███████   | 973/1384 [19:17<08:38,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  70%|███████   | 974/1384 [19:17<08:33,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  70%|███████   | 974/1384 [19:18<08:33,  1.25s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  70%|███████   | 975/1384 [19:18<08:25,  1.24s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  70%|███████   | 975/1384 [19:19<08:25,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████   | 976/1384 [19:19<08:22,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████   | 976/1384 [19:20<08:22,  1.23s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  71%|███████   | 977/1384 [19:20<08:22,  1.23s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  71%|███████   | 977/1384 [19:22<08:22,  1.23s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  71%|███████   | 978/1384 [19:22<08:23,  1.24s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  71%|███████   | 978/1384 [19:23<08:23,  1.24s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  71%|███████   | 979/1384 [19:23<08:21,  1.24s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  71%|███████   | 979/1384 [19:24<08:21,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  71%|███████   | 980/1384 [19:24<08:19,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  71%|███████   | 980/1384 [19:25<08:19,  1.24s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  71%|███████   | 981/1384 [19:25<08:16,  1.23s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  71%|███████   | 981/1384 [19:27<08:16,  1.23s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  71%|███████   | 982/1384 [19:27<08:19,  1.24s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  71%|███████   | 982/1384 [19:28<08:19,  1.24s/it, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  71%|███████   | 983/1384 [19:28<08:18,  1.24s/it, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  71%|███████   | 983/1384 [19:29<08:18,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████   | 984/1384 [19:29<08:12,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████   | 984/1384 [19:30<08:12,  1.23s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  71%|███████   | 985/1384 [19:30<08:17,  1.25s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  71%|███████   | 985/1384 [19:32<08:17,  1.25s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 986/1384 [19:32<08:18,  1.25s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 986/1384 [19:33<08:18,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 987/1384 [19:33<08:24,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 987/1384 [19:34<08:24,  1.27s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 988/1384 [19:34<08:19,  1.26s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 988/1384 [19:35<08:19,  1.26s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 989/1384 [19:35<08:16,  1.26s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 989/1384 [19:37<08:16,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 990/1384 [19:37<08:17,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 990/1384 [19:38<08:17,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 991/1384 [19:38<08:18,  1.27s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 991/1384 [19:39<08:18,  1.27s/it, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 992/1384 [19:39<08:16,  1.27s/it, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 992/1384 [19:41<08:16,  1.27s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 993/1384 [19:41<08:16,  1.27s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 993/1384 [19:42<08:16,  1.27s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 994/1384 [19:42<08:17,  1.27s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 994/1384 [19:43<08:17,  1.27s/it, training_loss=0.585]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 995/1384 [19:43<08:10,  1.26s/it, training_loss=0.585]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 995/1384 [19:44<08:10,  1.26s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 996/1384 [19:44<08:06,  1.25s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 996/1384 [19:46<08:06,  1.25s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 997/1384 [19:46<07:59,  1.24s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 997/1384 [19:47<07:59,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 998/1384 [19:47<08:02,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 998/1384 [19:48<08:02,  1.25s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 999/1384 [19:48<08:06,  1.26s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 999/1384 [19:49<08:06,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1000/1384 [19:49<08:08,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1000/1384 [19:51<08:08,  1.27s/it, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1001/1384 [19:51<08:08,  1.28s/it, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1001/1384 [19:52<08:08,  1.28s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1002/1384 [19:52<08:06,  1.27s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1002/1384 [19:53<08:06,  1.27s/it, training_loss=0.424]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1003/1384 [19:53<08:01,  1.26s/it, training_loss=0.424]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 1003/1384 [19:54<08:01,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1004/1384 [19:54<08:00,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1004/1384 [19:56<08:00,  1.26s/it, training_loss=0.440]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1005/1384 [19:56<07:54,  1.25s/it, training_loss=0.440]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1005/1384 [19:57<07:54,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1006/1384 [19:57<07:50,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1006/1384 [19:58<07:50,  1.25s/it, training_loss=0.478]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1007/1384 [19:58<07:46,  1.24s/it, training_loss=0.478]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1007/1384 [19:59<07:46,  1.24s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1008/1384 [19:59<07:48,  1.25s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1008/1384 [20:01<07:48,  1.25s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1009/1384 [20:01<07:45,  1.24s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1009/1384 [20:02<07:45,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1010/1384 [20:02<07:42,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1010/1384 [20:03<07:42,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1011/1384 [20:03<07:53,  1.27s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1011/1384 [20:04<07:53,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1012/1384 [20:04<07:50,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1012/1384 [20:06<07:50,  1.27s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1013/1384 [20:06<07:46,  1.26s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1013/1384 [20:07<07:46,  1.26s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1014/1384 [20:07<07:42,  1.25s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1014/1384 [20:08<07:42,  1.25s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1015/1384 [20:08<07:43,  1.26s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1015/1384 [20:09<07:43,  1.26s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1016/1384 [20:09<07:38,  1.25s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1016/1384 [20:11<07:38,  1.25s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1017/1384 [20:11<07:32,  1.23s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 1017/1384 [20:12<07:32,  1.23s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  74%|██████▌  | 1018/1384 [20:12<07:32,  1.24s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  74%|██████▌  | 1018/1384 [20:13<07:32,  1.24s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1019/1384 [20:13<07:30,  1.23s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1019/1384 [20:14<07:30,  1.23s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1020/1384 [20:14<07:28,  1.23s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1020/1384 [20:16<07:28,  1.23s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1021/1384 [20:16<07:27,  1.23s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1021/1384 [20:17<07:27,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1022/1384 [20:17<07:35,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1022/1384 [20:18<07:35,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1023/1384 [20:18<07:35,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1023/1384 [20:19<07:35,  1.26s/it, training_loss=0.603]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1024/1384 [20:19<07:33,  1.26s/it, training_loss=0.603]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1024/1384 [20:21<07:33,  1.26s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1025/1384 [20:21<07:29,  1.25s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1025/1384 [20:22<07:29,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1026/1384 [20:22<07:24,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1026/1384 [20:23<07:24,  1.24s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1027/1384 [20:23<07:20,  1.23s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1027/1384 [20:24<07:20,  1.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1028/1384 [20:24<07:19,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1028/1384 [20:26<07:19,  1.24s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1029/1384 [20:26<07:16,  1.23s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1029/1384 [20:27<07:16,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1030/1384 [20:27<07:15,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1030/1384 [20:28<07:15,  1.23s/it, training_loss=0.728]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1031/1384 [20:28<07:17,  1.24s/it, training_loss=0.728]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 1031/1384 [20:29<07:17,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1032/1384 [20:29<07:18,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1032/1384 [20:31<07:18,  1.24s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1033/1384 [20:31<07:14,  1.24s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1033/1384 [20:32<07:14,  1.24s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1034/1384 [20:32<07:17,  1.25s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1034/1384 [20:33<07:17,  1.25s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1035/1384 [20:33<07:14,  1.25s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1035/1384 [20:34<07:14,  1.25s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1036/1384 [20:34<07:15,  1.25s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1036/1384 [20:36<07:15,  1.25s/it, training_loss=0.507]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1037/1384 [20:36<07:22,  1.27s/it, training_loss=0.507]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 1037/1384 [20:37<07:22,  1.27s/it, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1038/1384 [20:37<07:17,  1.26s/it, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1038/1384 [20:38<07:17,  1.26s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1039/1384 [20:38<07:11,  1.25s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1039/1384 [20:39<07:11,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1040/1384 [20:39<07:14,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1040/1384 [20:41<07:14,  1.26s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1041/1384 [20:41<07:17,  1.28s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1041/1384 [20:42<07:17,  1.28s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1042/1384 [20:42<07:15,  1.27s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1042/1384 [20:43<07:15,  1.27s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1043/1384 [20:43<07:09,  1.26s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1043/1384 [20:44<07:09,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1044/1384 [20:44<07:03,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 1044/1384 [20:46<07:03,  1.25s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1045/1384 [20:46<07:05,  1.25s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1045/1384 [20:47<07:05,  1.25s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1046/1384 [20:47<07:06,  1.26s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1046/1384 [20:48<07:06,  1.26s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1047/1384 [20:48<07:02,  1.25s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1047/1384 [20:49<07:02,  1.25s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1048/1384 [20:49<07:04,  1.26s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1048/1384 [20:51<07:04,  1.26s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1049/1384 [20:51<07:03,  1.26s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1049/1384 [20:52<07:03,  1.26s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1050/1384 [20:52<07:00,  1.26s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1050/1384 [20:53<07:00,  1.26s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1051/1384 [20:53<06:58,  1.26s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1051/1384 [20:54<06:58,  1.26s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1052/1384 [20:54<06:58,  1.26s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1052/1384 [20:56<06:58,  1.26s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1053/1384 [20:56<06:56,  1.26s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1053/1384 [20:57<06:56,  1.26s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1054/1384 [20:57<06:56,  1.26s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1054/1384 [20:58<06:56,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1055/1384 [20:58<06:54,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1055/1384 [21:00<06:54,  1.26s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1056/1384 [21:00<06:51,  1.26s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1056/1384 [21:01<06:51,  1.26s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1057/1384 [21:01<06:48,  1.25s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 1057/1384 [21:02<06:48,  1.25s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  76%|██████▉  | 1058/1384 [21:02<06:49,  1.26s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  76%|██████▉  | 1058/1384 [21:03<06:49,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1059/1384 [21:03<06:56,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1059/1384 [21:05<06:56,  1.28s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1060/1384 [21:05<06:53,  1.28s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1060/1384 [21:06<06:53,  1.28s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1061/1384 [21:06<06:48,  1.27s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1061/1384 [21:07<06:48,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1062/1384 [21:07<06:51,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1062/1384 [21:08<06:51,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1063/1384 [21:08<06:44,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1063/1384 [21:10<06:44,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1064/1384 [21:10<06:38,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1064/1384 [21:11<06:38,  1.25s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1065/1384 [21:11<06:35,  1.24s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1065/1384 [21:12<06:35,  1.24s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1066/1384 [21:12<06:35,  1.24s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1066/1384 [21:13<06:35,  1.24s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1067/1384 [21:13<06:35,  1.25s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1067/1384 [21:15<06:35,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1068/1384 [21:15<06:38,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1068/1384 [21:16<06:38,  1.26s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1069/1384 [21:16<06:41,  1.27s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1069/1384 [21:17<06:41,  1.27s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1070/1384 [21:17<06:42,  1.28s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1070/1384 [21:18<06:42,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1071/1384 [21:19<06:40,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1071/1384 [21:20<06:40,  1.28s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1072/1384 [21:20<06:39,  1.28s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 1072/1384 [21:21<06:39,  1.28s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1073/1384 [21:21<06:43,  1.30s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1073/1384 [21:22<06:43,  1.30s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1074/1384 [21:22<06:42,  1.30s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1074/1384 [21:24<06:42,  1.30s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1075/1384 [21:24<06:43,  1.30s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1075/1384 [21:25<06:43,  1.30s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1076/1384 [21:25<06:51,  1.33s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 1076/1384 [21:26<06:51,  1.33s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1077/1384 [21:26<06:46,  1.33s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1077/1384 [21:28<06:46,  1.33s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1078/1384 [21:28<06:39,  1.31s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1078/1384 [21:29<06:39,  1.31s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1079/1384 [21:29<06:36,  1.30s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1079/1384 [21:30<06:36,  1.30s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1080/1384 [21:30<06:35,  1.30s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1080/1384 [21:32<06:35,  1.30s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1081/1384 [21:32<06:29,  1.28s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1081/1384 [21:33<06:29,  1.28s/it, training_loss=0.844]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1082/1384 [21:33<06:27,  1.28s/it, training_loss=0.844]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1082/1384 [21:34<06:27,  1.28s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1083/1384 [21:34<06:22,  1.27s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1083/1384 [21:35<06:22,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1084/1384 [21:35<06:22,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1084/1384 [21:37<06:22,  1.28s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1085/1384 [21:37<06:22,  1.28s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1085/1384 [21:38<06:22,  1.28s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1086/1384 [21:38<06:24,  1.29s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  78%|███████  | 1086/1384 [21:39<06:24,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1087/1384 [21:39<06:20,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1087/1384 [21:40<06:20,  1.28s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1088/1384 [21:40<06:15,  1.27s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1088/1384 [21:42<06:15,  1.27s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1089/1384 [21:42<06:13,  1.27s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1089/1384 [21:43<06:13,  1.27s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1090/1384 [21:43<06:11,  1.26s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1090/1384 [21:44<06:11,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1091/1384 [21:44<06:10,  1.27s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1091/1384 [21:45<06:10,  1.27s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1092/1384 [21:45<06:06,  1.25s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1092/1384 [21:47<06:06,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1093/1384 [21:47<06:02,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1093/1384 [21:48<06:02,  1.25s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1094/1384 [21:48<06:01,  1.25s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1094/1384 [21:49<06:01,  1.25s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1095/1384 [21:49<06:02,  1.26s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 1:  79%|███████  | 1095/1384 [21:50<06:02,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1096/1384 [21:50<05:59,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1096/1384 [21:52<05:59,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1097/1384 [21:52<05:58,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1097/1384 [21:53<05:58,  1.25s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1098/1384 [21:53<05:55,  1.24s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1098/1384 [21:54<05:55,  1.24s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1099/1384 [21:54<05:56,  1.25s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1099/1384 [21:55<05:56,  1.25s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1100/1384 [21:55<05:57,  1.26s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 1100/1384 [21:57<05:57,  1.26s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1101/1384 [21:57<05:55,  1.26s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1101/1384 [21:58<05:55,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1102/1384 [21:58<05:56,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1102/1384 [21:59<05:56,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1103/1384 [21:59<05:53,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1103/1384 [22:01<05:53,  1.26s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1104/1384 [22:01<05:51,  1.26s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1104/1384 [22:02<05:51,  1.26s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1105/1384 [22:02<05:48,  1.25s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1105/1384 [22:03<05:48,  1.25s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1106/1384 [22:03<05:46,  1.25s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1106/1384 [22:04<05:46,  1.25s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1107/1384 [22:04<05:44,  1.24s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1107/1384 [22:05<05:44,  1.24s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1108/1384 [22:05<05:43,  1.24s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1108/1384 [22:07<05:43,  1.24s/it, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1109/1384 [22:07<05:40,  1.24s/it, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1109/1384 [22:08<05:40,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1110/1384 [22:08<05:40,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1110/1384 [22:09<05:40,  1.24s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1111/1384 [22:09<05:38,  1.24s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1111/1384 [22:10<05:38,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1112/1384 [22:10<05:35,  1.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1112/1384 [22:12<05:35,  1.23s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1113/1384 [22:12<05:37,  1.25s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1113/1384 [22:13<05:37,  1.25s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1114/1384 [22:13<05:37,  1.25s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 1114/1384 [22:14<05:37,  1.25s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1115/1384 [22:14<05:35,  1.25s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1115/1384 [22:15<05:35,  1.25s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1116/1384 [22:15<05:33,  1.24s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1116/1384 [22:17<05:33,  1.24s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1117/1384 [22:17<05:33,  1.25s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1117/1384 [22:18<05:33,  1.25s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1118/1384 [22:18<05:30,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1118/1384 [22:19<05:30,  1.24s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1119/1384 [22:19<05:29,  1.24s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1119/1384 [22:20<05:29,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1120/1384 [22:20<05:31,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1120/1384 [22:22<05:31,  1.26s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1121/1384 [22:22<05:32,  1.26s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1121/1384 [22:23<05:32,  1.26s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1122/1384 [22:23<05:30,  1.26s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1122/1384 [22:24<05:30,  1.26s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1123/1384 [22:24<05:30,  1.27s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1123/1384 [22:25<05:30,  1.27s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1124/1384 [22:25<05:28,  1.26s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1124/1384 [22:27<05:28,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1125/1384 [22:27<05:28,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1125/1384 [22:28<05:28,  1.27s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1126/1384 [22:28<05:28,  1.27s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1126/1384 [22:29<05:28,  1.27s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1127/1384 [22:29<05:26,  1.27s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 1127/1384 [22:31<05:26,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1128/1384 [22:31<05:24,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1128/1384 [22:32<05:24,  1.27s/it, training_loss=0.652]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1129/1384 [22:32<05:24,  1.27s/it, training_loss=0.652]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1129/1384 [22:33<05:24,  1.27s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1130/1384 [22:33<05:21,  1.27s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1130/1384 [22:34<05:21,  1.27s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1131/1384 [22:34<05:18,  1.26s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1131/1384 [22:36<05:18,  1.26s/it, training_loss=0.173]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1132/1384 [22:36<05:16,  1.26s/it, training_loss=0.173]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1132/1384 [22:37<05:16,  1.26s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1133/1384 [22:37<05:13,  1.25s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1133/1384 [22:38<05:13,  1.25s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1134/1384 [22:38<05:12,  1.25s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 1134/1384 [22:39<05:12,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1135/1384 [22:39<05:10,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1135/1384 [22:41<05:10,  1.25s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1136/1384 [22:41<05:08,  1.25s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1136/1384 [22:42<05:08,  1.25s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1137/1384 [22:42<05:07,  1.24s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1137/1384 [22:43<05:07,  1.24s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1138/1384 [22:43<05:06,  1.24s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1138/1384 [22:44<05:06,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1139/1384 [22:44<05:05,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1139/1384 [22:46<05:05,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1140/1384 [22:46<05:03,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1140/1384 [22:47<05:03,  1.24s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1141/1384 [22:47<05:02,  1.25s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 1141/1384 [22:48<05:02,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1142/1384 [22:48<05:02,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1142/1384 [22:49<05:02,  1.25s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1143/1384 [22:49<05:01,  1.25s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1143/1384 [22:51<05:01,  1.25s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1144/1384 [22:51<04:59,  1.25s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1144/1384 [22:52<04:59,  1.25s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1145/1384 [22:52<04:56,  1.24s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1145/1384 [22:53<04:56,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1146/1384 [22:53<04:55,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1146/1384 [22:54<04:55,  1.24s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1147/1384 [22:54<04:53,  1.24s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1147/1384 [22:56<04:53,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1148/1384 [22:56<04:52,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1148/1384 [22:57<04:52,  1.24s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1149/1384 [22:57<04:55,  1.26s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1149/1384 [22:58<04:55,  1.26s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1150/1384 [22:58<04:54,  1.26s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1150/1384 [22:59<04:54,  1.26s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1151/1384 [22:59<04:54,  1.27s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1151/1384 [23:01<04:54,  1.27s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1152/1384 [23:01<05:11,  1.34s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1152/1384 [23:02<05:11,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1153/1384 [23:02<05:05,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 1153/1384 [23:03<05:05,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|███████▌ | 1154/1384 [23:03<05:01,  1.31s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|███████▌ | 1154/1384 [23:05<05:01,  1.31s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  83%|███████▌ | 1155/1384 [23:05<04:56,  1.30s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  83%|███████▌ | 1155/1384 [23:06<04:56,  1.30s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1156/1384 [23:06<04:52,  1.28s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1156/1384 [23:07<04:52,  1.28s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1157/1384 [23:07<04:53,  1.29s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1157/1384 [23:09<04:53,  1.29s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1158/1384 [23:09<04:49,  1.28s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1158/1384 [23:10<04:49,  1.28s/it, training_loss=0.688]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1159/1384 [23:10<04:51,  1.29s/it, training_loss=0.688]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1159/1384 [23:11<04:51,  1.29s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1160/1384 [23:11<04:48,  1.29s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1160/1384 [23:12<04:48,  1.29s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1161/1384 [23:12<04:45,  1.28s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1161/1384 [23:14<04:45,  1.28s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1162/1384 [23:14<04:42,  1.27s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1162/1384 [23:15<04:42,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1163/1384 [23:15<04:39,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1163/1384 [23:16<04:39,  1.26s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1164/1384 [23:16<04:35,  1.25s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1164/1384 [23:17<04:35,  1.25s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1165/1384 [23:17<04:32,  1.24s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1165/1384 [23:19<04:32,  1.24s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1166/1384 [23:19<04:33,  1.26s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1166/1384 [23:20<04:33,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1167/1384 [23:20<04:33,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1167/1384 [23:21<04:33,  1.26s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1168/1384 [23:21<04:31,  1.26s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1168/1384 [23:22<04:31,  1.26s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1169/1384 [23:22<04:28,  1.25s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 1169/1384 [23:24<04:28,  1.25s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 1170/1384 [23:24<04:25,  1.24s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 1170/1384 [23:25<04:25,  1.24s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 1171/1384 [23:25<04:23,  1.24s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 1171/1384 [23:26<04:23,  1.24s/it, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 1172/1384 [23:26<04:22,  1.24s/it, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 1172/1384 [23:27<04:22,  1.24s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1173/1384 [23:27<04:20,  1.24s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1173/1384 [23:29<04:20,  1.24s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1174/1384 [23:29<04:19,  1.24s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1174/1384 [23:30<04:19,  1.24s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1175/1384 [23:30<04:17,  1.23s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1175/1384 [23:31<04:17,  1.23s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1176/1384 [23:31<04:17,  1.24s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1176/1384 [23:32<04:17,  1.24s/it, training_loss=0.728]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1177/1384 [23:32<04:16,  1.24s/it, training_loss=0.728]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1177/1384 [23:33<04:16,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1178/1384 [23:33<04:14,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1178/1384 [23:35<04:14,  1.24s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1179/1384 [23:35<04:13,  1.23s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1179/1384 [23:36<04:13,  1.23s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1180/1384 [23:36<04:14,  1.25s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1180/1384 [23:37<04:14,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1181/1384 [23:37<04:11,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1181/1384 [23:38<04:11,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1182/1384 [23:38<04:10,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1182/1384 [23:40<04:10,  1.24s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1183/1384 [23:40<04:08,  1.24s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 1183/1384 [23:41<04:08,  1.24s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1184/1384 [23:41<04:07,  1.24s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1184/1384 [23:42<04:07,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1185/1384 [23:42<04:05,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1185/1384 [23:43<04:05,  1.24s/it, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1186/1384 [23:43<04:04,  1.24s/it, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1186/1384 [23:45<04:04,  1.24s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1187/1384 [23:45<04:03,  1.24s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1187/1384 [23:46<04:03,  1.24s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1188/1384 [23:46<04:01,  1.23s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1188/1384 [23:47<04:01,  1.23s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1189/1384 [23:47<04:00,  1.23s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1189/1384 [23:48<04:00,  1.23s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1190/1384 [23:48<04:01,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1190/1384 [23:50<04:01,  1.25s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1191/1384 [23:50<04:00,  1.25s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 1191/1384 [23:51<04:00,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1192/1384 [23:51<03:58,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1192/1384 [23:52<03:58,  1.24s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1193/1384 [23:52<03:56,  1.24s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1193/1384 [23:53<03:56,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1194/1384 [23:53<03:54,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1194/1384 [23:55<03:54,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1195/1384 [23:55<03:55,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1195/1384 [23:56<03:55,  1.25s/it, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1196/1384 [23:56<03:54,  1.25s/it, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1196/1384 [23:57<03:54,  1.25s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1197/1384 [23:57<03:55,  1.26s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 1197/1384 [23:58<03:55,  1.26s/it, training_loss=0.644]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1198/1384 [23:58<03:56,  1.27s/it, training_loss=0.644]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1198/1384 [24:00<03:56,  1.27s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1199/1384 [24:00<03:55,  1.27s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1199/1384 [24:01<03:55,  1.27s/it, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1200/1384 [24:01<03:56,  1.28s/it, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1200/1384 [24:02<03:56,  1.28s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1201/1384 [24:02<03:57,  1.30s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1201/1384 [24:04<03:57,  1.30s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1202/1384 [24:04<03:58,  1.31s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1202/1384 [24:05<03:58,  1.31s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1203/1384 [24:05<03:56,  1.31s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1203/1384 [24:06<03:56,  1.31s/it, training_loss=0.871]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1204/1384 [24:06<03:54,  1.30s/it, training_loss=0.871]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1204/1384 [24:07<03:54,  1.30s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1205/1384 [24:07<03:52,  1.30s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1205/1384 [24:09<03:52,  1.30s/it, training_loss=0.643]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1206/1384 [24:09<03:48,  1.28s/it, training_loss=0.643]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1206/1384 [24:10<03:48,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1207/1384 [24:10<03:45,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1207/1384 [24:11<03:45,  1.27s/it, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1208/1384 [24:11<03:42,  1.26s/it, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1208/1384 [24:12<03:42,  1.26s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1209/1384 [24:12<03:39,  1.25s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1209/1384 [24:14<03:39,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1210/1384 [24:14<03:37,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 1210/1384 [24:15<03:37,  1.25s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1211/1384 [24:15<03:35,  1.25s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1211/1384 [24:16<03:35,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1212/1384 [24:16<03:33,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1212/1384 [24:17<03:33,  1.24s/it, training_loss=0.173]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1213/1384 [24:17<03:32,  1.24s/it, training_loss=0.173]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1213/1384 [24:19<03:32,  1.24s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1214/1384 [24:19<03:32,  1.25s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1214/1384 [24:20<03:32,  1.25s/it, training_loss=0.440]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1215/1384 [24:20<03:31,  1.25s/it, training_loss=0.440]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1215/1384 [24:21<03:31,  1.25s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1216/1384 [24:21<03:29,  1.25s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1216/1384 [24:22<03:29,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1217/1384 [24:22<03:27,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1217/1384 [24:24<03:27,  1.24s/it, training_loss=0.610]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1218/1384 [24:24<03:25,  1.24s/it, training_loss=0.610]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1218/1384 [24:25<03:25,  1.24s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1219/1384 [24:25<03:25,  1.25s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1219/1384 [24:26<03:25,  1.25s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1220/1384 [24:26<03:25,  1.25s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1220/1384 [24:27<03:25,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1221/1384 [24:27<03:23,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1221/1384 [24:29<03:23,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1222/1384 [24:29<03:22,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1222/1384 [24:30<03:22,  1.25s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1223/1384 [24:30<03:20,  1.24s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1223/1384 [24:31<03:20,  1.24s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1224/1384 [24:31<03:19,  1.25s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 1224/1384 [24:32<03:19,  1.25s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1225/1384 [24:32<03:17,  1.24s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1225/1384 [24:34<03:17,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1226/1384 [24:34<03:16,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1226/1384 [24:35<03:16,  1.24s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1227/1384 [24:35<03:15,  1.24s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1227/1384 [24:36<03:15,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1228/1384 [24:36<03:13,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1228/1384 [24:37<03:13,  1.24s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1229/1384 [24:37<03:12,  1.24s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1229/1384 [24:39<03:12,  1.24s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1230/1384 [24:39<03:11,  1.24s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 1230/1384 [24:40<03:11,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1231/1384 [24:40<03:10,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1231/1384 [24:41<03:10,  1.25s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1232/1384 [24:41<03:10,  1.25s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1232/1384 [24:42<03:10,  1.25s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1233/1384 [24:42<03:09,  1.26s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1233/1384 [24:44<03:09,  1.26s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1234/1384 [24:44<03:08,  1.26s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1234/1384 [24:45<03:08,  1.26s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1235/1384 [24:45<03:07,  1.26s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1235/1384 [24:46<03:07,  1.26s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1236/1384 [24:46<03:07,  1.27s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1236/1384 [24:47<03:07,  1.27s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1237/1384 [24:47<03:06,  1.27s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1237/1384 [24:49<03:06,  1.27s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1238/1384 [24:49<03:05,  1.27s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  89%|████████ | 1238/1384 [24:50<03:05,  1.27s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1239/1384 [24:50<03:04,  1.27s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1239/1384 [24:51<03:04,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1240/1384 [24:51<03:02,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1240/1384 [24:53<03:02,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1241/1384 [24:53<03:01,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1241/1384 [24:54<03:01,  1.27s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1242/1384 [24:54<03:00,  1.27s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1242/1384 [24:55<03:00,  1.27s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1243/1384 [24:55<02:58,  1.26s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1243/1384 [24:56<02:58,  1.26s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1244/1384 [24:56<02:57,  1.27s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1244/1384 [24:58<02:57,  1.27s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1245/1384 [24:58<02:56,  1.27s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1245/1384 [24:59<02:56,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1246/1384 [24:59<02:55,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1246/1384 [25:00<02:55,  1.27s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1247/1384 [25:00<02:53,  1.27s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1247/1384 [25:01<02:53,  1.27s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1248/1384 [25:01<02:52,  1.27s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1248/1384 [25:03<02:52,  1.27s/it, training_loss=0.620]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1249/1384 [25:03<02:50,  1.26s/it, training_loss=0.620]\u001b[A\n",
      "Epoch 1:  90%|████████ | 1249/1384 [25:04<02:50,  1.26s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 1250/1384 [25:04<02:49,  1.26s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 1250/1384 [25:05<02:49,  1.26s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 1251/1384 [25:05<02:47,  1.26s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 1251/1384 [25:06<02:47,  1.26s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 1252/1384 [25:06<02:45,  1.26s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 1252/1384 [25:08<02:45,  1.26s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1253/1384 [25:08<02:43,  1.25s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1253/1384 [25:09<02:43,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1254/1384 [25:09<02:41,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1254/1384 [25:10<02:41,  1.24s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1255/1384 [25:10<02:40,  1.25s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1255/1384 [25:11<02:40,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1256/1384 [25:11<02:38,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1256/1384 [25:13<02:38,  1.24s/it, training_loss=0.136]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1257/1384 [25:13<02:37,  1.24s/it, training_loss=0.136]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1257/1384 [25:14<02:37,  1.24s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1258/1384 [25:14<02:36,  1.24s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1258/1384 [25:15<02:36,  1.24s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1259/1384 [25:15<02:35,  1.25s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1259/1384 [25:16<02:35,  1.25s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1260/1384 [25:16<02:34,  1.24s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1260/1384 [25:18<02:34,  1.24s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1261/1384 [25:18<02:32,  1.24s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1261/1384 [25:19<02:32,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1262/1384 [25:19<02:31,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1262/1384 [25:20<02:31,  1.24s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1263/1384 [25:20<02:30,  1.24s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1263/1384 [25:21<02:30,  1.24s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1264/1384 [25:21<02:29,  1.24s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1264/1384 [25:23<02:29,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1265/1384 [25:23<02:27,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1265/1384 [25:24<02:27,  1.24s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1266/1384 [25:24<02:27,  1.25s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 1266/1384 [25:25<02:27,  1.25s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  92%|████████▏| 1267/1384 [25:25<02:26,  1.25s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  92%|████████▏| 1267/1384 [25:26<02:26,  1.25s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  92%|████████▏| 1268/1384 [25:26<02:25,  1.26s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  92%|████████▏| 1268/1384 [25:28<02:25,  1.26s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1269/1384 [25:28<02:24,  1.26s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1269/1384 [25:29<02:24,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1270/1384 [25:29<02:23,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1270/1384 [25:30<02:23,  1.26s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1271/1384 [25:30<02:23,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1271/1384 [25:31<02:23,  1.27s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1272/1384 [25:31<02:22,  1.27s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1272/1384 [25:33<02:22,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1273/1384 [25:33<02:20,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1273/1384 [25:34<02:20,  1.27s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1274/1384 [25:34<02:19,  1.27s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1274/1384 [25:35<02:19,  1.27s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1275/1384 [25:35<02:18,  1.27s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1275/1384 [25:37<02:18,  1.27s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1276/1384 [25:37<02:17,  1.27s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1276/1384 [25:38<02:17,  1.27s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1277/1384 [25:38<02:16,  1.27s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1277/1384 [25:39<02:16,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1278/1384 [25:39<02:14,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1278/1384 [25:40<02:14,  1.27s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1279/1384 [25:40<02:12,  1.27s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1279/1384 [25:42<02:12,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1280/1384 [25:42<02:11,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 1280/1384 [25:43<02:11,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1281/1384 [25:43<02:09,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1281/1384 [25:44<02:09,  1.26s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1282/1384 [25:44<02:08,  1.26s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1282/1384 [25:45<02:08,  1.26s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1283/1384 [25:45<02:07,  1.26s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1283/1384 [25:47<02:07,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1284/1384 [25:47<02:05,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1284/1384 [25:48<02:05,  1.26s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1285/1384 [25:48<02:03,  1.25s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1285/1384 [25:49<02:03,  1.25s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1286/1384 [25:49<02:02,  1.25s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1286/1384 [25:50<02:02,  1.25s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1287/1384 [25:50<02:01,  1.25s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 1287/1384 [25:52<02:01,  1.25s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1288/1384 [25:52<02:00,  1.25s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1288/1384 [25:53<02:00,  1.25s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1289/1384 [25:53<01:58,  1.25s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1289/1384 [25:54<01:58,  1.25s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1290/1384 [25:54<01:57,  1.25s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1290/1384 [25:55<01:57,  1.25s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1291/1384 [25:55<01:56,  1.25s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1291/1384 [25:57<01:56,  1.25s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1292/1384 [25:57<01:55,  1.26s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1292/1384 [25:58<01:55,  1.26s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1293/1384 [25:58<01:55,  1.27s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1293/1384 [25:59<01:55,  1.27s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1294/1384 [25:59<01:56,  1.29s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 1294/1384 [26:01<01:56,  1.29s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1295/1384 [26:01<01:55,  1.30s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1295/1384 [26:02<01:55,  1.30s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1296/1384 [26:02<01:55,  1.32s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1296/1384 [26:03<01:55,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1297/1384 [26:03<01:56,  1.33s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1297/1384 [26:05<01:56,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1298/1384 [26:05<01:56,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1298/1384 [26:06<01:56,  1.35s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1299/1384 [26:06<01:55,  1.35s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1299/1384 [26:07<01:55,  1.35s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1300/1384 [26:07<01:54,  1.37s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1300/1384 [26:09<01:54,  1.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1301/1384 [26:09<01:53,  1.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1301/1384 [26:10<01:53,  1.37s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1302/1384 [26:10<01:52,  1.37s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1302/1384 [26:12<01:52,  1.37s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1303/1384 [26:12<01:50,  1.37s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1303/1384 [26:13<01:50,  1.37s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1304/1384 [26:13<01:49,  1.36s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1304/1384 [26:14<01:49,  1.36s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1305/1384 [26:14<01:46,  1.35s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1305/1384 [26:16<01:46,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1306/1384 [26:16<01:44,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1306/1384 [26:17<01:44,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1307/1384 [26:17<01:41,  1.32s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 1307/1384 [26:18<01:41,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1308/1384 [26:18<01:39,  1.31s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1308/1384 [26:19<01:39,  1.31s/it, training_loss=0.792]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1309/1384 [26:19<01:37,  1.30s/it, training_loss=0.792]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1309/1384 [26:21<01:37,  1.30s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1310/1384 [26:21<01:35,  1.29s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1310/1384 [26:22<01:35,  1.29s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1311/1384 [26:22<01:33,  1.28s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1311/1384 [26:23<01:33,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1312/1384 [26:23<01:31,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1312/1384 [26:24<01:31,  1.27s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1313/1384 [26:24<01:29,  1.27s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1313/1384 [26:26<01:29,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1314/1384 [26:26<01:28,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1314/1384 [26:27<01:28,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1315/1384 [26:27<01:27,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1315/1384 [26:28<01:27,  1.27s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1316/1384 [26:28<01:25,  1.26s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1316/1384 [26:29<01:25,  1.26s/it, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1317/1384 [26:29<01:24,  1.26s/it, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1317/1384 [26:31<01:24,  1.26s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1318/1384 [26:31<01:23,  1.27s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1318/1384 [26:32<01:23,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1319/1384 [26:32<01:22,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1319/1384 [26:33<01:22,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1320/1384 [26:33<01:22,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1320/1384 [26:35<01:22,  1.29s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1321/1384 [26:35<01:21,  1.30s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 1321/1384 [26:36<01:21,  1.30s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1322/1384 [26:36<01:21,  1.31s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1322/1384 [26:37<01:21,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1323/1384 [26:37<01:21,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1323/1384 [26:39<01:21,  1.33s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1324/1384 [26:39<01:19,  1.33s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1324/1384 [26:40<01:19,  1.33s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1325/1384 [26:40<01:18,  1.33s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1325/1384 [26:41<01:18,  1.33s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1326/1384 [26:41<01:17,  1.34s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 1326/1384 [26:43<01:17,  1.34s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1327/1384 [26:43<01:16,  1.34s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1327/1384 [26:44<01:16,  1.34s/it, training_loss=0.584]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1328/1384 [26:44<01:14,  1.33s/it, training_loss=0.584]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1328/1384 [26:45<01:14,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1329/1384 [26:45<01:12,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1329/1384 [26:47<01:12,  1.32s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1330/1384 [26:47<01:10,  1.31s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1330/1384 [26:48<01:10,  1.31s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1331/1384 [26:48<01:09,  1.30s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1331/1384 [26:49<01:09,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1332/1384 [26:49<01:07,  1.29s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1332/1384 [26:50<01:07,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1333/1384 [26:50<01:05,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1333/1384 [26:52<01:05,  1.28s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1334/1384 [26:52<01:03,  1.27s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1334/1384 [26:53<01:03,  1.27s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1335/1384 [26:53<01:02,  1.27s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 1335/1384 [26:54<01:02,  1.27s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1336/1384 [26:54<01:00,  1.26s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1336/1384 [26:55<01:00,  1.26s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1337/1384 [26:55<00:59,  1.26s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1337/1384 [26:57<00:59,  1.26s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1338/1384 [26:57<00:58,  1.26s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1338/1384 [26:58<00:58,  1.26s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1339/1384 [26:58<00:56,  1.26s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1339/1384 [26:59<00:56,  1.26s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1340/1384 [26:59<00:56,  1.28s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1340/1384 [27:01<00:56,  1.28s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1341/1384 [27:01<00:55,  1.29s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1341/1384 [27:02<00:55,  1.29s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1342/1384 [27:02<00:54,  1.30s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1342/1384 [27:03<00:54,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1343/1384 [27:03<00:53,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1343/1384 [27:05<00:53,  1.31s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1344/1384 [27:05<00:52,  1.32s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1344/1384 [27:06<00:52,  1.32s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1345/1384 [27:06<00:51,  1.33s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 1345/1384 [27:07<00:51,  1.33s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1346/1384 [27:07<00:51,  1.35s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1346/1384 [27:09<00:51,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1347/1384 [27:09<00:49,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1347/1384 [27:10<00:49,  1.35s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1348/1384 [27:10<00:48,  1.34s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1348/1384 [27:11<00:48,  1.34s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1349/1384 [27:11<00:46,  1.34s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  97%|████████▊| 1349/1384 [27:13<00:46,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1350/1384 [27:13<00:45,  1.32s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1350/1384 [27:14<00:45,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1351/1384 [27:14<00:43,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1351/1384 [27:15<00:43,  1.31s/it, training_loss=0.639]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1352/1384 [27:15<00:41,  1.30s/it, training_loss=0.639]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1352/1384 [27:17<00:41,  1.30s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1353/1384 [27:17<00:39,  1.29s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1353/1384 [27:18<00:39,  1.29s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1354/1384 [27:18<00:38,  1.28s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1354/1384 [27:19<00:38,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1355/1384 [27:19<00:36,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1355/1384 [27:20<00:36,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1356/1384 [27:20<00:36,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1356/1384 [27:22<00:36,  1.29s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1357/1384 [27:22<00:34,  1.28s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1357/1384 [27:23<00:34,  1.28s/it, training_loss=0.577]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1358/1384 [27:23<00:33,  1.28s/it, training_loss=0.577]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1358/1384 [27:24<00:33,  1.28s/it, training_loss=0.522]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1359/1384 [27:24<00:31,  1.28s/it, training_loss=0.522]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1359/1384 [27:25<00:31,  1.28s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1360/1384 [27:25<00:30,  1.27s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1360/1384 [27:27<00:30,  1.27s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1361/1384 [27:27<00:29,  1.26s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1361/1384 [27:28<00:29,  1.26s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1362/1384 [27:28<00:27,  1.26s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1362/1384 [27:29<00:27,  1.26s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1363/1384 [27:29<00:26,  1.26s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 1363/1384 [27:30<00:26,  1.26s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  99%|████████▊| 1364/1384 [27:30<00:25,  1.26s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  99%|████████▊| 1364/1384 [27:32<00:25,  1.26s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1365/1384 [27:32<00:23,  1.26s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1365/1384 [27:33<00:23,  1.26s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1366/1384 [27:33<00:22,  1.26s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1366/1384 [27:34<00:22,  1.26s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1367/1384 [27:34<00:21,  1.28s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1367/1384 [27:36<00:21,  1.28s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1368/1384 [27:36<00:20,  1.30s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1368/1384 [27:37<00:20,  1.30s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1369/1384 [27:37<00:19,  1.32s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1369/1384 [27:38<00:19,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1370/1384 [27:38<00:18,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1370/1384 [27:40<00:18,  1.34s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1371/1384 [27:40<00:17,  1.36s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1371/1384 [27:41<00:17,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1372/1384 [27:41<00:16,  1.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1372/1384 [27:43<00:16,  1.37s/it, training_loss=0.563]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1373/1384 [27:43<00:15,  1.37s/it, training_loss=0.563]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1373/1384 [27:44<00:15,  1.37s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1374/1384 [27:44<00:13,  1.36s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1374/1384 [27:45<00:13,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1375/1384 [27:45<00:12,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1375/1384 [27:47<00:12,  1.36s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1376/1384 [27:47<00:10,  1.36s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1376/1384 [27:48<00:10,  1.36s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1377/1384 [27:48<00:09,  1.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 1377/1384 [27:49<00:09,  1.35s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1378/1384 [27:49<00:08,  1.35s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1378/1384 [27:51<00:08,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1379/1384 [27:51<00:06,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1379/1384 [27:52<00:06,  1.34s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1380/1384 [27:52<00:05,  1.33s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1380/1384 [27:53<00:05,  1.33s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1381/1384 [27:53<00:03,  1.33s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1381/1384 [27:55<00:03,  1.33s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1382/1384 [27:55<00:02,  1.31s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1382/1384 [27:56<00:02,  1.31s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1383/1384 [27:56<00:01,  1.31s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 1383/1384 [27:57<00:01,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1: 100%|█████████| 1384/1384 [27:57<00:00,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "  0%|                                                     | 0/2 [27:58<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.478417780343174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 1/2 [28:43<28:43, 1723.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.4112782022830251\n",
      "F1 Score (Weighted): 0.8843301633354589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:   0%|                                         | 0/1384 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                    | 0/1384 [00:01<?, ?it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   0%|            | 1/1384 [00:01<35:52,  1.56s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   0%|            | 1/1384 [00:03<35:52,  1.56s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   0%|            | 2/1384 [00:03<35:20,  1.53s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   0%|            | 2/1384 [00:04<35:20,  1.53s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   0%|            | 3/1384 [00:04<34:13,  1.49s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   0%|            | 3/1384 [00:05<34:13,  1.49s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:   0%|            | 4/1384 [00:05<32:32,  1.41s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:   0%|            | 4/1384 [00:07<32:32,  1.41s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:   0%|            | 5/1384 [00:07<31:17,  1.36s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:   0%|            | 5/1384 [00:08<31:17,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   0%|            | 6/1384 [00:08<30:14,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   0%|            | 6/1384 [00:09<30:14,  1.32s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:   1%|            | 7/1384 [00:09<29:52,  1.30s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:   1%|            | 7/1384 [00:10<29:52,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|            | 8/1384 [00:10<29:24,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|            | 8/1384 [00:11<29:24,  1.28s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   1%|            | 9/1384 [00:11<28:31,  1.25s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   1%|            | 9/1384 [00:13<28:31,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 10/1384 [00:13<27:06,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 10/1384 [00:14<27:06,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 11/1384 [00:14<28:01,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 11/1384 [00:15<28:01,  1.23s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:   1%|           | 12/1384 [00:15<30:29,  1.33s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:   1%|           | 12/1384 [00:17<30:29,  1.33s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 2:   1%|           | 13/1384 [00:17<31:18,  1.37s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 2:   1%|           | 13/1384 [00:18<31:18,  1.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 14/1384 [00:18<31:32,  1.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 14/1384 [00:20<31:32,  1.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 15/1384 [00:20<32:01,  1.40s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   1%|           | 15/1384 [00:21<32:01,  1.40s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:   1%|▏          | 16/1384 [00:21<32:22,  1.42s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:   1%|▏          | 16/1384 [00:23<32:22,  1.42s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:   1%|▏          | 17/1384 [00:23<32:15,  1.42s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:   1%|▏          | 17/1384 [00:24<32:15,  1.42s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:   1%|▏          | 18/1384 [00:24<31:55,  1.40s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:   1%|▏          | 18/1384 [00:25<31:55,  1.40s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 2:   1%|▏          | 19/1384 [00:25<30:52,  1.36s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 2:   1%|▏          | 19/1384 [00:26<30:52,  1.36s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|▏          | 20/1384 [00:26<29:09,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|▏          | 20/1384 [00:27<29:09,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 21/1384 [00:27<27:46,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 21/1384 [00:29<27:46,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   2%|▏          | 22/1384 [00:29<26:56,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   2%|▏          | 22/1384 [00:30<26:56,  1.19s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:   2%|▏          | 23/1384 [00:30<26:24,  1.16s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:   2%|▏          | 23/1384 [00:31<26:24,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 24/1384 [00:31<26:21,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 24/1384 [00:32<26:21,  1.16s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:   2%|▏          | 25/1384 [00:32<26:56,  1.19s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:   2%|▏          | 25/1384 [00:33<26:56,  1.19s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   2%|▏          | 26/1384 [00:33<26:55,  1.19s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   2%|▏          | 26/1384 [00:34<26:55,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   2%|▏          | 27/1384 [00:34<26:19,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   2%|▏          | 27/1384 [00:35<26:19,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 28/1384 [00:35<25:41,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 28/1384 [00:36<25:41,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 29/1384 [00:36<25:03,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏          | 29/1384 [00:37<25:03,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏          | 30/1384 [00:37<24:20,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   2%|▏          | 30/1384 [00:39<24:20,  1.08s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   2%|▏          | 31/1384 [00:39<24:54,  1.10s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   2%|▏          | 31/1384 [00:40<24:54,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▎          | 32/1384 [00:40<25:17,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▎          | 32/1384 [00:41<25:17,  1.12s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:   2%|▎          | 33/1384 [00:41<25:08,  1.12s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:   2%|▎          | 33/1384 [00:42<25:08,  1.12s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   2%|▎          | 34/1384 [00:42<24:37,  1.09s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   2%|▎          | 34/1384 [00:43<24:37,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 35/1384 [00:43<24:51,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 35/1384 [00:44<24:51,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎          | 36/1384 [00:44<24:34,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎          | 36/1384 [00:45<24:34,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 37/1384 [00:45<25:15,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 37/1384 [00:46<25:15,  1.13s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:   3%|▎          | 38/1384 [00:46<24:45,  1.10s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:   3%|▎          | 38/1384 [00:47<24:45,  1.10s/it, training_loss=0.554]\u001b[A\n",
      "Epoch 2:   3%|▎          | 39/1384 [00:47<24:09,  1.08s/it, training_loss=0.554]\u001b[A\n",
      "Epoch 2:   3%|▎          | 39/1384 [00:48<24:09,  1.08s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 2:   3%|▎          | 40/1384 [00:48<23:41,  1.06s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 2:   3%|▎          | 40/1384 [00:49<23:41,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 41/1384 [00:49<23:30,  1.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 41/1384 [00:50<23:30,  1.05s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:   3%|▎          | 42/1384 [00:50<23:24,  1.05s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:   3%|▎          | 42/1384 [00:52<23:24,  1.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 43/1384 [00:52<23:22,  1.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   3%|▎          | 43/1384 [00:53<23:22,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎          | 44/1384 [00:53<24:17,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   3%|▎          | 44/1384 [00:54<24:17,  1.09s/it, training_loss=0.610]\u001b[A\n",
      "Epoch 2:   3%|▎          | 45/1384 [00:54<25:53,  1.16s/it, training_loss=0.610]\u001b[A\n",
      "Epoch 2:   3%|▎          | 45/1384 [00:55<25:53,  1.16s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 2:   3%|▎          | 46/1384 [00:55<25:36,  1.15s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 2:   3%|▎          | 46/1384 [00:56<25:36,  1.15s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 2:   3%|▎          | 47/1384 [00:56<25:02,  1.12s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 2:   3%|▎          | 47/1384 [00:57<25:02,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   3%|▍          | 48/1384 [00:57<24:31,  1.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   3%|▍          | 48/1384 [00:58<24:31,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍          | 49/1384 [00:58<24:15,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍          | 49/1384 [01:00<24:15,  1.09s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   4%|▍          | 50/1384 [01:00<25:27,  1.14s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   4%|▍          | 50/1384 [01:01<25:27,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   4%|▍          | 51/1384 [01:01<26:20,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   4%|▍          | 51/1384 [01:02<26:20,  1.19s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 2:   4%|▍          | 52/1384 [01:02<25:59,  1.17s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 2:   4%|▍          | 52/1384 [01:03<25:59,  1.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   4%|▍          | 53/1384 [01:03<25:50,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   4%|▍          | 53/1384 [01:04<25:50,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   4%|▍          | 54/1384 [01:04<25:36,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   4%|▍          | 54/1384 [01:05<25:36,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   4%|▍          | 55/1384 [01:05<25:26,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   4%|▍          | 55/1384 [01:07<25:26,  1.15s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 2:   4%|▍          | 56/1384 [01:07<24:46,  1.12s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 2:   4%|▍          | 56/1384 [01:08<24:46,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍          | 57/1384 [01:08<24:39,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍          | 57/1384 [01:09<24:39,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍          | 58/1384 [01:09<24:14,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   4%|▍          | 58/1384 [01:10<24:14,  1.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   4%|▍          | 59/1384 [01:10<24:40,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   4%|▍          | 59/1384 [01:11<24:40,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   4%|▍          | 60/1384 [01:11<24:19,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   4%|▍          | 60/1384 [01:12<24:19,  1.10s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:   4%|▍          | 61/1384 [01:12<23:42,  1.08s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:   4%|▍          | 61/1384 [01:13<23:42,  1.08s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 2:   4%|▍          | 62/1384 [01:13<23:17,  1.06s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 2:   4%|▍          | 62/1384 [01:14<23:17,  1.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 63/1384 [01:14<23:10,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 63/1384 [01:15<23:10,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 64/1384 [01:15<22:53,  1.04s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 64/1384 [01:16<22:53,  1.04s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 2:   5%|▌          | 65/1384 [01:16<22:39,  1.03s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 2:   5%|▌          | 65/1384 [01:17<22:39,  1.03s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 66/1384 [01:17<22:38,  1.03s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 66/1384 [01:18<22:38,  1.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 67/1384 [01:18<22:39,  1.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 67/1384 [01:19<22:39,  1.03s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 2:   5%|▌          | 68/1384 [01:19<22:52,  1.04s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 2:   5%|▌          | 68/1384 [01:20<22:52,  1.04s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:   5%|▌          | 69/1384 [01:20<22:58,  1.05s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:   5%|▌          | 69/1384 [01:21<22:58,  1.05s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 2:   5%|▌          | 70/1384 [01:21<22:55,  1.05s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 2:   5%|▌          | 70/1384 [01:23<22:55,  1.05s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:   5%|▌          | 71/1384 [01:23<25:12,  1.15s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:   5%|▌          | 71/1384 [01:24<25:12,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 72/1384 [01:24<26:13,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 72/1384 [01:25<26:13,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 73/1384 [01:25<25:37,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 73/1384 [01:26<25:37,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 74/1384 [01:26<25:13,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 74/1384 [01:27<25:13,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 75/1384 [01:27<24:32,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   5%|▌          | 75/1384 [01:28<24:32,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 76/1384 [01:28<24:05,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌          | 76/1384 [01:29<24:05,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▌          | 77/1384 [01:29<23:48,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▌          | 77/1384 [01:30<23:48,  1.09s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:   6%|▌          | 78/1384 [01:30<23:27,  1.08s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:   6%|▌          | 78/1384 [01:31<23:27,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋          | 79/1384 [01:31<23:10,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋          | 79/1384 [01:32<23:10,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋          | 80/1384 [01:32<22:58,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋          | 80/1384 [01:33<22:58,  1.06s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:   6%|▋          | 81/1384 [01:33<22:50,  1.05s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:   6%|▋          | 81/1384 [01:35<22:50,  1.05s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:   6%|▋          | 82/1384 [01:35<22:44,  1.05s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:   6%|▋          | 82/1384 [01:36<22:44,  1.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋          | 83/1384 [01:36<22:47,  1.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   6%|▋          | 83/1384 [01:37<22:47,  1.05s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 2:   6%|▋          | 84/1384 [01:37<22:39,  1.05s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 2:   6%|▋          | 84/1384 [01:38<22:39,  1.05s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:   6%|▋          | 85/1384 [01:38<22:35,  1.04s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:   6%|▋          | 85/1384 [01:39<22:35,  1.04s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:   6%|▋          | 86/1384 [01:39<22:36,  1.05s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:   6%|▋          | 86/1384 [01:40<22:36,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   6%|▋          | 87/1384 [01:40<22:35,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   6%|▋          | 87/1384 [01:41<22:35,  1.05s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 2:   6%|▋          | 88/1384 [01:41<22:35,  1.05s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 2:   6%|▋          | 88/1384 [01:42<22:35,  1.05s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 2:   6%|▋          | 89/1384 [01:42<22:36,  1.05s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 2:   6%|▋          | 89/1384 [01:43<22:36,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋          | 90/1384 [01:43<24:09,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋          | 90/1384 [01:44<24:09,  1.12s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 2:   7%|▋          | 91/1384 [01:44<25:09,  1.17s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 2:   7%|▋          | 91/1384 [01:45<25:09,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋          | 92/1384 [01:45<24:22,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋          | 92/1384 [01:47<24:22,  1.13s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:   7%|▋          | 93/1384 [01:47<23:55,  1.11s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:   7%|▋          | 93/1384 [01:48<23:55,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋          | 94/1384 [01:48<24:01,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋          | 94/1384 [01:49<24:01,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   7%|▊          | 95/1384 [01:49<25:56,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   7%|▊          | 95/1384 [01:51<25:56,  1.21s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 2:   7%|▊          | 96/1384 [01:51<27:49,  1.30s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 2:   7%|▊          | 96/1384 [01:52<27:49,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▊          | 97/1384 [01:52<26:53,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▊          | 97/1384 [01:53<26:53,  1.25s/it, training_loss=0.388]\u001b[A\n",
      "Epoch 2:   7%|▊          | 98/1384 [01:53<26:57,  1.26s/it, training_loss=0.388]\u001b[A\n",
      "Epoch 2:   7%|▊          | 98/1384 [01:54<26:57,  1.26s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   7%|▊          | 99/1384 [01:54<25:46,  1.20s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   7%|▊          | 99/1384 [01:55<25:46,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋         | 100/1384 [01:55<24:45,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋         | 100/1384 [01:56<24:45,  1.16s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   7%|▋         | 101/1384 [01:56<24:25,  1.14s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   7%|▋         | 101/1384 [01:57<24:25,  1.14s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:   7%|▋         | 102/1384 [01:57<24:07,  1.13s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:   7%|▋         | 102/1384 [01:58<24:07,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 103/1384 [01:58<23:56,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   7%|▋         | 103/1384 [02:00<23:56,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 104/1384 [02:00<23:43,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 104/1384 [02:01<23:43,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 105/1384 [02:01<23:21,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 105/1384 [02:02<23:21,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 106/1384 [02:02<23:03,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 106/1384 [02:03<23:03,  1.08s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 2:   8%|▊         | 107/1384 [02:03<22:55,  1.08s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 2:   8%|▊         | 107/1384 [02:04<22:55,  1.08s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 2:   8%|▊         | 108/1384 [02:04<22:56,  1.08s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 2:   8%|▊         | 108/1384 [02:05<22:56,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 109/1384 [02:05<22:46,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 109/1384 [02:06<22:46,  1.07s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 2:   8%|▊         | 110/1384 [02:06<22:41,  1.07s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 2:   8%|▊         | 110/1384 [02:07<22:41,  1.07s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   8%|▊         | 111/1384 [02:07<22:30,  1.06s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   8%|▊         | 111/1384 [02:08<22:30,  1.06s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 2:   8%|▊         | 112/1384 [02:08<22:28,  1.06s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 2:   8%|▊         | 112/1384 [02:09<22:28,  1.06s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 2:   8%|▊         | 113/1384 [02:09<22:31,  1.06s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 2:   8%|▊         | 113/1384 [02:10<22:31,  1.06s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 2:   8%|▊         | 114/1384 [02:10<22:34,  1.07s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 2:   8%|▊         | 114/1384 [02:11<22:34,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 115/1384 [02:11<22:29,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   8%|▊         | 115/1384 [02:12<22:29,  1.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   8%|▊         | 116/1384 [02:12<22:39,  1.07s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   8%|▊         | 116/1384 [02:14<22:39,  1.07s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   8%|▊         | 117/1384 [02:14<23:39,  1.12s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   8%|▊         | 117/1384 [02:15<23:39,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 118/1384 [02:15<24:56,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 118/1384 [02:16<24:56,  1.18s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:   9%|▊         | 119/1384 [02:16<24:56,  1.18s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:   9%|▊         | 119/1384 [02:17<24:56,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 120/1384 [02:17<24:15,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 120/1384 [02:18<24:15,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▊         | 121/1384 [02:18<23:41,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▊         | 121/1384 [02:19<23:41,  1.13s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   9%|▉         | 122/1384 [02:19<24:36,  1.17s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   9%|▉         | 122/1384 [02:21<24:36,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 123/1384 [02:21<25:25,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 123/1384 [02:22<25:25,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 124/1384 [02:22<25:55,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 124/1384 [02:23<25:55,  1.23s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   9%|▉         | 125/1384 [02:23<25:32,  1.22s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   9%|▉         | 125/1384 [02:24<25:32,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 126/1384 [02:24<24:42,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 126/1384 [02:25<24:42,  1.18s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:   9%|▉         | 127/1384 [02:25<24:02,  1.15s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:   9%|▉         | 127/1384 [02:26<24:02,  1.15s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   9%|▉         | 128/1384 [02:26<23:40,  1.13s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   9%|▉         | 128/1384 [02:28<23:40,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 129/1384 [02:28<23:16,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 129/1384 [02:29<23:16,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 130/1384 [02:29<22:58,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:   9%|▉         | 130/1384 [02:30<22:58,  1.10s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 2:   9%|▉         | 131/1384 [02:30<22:45,  1.09s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 2:   9%|▉         | 131/1384 [02:31<22:45,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 132/1384 [02:31<22:36,  1.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 132/1384 [02:32<22:36,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 133/1384 [02:32<22:25,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 133/1384 [02:33<22:25,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 134/1384 [02:33<22:16,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 134/1384 [02:34<22:16,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 135/1384 [02:34<22:19,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 135/1384 [02:35<22:19,  1.07s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 2:  10%|▉         | 136/1384 [02:35<22:22,  1.08s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 2:  10%|▉         | 136/1384 [02:36<22:22,  1.08s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  10%|▉         | 137/1384 [02:36<22:27,  1.08s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  10%|▉         | 137/1384 [02:37<22:27,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 138/1384 [02:37<22:20,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|▉         | 138/1384 [02:38<22:20,  1.08s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  10%|█         | 139/1384 [02:38<22:17,  1.07s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  10%|█         | 139/1384 [02:39<22:17,  1.07s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 2:  10%|█         | 140/1384 [02:39<22:30,  1.09s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 2:  10%|█         | 140/1384 [02:40<22:30,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 141/1384 [02:40<22:28,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 141/1384 [02:42<22:28,  1.08s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  10%|█         | 142/1384 [02:42<22:25,  1.08s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  10%|█         | 142/1384 [02:43<22:25,  1.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|█         | 143/1384 [02:43<22:46,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|█         | 143/1384 [02:44<22:46,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 144/1384 [02:44<24:40,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  10%|█         | 144/1384 [02:45<24:40,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  10%|█         | 145/1384 [02:45<24:25,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  10%|█         | 145/1384 [02:46<24:25,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 146/1384 [02:46<24:04,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 146/1384 [02:48<24:04,  1.17s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  11%|█         | 147/1384 [02:48<24:03,  1.17s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  11%|█         | 147/1384 [02:49<24:03,  1.17s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  11%|█         | 148/1384 [02:49<24:20,  1.18s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  11%|█         | 148/1384 [02:50<24:20,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 149/1384 [02:50<25:05,  1.22s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 149/1384 [02:51<25:05,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 150/1384 [02:51<24:22,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 150/1384 [02:52<24:22,  1.19s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  11%|█         | 151/1384 [02:52<24:27,  1.19s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  11%|█         | 151/1384 [02:54<24:27,  1.19s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  11%|█         | 152/1384 [02:54<24:34,  1.20s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  11%|█         | 152/1384 [02:55<24:34,  1.20s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  11%|█         | 153/1384 [02:55<24:34,  1.20s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  11%|█         | 153/1384 [02:56<24:34,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 154/1384 [02:56<23:58,  1.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 154/1384 [02:57<23:58,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 155/1384 [02:57<23:25,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█         | 155/1384 [02:58<23:25,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 156/1384 [02:58<22:58,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 156/1384 [02:59<22:58,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 157/1384 [02:59<22:43,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 157/1384 [03:00<22:43,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 158/1384 [03:00<22:32,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 158/1384 [03:01<22:32,  1.10s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 159/1384 [03:01<22:20,  1.09s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 159/1384 [03:02<22:20,  1.09s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 160/1384 [03:02<22:14,  1.09s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 160/1384 [03:04<22:14,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 161/1384 [03:04<22:26,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 161/1384 [03:05<22:26,  1.10s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 162/1384 [03:05<22:21,  1.10s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 162/1384 [03:06<22:21,  1.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 163/1384 [03:06<22:17,  1.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 163/1384 [03:07<22:17,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 164/1384 [03:07<22:32,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 164/1384 [03:08<22:32,  1.11s/it, training_loss=0.499]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 165/1384 [03:08<22:18,  1.10s/it, training_loss=0.499]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 165/1384 [03:09<22:18,  1.10s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 166/1384 [03:09<22:17,  1.10s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 166/1384 [03:10<22:17,  1.10s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 167/1384 [03:10<22:02,  1.09s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 167/1384 [03:11<22:02,  1.09s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 168/1384 [03:11<21:56,  1.08s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 168/1384 [03:12<21:56,  1.08s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 169/1384 [03:12<22:45,  1.12s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 169/1384 [03:14<22:45,  1.12s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 170/1384 [03:14<24:29,  1.21s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 170/1384 [03:15<24:29,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 171/1384 [03:15<24:39,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 171/1384 [03:16<24:39,  1.22s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 172/1384 [03:16<23:50,  1.18s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 172/1384 [03:17<23:50,  1.18s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  12%|█▎        | 173/1384 [03:17<23:17,  1.15s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  12%|█▎        | 173/1384 [03:18<23:17,  1.15s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 174/1384 [03:18<22:45,  1.13s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 174/1384 [03:19<22:45,  1.13s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 175/1384 [03:19<22:21,  1.11s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 175/1384 [03:20<22:21,  1.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 176/1384 [03:20<22:07,  1.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 176/1384 [03:21<22:07,  1.10s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 177/1384 [03:21<21:55,  1.09s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 177/1384 [03:23<21:55,  1.09s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 178/1384 [03:23<21:56,  1.09s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 178/1384 [03:24<21:56,  1.09s/it, training_loss=0.563]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 179/1384 [03:24<21:53,  1.09s/it, training_loss=0.563]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 179/1384 [03:25<21:53,  1.09s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 180/1384 [03:25<21:46,  1.09s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 180/1384 [03:26<21:46,  1.09s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 181/1384 [03:26<21:50,  1.09s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 181/1384 [03:27<21:50,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 182/1384 [03:27<21:47,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 182/1384 [03:28<21:47,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 183/1384 [03:28<21:40,  1.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 183/1384 [03:29<21:40,  1.08s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 184/1384 [03:29<21:40,  1.08s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 184/1384 [03:30<21:40,  1.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 185/1384 [03:30<21:32,  1.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 185/1384 [03:31<21:32,  1.08s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 186/1384 [03:31<21:33,  1.08s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 186/1384 [03:32<21:33,  1.08s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 187/1384 [03:32<21:37,  1.08s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 187/1384 [03:33<21:37,  1.08s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 188/1384 [03:33<21:51,  1.10s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 188/1384 [03:35<21:51,  1.10s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 189/1384 [03:35<21:47,  1.09s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 189/1384 [03:36<21:47,  1.09s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 190/1384 [03:36<21:58,  1.10s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 190/1384 [03:37<21:58,  1.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 191/1384 [03:37<21:56,  1.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 191/1384 [03:38<21:56,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 192/1384 [03:38<22:00,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 192/1384 [03:39<22:00,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 193/1384 [03:39<21:57,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 193/1384 [03:40<21:57,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 194/1384 [03:40<22:02,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 194/1384 [03:41<22:02,  1.11s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 195/1384 [03:41<21:51,  1.10s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 195/1384 [03:42<21:51,  1.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 196/1384 [03:42<21:48,  1.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 196/1384 [03:43<21:48,  1.10s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 197/1384 [03:43<21:39,  1.10s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 197/1384 [03:44<21:39,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 198/1384 [03:44<21:51,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 198/1384 [03:46<21:51,  1.11s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 199/1384 [03:46<21:45,  1.10s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 199/1384 [03:47<21:45,  1.10s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 200/1384 [03:47<21:49,  1.11s/it, training_loss=0.395]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 200/1384 [03:48<21:49,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 201/1384 [03:48<22:11,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 201/1384 [03:49<22:11,  1.13s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 202/1384 [03:49<22:04,  1.12s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 202/1384 [03:50<22:04,  1.12s/it, training_loss=0.438]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 203/1384 [03:50<21:52,  1.11s/it, training_loss=0.438]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 203/1384 [03:51<21:52,  1.11s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 204/1384 [03:51<21:53,  1.11s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 204/1384 [03:52<21:53,  1.11s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 205/1384 [03:52<21:42,  1.10s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 205/1384 [03:53<21:42,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 206/1384 [03:53<21:40,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 206/1384 [03:54<21:40,  1.10s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 207/1384 [03:54<21:39,  1.10s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 207/1384 [03:56<21:39,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 208/1384 [03:56<21:54,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 208/1384 [03:57<21:54,  1.12s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 209/1384 [03:57<21:52,  1.12s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 209/1384 [03:58<21:52,  1.12s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 210/1384 [03:58<21:47,  1.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 210/1384 [03:59<21:47,  1.11s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 211/1384 [03:59<21:37,  1.11s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 211/1384 [04:00<21:37,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 212/1384 [04:00<21:31,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 212/1384 [04:01<21:31,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 213/1384 [04:01<21:34,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 213/1384 [04:02<21:34,  1.11s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 214/1384 [04:02<21:58,  1.13s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 214/1384 [04:04<21:58,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 215/1384 [04:04<22:21,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 215/1384 [04:05<22:21,  1.15s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 216/1384 [04:05<22:07,  1.14s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 216/1384 [04:06<22:07,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 217/1384 [04:06<21:55,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 217/1384 [04:07<21:55,  1.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 218/1384 [04:07<21:44,  1.12s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 218/1384 [04:08<21:44,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 219/1384 [04:08<21:34,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 219/1384 [04:09<21:34,  1.11s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 220/1384 [04:09<21:31,  1.11s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 220/1384 [04:10<21:31,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 221/1384 [04:10<21:23,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 221/1384 [04:11<21:23,  1.10s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 222/1384 [04:11<21:24,  1.11s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 222/1384 [04:12<21:24,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 223/1384 [04:12<21:40,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 223/1384 [04:13<21:40,  1.12s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 224/1384 [04:13<21:37,  1.12s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 224/1384 [04:15<21:37,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 225/1384 [04:15<21:44,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 225/1384 [04:16<21:44,  1.13s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 226/1384 [04:16<21:44,  1.13s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 226/1384 [04:17<21:44,  1.13s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 227/1384 [04:17<21:55,  1.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 227/1384 [04:18<21:55,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 228/1384 [04:18<22:35,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 228/1384 [04:19<22:35,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 229/1384 [04:19<22:56,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 229/1384 [04:21<22:56,  1.19s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 230/1384 [04:21<22:32,  1.17s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 230/1384 [04:22<22:32,  1.17s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 231/1384 [04:22<22:06,  1.15s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 231/1384 [04:23<22:06,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 232/1384 [04:23<21:52,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 232/1384 [04:24<21:52,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 233/1384 [04:24<21:33,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 233/1384 [04:25<21:33,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 234/1384 [04:25<21:19,  1.11s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 234/1384 [04:26<21:19,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 235/1384 [04:26<21:05,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 235/1384 [04:27<21:05,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 236/1384 [04:27<21:03,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 236/1384 [04:28<21:03,  1.10s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 237/1384 [04:28<20:59,  1.10s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 237/1384 [04:29<20:59,  1.10s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 238/1384 [04:29<20:53,  1.09s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 238/1384 [04:30<20:53,  1.09s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 239/1384 [04:30<20:54,  1.10s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 239/1384 [04:31<20:54,  1.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 240/1384 [04:31<20:51,  1.09s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 240/1384 [04:33<20:51,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 241/1384 [04:33<20:56,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 241/1384 [04:34<20:56,  1.10s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 242/1384 [04:34<20:58,  1.10s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 242/1384 [04:35<20:58,  1.10s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 243/1384 [04:35<20:51,  1.10s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 243/1384 [04:36<20:51,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 244/1384 [04:36<20:52,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 244/1384 [04:37<20:52,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 245/1384 [04:37<20:45,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 245/1384 [04:38<20:45,  1.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 246/1384 [04:38<20:42,  1.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 246/1384 [04:39<20:42,  1.09s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 247/1384 [04:39<20:41,  1.09s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 247/1384 [04:40<20:41,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 248/1384 [04:40<20:45,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 248/1384 [04:42<20:45,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 249/1384 [04:42<21:58,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 249/1384 [04:43<21:58,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 250/1384 [04:43<23:06,  1.22s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 250/1384 [04:44<23:06,  1.22s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 251/1384 [04:44<22:45,  1.21s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 251/1384 [04:45<22:45,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 252/1384 [04:45<22:39,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 252/1384 [04:47<22:39,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 253/1384 [04:47<23:46,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 253/1384 [04:48<23:46,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 254/1384 [04:48<24:51,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 254/1384 [04:49<24:51,  1.32s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 255/1384 [04:49<24:07,  1.28s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 255/1384 [04:51<24:07,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 256/1384 [04:51<24:00,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 256/1384 [04:52<24:00,  1.28s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 257/1384 [04:52<24:20,  1.30s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 257/1384 [04:53<24:20,  1.30s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 258/1384 [04:53<23:38,  1.26s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 258/1384 [04:54<23:38,  1.26s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 259/1384 [04:54<22:46,  1.21s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 259/1384 [04:55<22:46,  1.21s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 260/1384 [04:55<22:12,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 260/1384 [04:56<22:12,  1.19s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 261/1384 [04:56<21:39,  1.16s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 261/1384 [04:58<21:39,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 262/1384 [04:58<21:17,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 262/1384 [04:59<21:17,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 263/1384 [04:59<21:01,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 263/1384 [05:00<21:01,  1.13s/it, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 264/1384 [05:00<20:52,  1.12s/it, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 264/1384 [05:01<20:52,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 265/1384 [05:01<20:55,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 265/1384 [05:02<20:55,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 266/1384 [05:02<20:47,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 266/1384 [05:03<20:47,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 267/1384 [05:03<20:45,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 267/1384 [05:04<20:45,  1.12s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 268/1384 [05:04<20:40,  1.11s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 268/1384 [05:05<20:40,  1.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 269/1384 [05:05<20:42,  1.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 269/1384 [05:06<20:42,  1.11s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 270/1384 [05:06<20:37,  1.11s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 270/1384 [05:08<20:37,  1.11s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 271/1384 [05:08<20:37,  1.11s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 271/1384 [05:09<20:37,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 272/1384 [05:09<20:56,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 272/1384 [05:10<20:56,  1.13s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 273/1384 [05:10<20:54,  1.13s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 273/1384 [05:11<20:54,  1.13s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 274/1384 [05:11<20:51,  1.13s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 274/1384 [05:12<20:51,  1.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 275/1384 [05:12<20:51,  1.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 275/1384 [05:13<20:51,  1.13s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 276/1384 [05:13<21:03,  1.14s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 276/1384 [05:14<21:03,  1.14s/it, training_loss=0.449]\u001b[A\n",
      "Epoch 2:  20%|██        | 277/1384 [05:14<21:09,  1.15s/it, training_loss=0.449]\u001b[A\n",
      "Epoch 2:  20%|██        | 277/1384 [05:16<21:09,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 278/1384 [05:16<21:16,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 278/1384 [05:17<21:16,  1.15s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  20%|██        | 279/1384 [05:17<21:12,  1.15s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  20%|██        | 279/1384 [05:18<21:12,  1.15s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  20%|██        | 280/1384 [05:18<21:05,  1.15s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  20%|██        | 280/1384 [05:19<21:05,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 281/1384 [05:19<20:44,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  20%|██        | 281/1384 [05:20<20:44,  1.13s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  20%|██        | 282/1384 [05:20<20:41,  1.13s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  20%|██        | 282/1384 [05:21<20:41,  1.13s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  20%|██        | 283/1384 [05:21<20:42,  1.13s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  20%|██        | 283/1384 [05:22<20:42,  1.13s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  21%|██        | 284/1384 [05:22<20:44,  1.13s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  21%|██        | 284/1384 [05:23<20:44,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 285/1384 [05:23<20:38,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 285/1384 [05:25<20:38,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 286/1384 [05:25<20:28,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 286/1384 [05:26<20:28,  1.12s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  21%|██        | 287/1384 [05:26<20:17,  1.11s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  21%|██        | 287/1384 [05:27<20:17,  1.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  21%|██        | 288/1384 [05:27<20:07,  1.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  21%|██        | 288/1384 [05:28<20:07,  1.10s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  21%|██        | 289/1384 [05:28<20:05,  1.10s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  21%|██        | 289/1384 [05:29<20:05,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 290/1384 [05:29<19:56,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 290/1384 [05:30<19:56,  1.09s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 2:  21%|██        | 291/1384 [05:30<20:00,  1.10s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 2:  21%|██        | 291/1384 [05:31<20:00,  1.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  21%|██        | 292/1384 [05:31<19:53,  1.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  21%|██        | 292/1384 [05:32<19:53,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 293/1384 [05:32<19:49,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  21%|██        | 293/1384 [05:33<19:49,  1.09s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  21%|██        | 294/1384 [05:33<19:53,  1.09s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  21%|██        | 294/1384 [05:34<19:53,  1.09s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 295/1384 [05:34<19:50,  1.09s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 295/1384 [05:35<19:50,  1.09s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 296/1384 [05:35<20:01,  1.10s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 296/1384 [05:37<20:01,  1.10s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 297/1384 [05:37<20:02,  1.11s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 297/1384 [05:38<20:02,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 298/1384 [05:38<20:03,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 298/1384 [05:39<20:03,  1.11s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 299/1384 [05:39<20:03,  1.11s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 299/1384 [05:40<20:03,  1.11s/it, training_loss=0.451]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 300/1384 [05:40<20:02,  1.11s/it, training_loss=0.451]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 300/1384 [05:41<20:02,  1.11s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 301/1384 [05:41<20:14,  1.12s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 301/1384 [05:42<20:14,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 302/1384 [05:42<20:11,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 302/1384 [05:43<20:11,  1.12s/it, training_loss=0.562]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 303/1384 [05:43<20:11,  1.12s/it, training_loss=0.562]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 303/1384 [05:44<20:11,  1.12s/it, training_loss=0.413]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 304/1384 [05:44<20:11,  1.12s/it, training_loss=0.413]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 304/1384 [05:46<20:11,  1.12s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 305/1384 [05:46<22:16,  1.24s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 305/1384 [05:47<22:16,  1.24s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 306/1384 [05:48<23:53,  1.33s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 306/1384 [05:49<23:53,  1.33s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 307/1384 [05:49<23:16,  1.30s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 307/1384 [05:50<23:16,  1.30s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 308/1384 [05:50<22:12,  1.24s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 308/1384 [05:51<22:12,  1.24s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 309/1384 [05:51<21:51,  1.22s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 309/1384 [05:52<21:51,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 310/1384 [05:52<21:24,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 310/1384 [05:53<21:24,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 311/1384 [05:53<21:17,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 311/1384 [05:54<21:17,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 312/1384 [05:54<20:48,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 312/1384 [05:56<20:48,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 313/1384 [05:56<20:28,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 313/1384 [05:57<20:28,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 314/1384 [05:57<20:11,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 314/1384 [05:58<20:11,  1.13s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 315/1384 [05:58<19:59,  1.12s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 315/1384 [05:59<19:59,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 316/1384 [05:59<19:58,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 316/1384 [06:00<19:58,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 317/1384 [06:00<19:55,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 317/1384 [06:01<19:55,  1.12s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 318/1384 [06:01<19:46,  1.11s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 318/1384 [06:02<19:46,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 319/1384 [06:02<20:32,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 319/1384 [06:03<20:32,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 320/1384 [06:03<20:34,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 320/1384 [06:05<20:34,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 321/1384 [06:05<20:34,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 321/1384 [06:06<20:34,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 322/1384 [06:06<20:37,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 322/1384 [06:07<20:37,  1.17s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 323/1384 [06:07<20:22,  1.15s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 323/1384 [06:08<20:22,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 324/1384 [06:08<20:18,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 324/1384 [06:09<20:18,  1.15s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 325/1384 [06:09<20:08,  1.14s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 325/1384 [06:10<20:08,  1.14s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 326/1384 [06:10<20:01,  1.14s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 326/1384 [06:11<20:01,  1.14s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 327/1384 [06:11<19:52,  1.13s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 327/1384 [06:13<19:52,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 328/1384 [06:13<19:48,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 328/1384 [06:14<19:48,  1.13s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 329/1384 [06:14<19:48,  1.13s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 329/1384 [06:15<19:48,  1.13s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 330/1384 [06:15<19:41,  1.12s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 330/1384 [06:16<19:41,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 331/1384 [06:16<19:38,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 331/1384 [06:17<19:38,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 332/1384 [06:17<19:38,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 332/1384 [06:18<19:38,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 333/1384 [06:18<19:36,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 333/1384 [06:19<19:36,  1.12s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 334/1384 [06:19<19:37,  1.12s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 334/1384 [06:20<19:37,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 335/1384 [06:20<19:36,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 335/1384 [06:22<19:36,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 336/1384 [06:22<19:39,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 336/1384 [06:23<19:39,  1.13s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 337/1384 [06:23<19:50,  1.14s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 337/1384 [06:24<19:50,  1.14s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 338/1384 [06:24<20:03,  1.15s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 338/1384 [06:25<20:03,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 339/1384 [06:25<20:16,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 339/1384 [06:26<20:16,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 340/1384 [06:26<20:26,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 340/1384 [06:27<20:26,  1.18s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 341/1384 [06:27<20:34,  1.18s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 341/1384 [06:29<20:34,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 342/1384 [06:29<20:40,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 342/1384 [06:30<20:40,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 343/1384 [06:30<20:43,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 343/1384 [06:31<20:43,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 344/1384 [06:31<20:52,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 344/1384 [06:32<20:52,  1.20s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 345/1384 [06:32<20:51,  1.20s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 345/1384 [06:34<20:51,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 346/1384 [06:34<20:47,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 346/1384 [06:35<20:47,  1.20s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 347/1384 [06:35<20:35,  1.19s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 347/1384 [06:36<20:35,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 348/1384 [06:36<20:23,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 348/1384 [06:37<20:23,  1.18s/it, training_loss=0.672]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 349/1384 [06:37<20:14,  1.17s/it, training_loss=0.672]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 349/1384 [06:38<20:14,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 350/1384 [06:38<19:57,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 350/1384 [06:39<19:57,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 351/1384 [06:39<19:45,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 351/1384 [06:40<19:45,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 352/1384 [06:40<19:27,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 352/1384 [06:41<19:27,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 353/1384 [06:41<19:24,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 353/1384 [06:43<19:24,  1.13s/it, training_loss=0.427]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 354/1384 [06:43<19:20,  1.13s/it, training_loss=0.427]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 354/1384 [06:44<19:20,  1.13s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 355/1384 [06:44<19:11,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 355/1384 [06:45<19:11,  1.12s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 356/1384 [06:45<19:06,  1.12s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 356/1384 [06:46<19:06,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 357/1384 [06:46<19:11,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 357/1384 [06:47<19:11,  1.12s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 358/1384 [06:47<19:07,  1.12s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 358/1384 [06:48<19:07,  1.12s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 359/1384 [06:48<19:00,  1.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 359/1384 [06:49<19:00,  1.11s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 360/1384 [06:49<18:58,  1.11s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 360/1384 [06:50<18:58,  1.11s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 361/1384 [06:50<19:00,  1.11s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 361/1384 [06:51<19:00,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 362/1384 [06:51<18:55,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 362/1384 [06:53<18:55,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 363/1384 [06:53<18:54,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 363/1384 [06:54<18:54,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 364/1384 [06:54<18:55,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 364/1384 [06:55<18:55,  1.11s/it, training_loss=0.695]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 365/1384 [06:55<18:57,  1.12s/it, training_loss=0.695]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 365/1384 [06:56<18:57,  1.12s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 366/1384 [06:56<18:55,  1.12s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 366/1384 [06:57<18:55,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 367/1384 [06:57<18:57,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 367/1384 [06:58<18:57,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 368/1384 [06:58<19:00,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 368/1384 [06:59<19:00,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 369/1384 [06:59<19:10,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 369/1384 [07:00<19:10,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 370/1384 [07:00<19:08,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 370/1384 [07:02<19:08,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 371/1384 [07:02<19:12,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 371/1384 [07:03<19:12,  1.14s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 372/1384 [07:03<19:37,  1.16s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 372/1384 [07:04<19:37,  1.16s/it, training_loss=0.457]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 373/1384 [07:04<19:38,  1.17s/it, training_loss=0.457]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 373/1384 [07:05<19:38,  1.17s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 374/1384 [07:05<19:39,  1.17s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 374/1384 [07:06<19:39,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 375/1384 [07:06<19:33,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 375/1384 [07:08<19:33,  1.16s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 376/1384 [07:08<19:29,  1.16s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 376/1384 [07:09<19:29,  1.16s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 377/1384 [07:09<19:28,  1.16s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 377/1384 [07:10<19:28,  1.16s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 378/1384 [07:10<19:26,  1.16s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 378/1384 [07:11<19:26,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 379/1384 [07:11<19:21,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 379/1384 [07:12<19:21,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 380/1384 [07:12<19:19,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 380/1384 [07:13<19:19,  1.16s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 381/1384 [07:13<19:25,  1.16s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 381/1384 [07:14<19:25,  1.16s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 382/1384 [07:14<19:23,  1.16s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 382/1384 [07:16<19:23,  1.16s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 383/1384 [07:16<19:24,  1.16s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 383/1384 [07:17<19:24,  1.16s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 384/1384 [07:17<19:21,  1.16s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 384/1384 [07:18<19:21,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 385/1384 [07:18<19:21,  1.16s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 385/1384 [07:19<19:21,  1.16s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 386/1384 [07:19<19:11,  1.15s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 386/1384 [07:20<19:11,  1.15s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 387/1384 [07:20<19:03,  1.15s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 387/1384 [07:21<19:03,  1.15s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 388/1384 [07:21<18:58,  1.14s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 388/1384 [07:23<18:58,  1.14s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 389/1384 [07:23<19:00,  1.15s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 389/1384 [07:24<19:00,  1.15s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 390/1384 [07:24<18:58,  1.15s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 390/1384 [07:25<18:58,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 391/1384 [07:25<18:56,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 391/1384 [07:26<18:56,  1.14s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 392/1384 [07:26<18:52,  1.14s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 392/1384 [07:27<18:52,  1.14s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 393/1384 [07:27<18:47,  1.14s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 393/1384 [07:28<18:47,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 394/1384 [07:28<18:45,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 394/1384 [07:29<18:45,  1.14s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 395/1384 [07:29<18:45,  1.14s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 395/1384 [07:30<18:45,  1.14s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 396/1384 [07:30<18:44,  1.14s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 396/1384 [07:32<18:44,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 397/1384 [07:32<18:35,  1.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 397/1384 [07:33<18:35,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 398/1384 [07:33<18:35,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 398/1384 [07:34<18:35,  1.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 399/1384 [07:34<18:32,  1.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 399/1384 [07:35<18:32,  1.13s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 400/1384 [07:35<18:29,  1.13s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 400/1384 [07:36<18:29,  1.13s/it, training_loss=0.739]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 401/1384 [07:36<18:41,  1.14s/it, training_loss=0.739]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 401/1384 [07:37<18:41,  1.14s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 402/1384 [07:37<18:44,  1.14s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 402/1384 [07:38<18:44,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 403/1384 [07:38<18:47,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 403/1384 [07:40<18:47,  1.15s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 404/1384 [07:40<18:51,  1.15s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 404/1384 [07:41<18:51,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 405/1384 [07:41<19:02,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 405/1384 [07:42<19:02,  1.17s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 406/1384 [07:42<19:12,  1.18s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 406/1384 [07:43<19:12,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 407/1384 [07:43<19:23,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 407/1384 [07:44<19:23,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 408/1384 [07:44<19:27,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 408/1384 [07:46<19:27,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 409/1384 [07:46<19:35,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 409/1384 [07:47<19:35,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 410/1384 [07:47<19:42,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 410/1384 [07:48<19:42,  1.21s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 411/1384 [07:48<19:50,  1.22s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 411/1384 [07:49<19:50,  1.22s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 412/1384 [07:49<19:57,  1.23s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 412/1384 [07:51<19:57,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 413/1384 [07:51<19:53,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 413/1384 [07:52<19:53,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 414/1384 [07:52<19:51,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 414/1384 [07:53<19:51,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 415/1384 [07:53<19:41,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 415/1384 [07:54<19:41,  1.22s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  30%|███       | 416/1384 [07:54<19:34,  1.21s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  30%|███       | 416/1384 [07:55<19:34,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  30%|███       | 417/1384 [07:55<19:39,  1.22s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  30%|███       | 417/1384 [07:57<19:39,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 418/1384 [07:57<19:21,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 418/1384 [07:58<19:21,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  30%|███       | 419/1384 [07:58<19:08,  1.19s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  30%|███       | 419/1384 [07:59<19:08,  1.19s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  30%|███       | 420/1384 [07:59<19:05,  1.19s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  30%|███       | 420/1384 [08:00<19:05,  1.19s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  30%|███       | 421/1384 [08:00<18:58,  1.18s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  30%|███       | 421/1384 [08:01<18:58,  1.18s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 2:  30%|███       | 422/1384 [08:01<18:54,  1.18s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 2:  30%|███       | 422/1384 [08:03<18:54,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  31%|███       | 423/1384 [08:03<19:27,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  31%|███       | 423/1384 [08:04<19:27,  1.21s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 2:  31%|███       | 424/1384 [08:04<19:30,  1.22s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 2:  31%|███       | 424/1384 [08:05<19:30,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 425/1384 [08:05<19:29,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 425/1384 [08:06<19:29,  1.22s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  31%|███       | 426/1384 [08:06<19:09,  1.20s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  31%|███       | 426/1384 [08:07<19:09,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 427/1384 [08:07<19:00,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 427/1384 [08:09<19:00,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 428/1384 [08:09<18:53,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 428/1384 [08:10<18:53,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 429/1384 [08:10<18:46,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███       | 429/1384 [08:11<18:46,  1.18s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  31%|███       | 430/1384 [08:11<18:39,  1.17s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  31%|███       | 430/1384 [08:12<18:39,  1.17s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  31%|███       | 431/1384 [08:12<18:44,  1.18s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  31%|███       | 431/1384 [08:13<18:44,  1.18s/it, training_loss=0.597]\u001b[A\n",
      "Epoch 2:  31%|███       | 432/1384 [08:13<18:36,  1.17s/it, training_loss=0.597]\u001b[A\n",
      "Epoch 2:  31%|███       | 432/1384 [08:14<18:36,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 433/1384 [08:14<18:34,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 433/1384 [08:16<18:34,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 434/1384 [08:16<18:25,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 434/1384 [08:17<18:25,  1.16s/it, training_loss=0.412]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 435/1384 [08:17<18:21,  1.16s/it, training_loss=0.412]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 435/1384 [08:18<18:21,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 436/1384 [08:18<18:18,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 436/1384 [08:19<18:18,  1.16s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 437/1384 [08:19<18:13,  1.16s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 437/1384 [08:20<18:13,  1.16s/it, training_loss=0.689]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 438/1384 [08:20<18:09,  1.15s/it, training_loss=0.689]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 438/1384 [08:21<18:09,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 439/1384 [08:21<18:07,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 439/1384 [08:22<18:07,  1.15s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 440/1384 [08:22<18:13,  1.16s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 440/1384 [08:24<18:13,  1.16s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 441/1384 [08:24<18:09,  1.16s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 441/1384 [08:25<18:09,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 442/1384 [08:25<18:11,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 442/1384 [08:26<18:11,  1.16s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 443/1384 [08:26<18:09,  1.16s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 443/1384 [08:27<18:09,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 444/1384 [08:27<18:08,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 444/1384 [08:28<18:08,  1.16s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 445/1384 [08:28<18:33,  1.19s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 445/1384 [08:30<18:33,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 446/1384 [08:30<18:29,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 446/1384 [08:31<18:29,  1.18s/it, training_loss=0.514]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 447/1384 [08:31<18:29,  1.18s/it, training_loss=0.514]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 447/1384 [08:32<18:29,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 448/1384 [08:32<18:30,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 448/1384 [08:33<18:30,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 449/1384 [08:33<19:00,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 449/1384 [08:34<19:00,  1.22s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 450/1384 [08:34<18:50,  1.21s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 450/1384 [08:36<18:50,  1.21s/it, training_loss=0.558]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 451/1384 [08:36<18:42,  1.20s/it, training_loss=0.558]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 451/1384 [08:37<18:42,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 452/1384 [08:37<18:34,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 452/1384 [08:38<18:34,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 453/1384 [08:38<18:45,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 453/1384 [08:39<18:45,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 454/1384 [08:39<18:37,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 454/1384 [08:40<18:37,  1.20s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 455/1384 [08:40<18:34,  1.20s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 455/1384 [08:42<18:34,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 456/1384 [08:42<18:40,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 456/1384 [08:43<18:40,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 457/1384 [08:43<18:39,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 457/1384 [08:44<18:39,  1.21s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 458/1384 [08:44<18:45,  1.22s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 458/1384 [08:45<18:45,  1.22s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 459/1384 [08:45<18:42,  1.21s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 459/1384 [08:46<18:42,  1.21s/it, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 460/1384 [08:46<18:41,  1.21s/it, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 460/1384 [08:48<18:41,  1.21s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 461/1384 [08:48<18:52,  1.23s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 461/1384 [08:49<18:52,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 462/1384 [08:49<18:41,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 462/1384 [08:50<18:41,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 463/1384 [08:50<18:54,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 463/1384 [08:51<18:54,  1.23s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 464/1384 [08:51<18:54,  1.23s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 464/1384 [08:53<18:54,  1.23s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 465/1384 [08:53<18:44,  1.22s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 465/1384 [08:54<18:44,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 466/1384 [08:54<18:50,  1.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 466/1384 [08:55<18:50,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 467/1384 [08:55<18:45,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 467/1384 [08:56<18:45,  1.23s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 468/1384 [08:56<18:26,  1.21s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 468/1384 [08:57<18:26,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 469/1384 [08:57<18:12,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 469/1384 [08:59<18:12,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 470/1384 [08:59<18:04,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 470/1384 [09:00<18:04,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 471/1384 [09:00<18:00,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 471/1384 [09:01<18:00,  1.18s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 472/1384 [09:01<18:01,  1.19s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 472/1384 [09:02<18:01,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 473/1384 [09:02<17:57,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 473/1384 [09:03<17:57,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 474/1384 [09:03<17:58,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 474/1384 [09:05<17:58,  1.19s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 475/1384 [09:05<18:00,  1.19s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 475/1384 [09:06<18:00,  1.19s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 476/1384 [09:06<18:02,  1.19s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 476/1384 [09:07<18:02,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 477/1384 [09:07<18:06,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 477/1384 [09:08<18:06,  1.20s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 478/1384 [09:08<18:08,  1.20s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 478/1384 [09:09<18:08,  1.20s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 479/1384 [09:09<18:20,  1.22s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 479/1384 [09:11<18:20,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 480/1384 [09:11<18:27,  1.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 480/1384 [09:12<18:27,  1.23s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 481/1384 [09:12<18:26,  1.23s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 481/1384 [09:13<18:26,  1.23s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 482/1384 [09:13<18:35,  1.24s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 482/1384 [09:14<18:35,  1.24s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 483/1384 [09:14<18:32,  1.23s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 483/1384 [09:16<18:32,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 484/1384 [09:16<18:29,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 484/1384 [09:17<18:29,  1.23s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 485/1384 [09:17<18:35,  1.24s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 485/1384 [09:18<18:35,  1.24s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 486/1384 [09:18<18:33,  1.24s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 486/1384 [09:19<18:33,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 487/1384 [09:19<18:25,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 487/1384 [09:21<18:25,  1.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 488/1384 [09:21<18:15,  1.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 488/1384 [09:22<18:15,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 489/1384 [09:22<18:06,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 489/1384 [09:23<18:06,  1.21s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 490/1384 [09:23<17:59,  1.21s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 490/1384 [09:24<17:59,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 491/1384 [09:24<17:45,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 491/1384 [09:25<17:45,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 492/1384 [09:25<17:48,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 492/1384 [09:26<17:48,  1.20s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 493/1384 [09:26<17:37,  1.19s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 493/1384 [09:28<17:37,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 494/1384 [09:28<17:55,  1.21s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 494/1384 [09:29<17:55,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 495/1384 [09:29<17:38,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 495/1384 [09:30<17:38,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 496/1384 [09:30<17:27,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 496/1384 [09:31<17:27,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 497/1384 [09:31<17:26,  1.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 497/1384 [09:32<17:26,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 498/1384 [09:32<17:15,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 498/1384 [09:33<17:15,  1.17s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 499/1384 [09:33<17:11,  1.17s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 499/1384 [09:35<17:11,  1.17s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 500/1384 [09:35<17:20,  1.18s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 500/1384 [09:36<17:20,  1.18s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 501/1384 [09:36<17:15,  1.17s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 501/1384 [09:37<17:15,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 502/1384 [09:37<17:46,  1.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 502/1384 [09:39<17:46,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 503/1384 [09:39<18:37,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 503/1384 [09:40<18:37,  1.27s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 504/1384 [09:40<19:27,  1.33s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 504/1384 [09:42<19:27,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 505/1384 [09:42<20:46,  1.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 505/1384 [09:43<20:46,  1.42s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 506/1384 [09:43<21:20,  1.46s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 506/1384 [09:44<21:20,  1.46s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 507/1384 [09:44<20:37,  1.41s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 507/1384 [09:46<20:37,  1.41s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 508/1384 [09:46<19:51,  1.36s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 508/1384 [09:47<19:51,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 509/1384 [09:47<19:25,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 509/1384 [09:48<19:25,  1.33s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 510/1384 [09:48<18:50,  1.29s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 510/1384 [09:49<18:50,  1.29s/it, training_loss=0.565]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 511/1384 [09:49<18:32,  1.27s/it, training_loss=0.565]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 511/1384 [09:51<18:32,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 512/1384 [09:51<18:15,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 512/1384 [09:52<18:15,  1.26s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 513/1384 [09:52<18:02,  1.24s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 513/1384 [09:53<18:02,  1.24s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 514/1384 [09:53<17:58,  1.24s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 514/1384 [09:54<17:58,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 515/1384 [09:54<18:04,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 515/1384 [09:56<18:04,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 516/1384 [09:56<18:40,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 516/1384 [09:57<18:40,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 517/1384 [09:57<19:21,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 517/1384 [09:59<19:21,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 518/1384 [09:59<19:32,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 518/1384 [10:00<19:32,  1.35s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 519/1384 [10:00<19:34,  1.36s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 519/1384 [10:01<19:34,  1.36s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 520/1384 [10:01<19:29,  1.35s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 520/1384 [10:03<19:29,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 521/1384 [10:03<19:11,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 521/1384 [10:04<19:11,  1.33s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 522/1384 [10:04<18:37,  1.30s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 522/1384 [10:05<18:37,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 523/1384 [10:05<18:07,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 523/1384 [10:06<18:07,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 524/1384 [10:06<18:02,  1.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 524/1384 [10:07<18:02,  1.26s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 525/1384 [10:07<17:30,  1.22s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 525/1384 [10:09<17:30,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 526/1384 [10:09<17:20,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 526/1384 [10:10<17:20,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 527/1384 [10:10<19:46,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 527/1384 [10:11<19:46,  1.38s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 528/1384 [10:11<18:43,  1.31s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 528/1384 [10:13<18:43,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 529/1384 [10:13<18:05,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 529/1384 [10:14<18:05,  1.27s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 530/1384 [10:14<18:33,  1.30s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 530/1384 [10:15<18:33,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 531/1384 [10:15<18:25,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 531/1384 [10:16<18:25,  1.30s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 532/1384 [10:16<17:43,  1.25s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 532/1384 [10:18<17:43,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 533/1384 [10:18<17:41,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 533/1384 [10:19<17:41,  1.25s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 534/1384 [10:19<18:09,  1.28s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 534/1384 [10:20<18:09,  1.28s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 535/1384 [10:20<18:19,  1.30s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 535/1384 [10:22<18:19,  1.30s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 536/1384 [10:22<18:24,  1.30s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 536/1384 [10:23<18:24,  1.30s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 537/1384 [10:23<18:28,  1.31s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 537/1384 [10:24<18:28,  1.31s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 538/1384 [10:24<18:24,  1.31s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 538/1384 [10:26<18:24,  1.31s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 539/1384 [10:26<18:28,  1.31s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 539/1384 [10:27<18:28,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 540/1384 [10:27<18:24,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 540/1384 [10:28<18:24,  1.31s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 541/1384 [10:28<18:26,  1.31s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 541/1384 [10:30<18:26,  1.31s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 542/1384 [10:30<18:11,  1.30s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 542/1384 [10:31<18:11,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 543/1384 [10:31<18:07,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 543/1384 [10:32<18:07,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 544/1384 [10:32<17:31,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 544/1384 [10:33<17:31,  1.25s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 545/1384 [10:33<17:18,  1.24s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 545/1384 [10:34<17:18,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 546/1384 [10:34<16:46,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 546/1384 [10:35<16:46,  1.20s/it, training_loss=0.444]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 547/1384 [10:35<16:39,  1.19s/it, training_loss=0.444]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 547/1384 [10:37<16:39,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 548/1384 [10:37<16:27,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 548/1384 [10:38<16:27,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 549/1384 [10:38<16:11,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 549/1384 [10:39<16:11,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 550/1384 [10:39<16:14,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 550/1384 [10:40<16:14,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 551/1384 [10:40<16:24,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 551/1384 [10:41<16:24,  1.18s/it, training_loss=0.413]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 552/1384 [10:41<16:44,  1.21s/it, training_loss=0.413]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 552/1384 [10:43<16:44,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 553/1384 [10:43<16:48,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 553/1384 [10:44<16:48,  1.21s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  40%|████      | 554/1384 [10:44<16:44,  1.21s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  40%|████      | 554/1384 [10:45<16:44,  1.21s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  40%|████      | 555/1384 [10:45<16:36,  1.20s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  40%|████      | 555/1384 [10:46<16:36,  1.20s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  40%|████      | 556/1384 [10:46<17:19,  1.26s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  40%|████      | 556/1384 [10:48<17:19,  1.26s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  40%|████      | 557/1384 [10:48<17:44,  1.29s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  40%|████      | 557/1384 [10:49<17:44,  1.29s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 2:  40%|████      | 558/1384 [10:49<18:03,  1.31s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 2:  40%|████      | 558/1384 [10:50<18:03,  1.31s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  40%|████      | 559/1384 [10:50<17:42,  1.29s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  40%|████      | 559/1384 [10:52<17:42,  1.29s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  40%|████      | 560/1384 [10:52<17:54,  1.30s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  40%|████      | 560/1384 [10:53<17:54,  1.30s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  41%|████      | 561/1384 [10:53<17:57,  1.31s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  41%|████      | 561/1384 [10:54<17:57,  1.31s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  41%|████      | 562/1384 [10:54<17:48,  1.30s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  41%|████      | 562/1384 [10:56<17:48,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████      | 563/1384 [10:56<17:31,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████      | 563/1384 [10:57<17:31,  1.28s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  41%|████      | 564/1384 [10:57<17:17,  1.26s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  41%|████      | 564/1384 [10:58<17:17,  1.26s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  41%|████      | 565/1384 [10:58<17:06,  1.25s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  41%|████      | 565/1384 [10:59<17:06,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 566/1384 [10:59<17:18,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 566/1384 [11:01<17:18,  1.27s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  41%|████      | 567/1384 [11:01<17:39,  1.30s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  41%|████      | 567/1384 [11:02<17:39,  1.30s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  41%|████      | 568/1384 [11:02<18:23,  1.35s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  41%|████      | 568/1384 [11:04<18:23,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 569/1384 [11:04<18:34,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 569/1384 [11:05<18:34,  1.37s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  41%|████      | 570/1384 [11:05<18:04,  1.33s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  41%|████      | 570/1384 [11:06<18:04,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 571/1384 [11:06<18:06,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 571/1384 [11:08<18:06,  1.34s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 572/1384 [11:08<18:11,  1.34s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 572/1384 [11:09<18:11,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 573/1384 [11:09<18:18,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 573/1384 [11:10<18:18,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 574/1384 [11:10<18:15,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 574/1384 [11:11<18:15,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 575/1384 [11:11<17:39,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 575/1384 [11:13<17:39,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 576/1384 [11:13<17:03,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 576/1384 [11:14<17:03,  1.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 577/1384 [11:14<16:22,  1.22s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 577/1384 [11:15<16:22,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 578/1384 [11:15<15:54,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 578/1384 [11:16<15:54,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 579/1384 [11:16<15:34,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 579/1384 [11:17<15:34,  1.16s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 580/1384 [11:17<15:21,  1.15s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 580/1384 [11:18<15:21,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 581/1384 [11:18<15:07,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 581/1384 [11:19<15:07,  1.13s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 582/1384 [11:19<14:56,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 582/1384 [11:20<14:56,  1.12s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 583/1384 [11:20<14:48,  1.11s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 583/1384 [11:21<14:48,  1.11s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 584/1384 [11:21<14:41,  1.10s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 584/1384 [11:23<14:41,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 585/1384 [11:23<14:43,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 585/1384 [11:24<14:43,  1.11s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 586/1384 [11:24<14:35,  1.10s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 586/1384 [11:25<14:35,  1.10s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 587/1384 [11:25<14:28,  1.09s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 587/1384 [11:26<14:28,  1.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 588/1384 [11:26<14:21,  1.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 588/1384 [11:27<14:21,  1.08s/it, training_loss=0.426]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 589/1384 [11:27<14:23,  1.09s/it, training_loss=0.426]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 589/1384 [11:28<14:23,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 590/1384 [11:28<14:18,  1.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 590/1384 [11:29<14:18,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 591/1384 [11:29<14:20,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 591/1384 [11:30<14:20,  1.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 592/1384 [11:30<14:23,  1.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 592/1384 [11:31<14:23,  1.09s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 593/1384 [11:31<14:27,  1.10s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 593/1384 [11:32<14:27,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 594/1384 [11:32<14:24,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 594/1384 [11:33<14:24,  1.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 595/1384 [11:33<14:24,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 595/1384 [11:34<14:24,  1.10s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 596/1384 [11:34<14:26,  1.10s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 596/1384 [11:36<14:26,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 597/1384 [11:36<14:39,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 597/1384 [11:37<14:39,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 598/1384 [11:37<14:44,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 598/1384 [11:38<14:44,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 599/1384 [11:38<14:38,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 599/1384 [11:39<14:38,  1.12s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 600/1384 [11:39<14:38,  1.12s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 600/1384 [11:40<14:38,  1.12s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 601/1384 [11:40<14:31,  1.11s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 601/1384 [11:41<14:31,  1.11s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 602/1384 [11:41<14:54,  1.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 602/1384 [11:43<14:54,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 603/1384 [11:43<15:16,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 603/1384 [11:44<15:16,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 604/1384 [11:44<15:16,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 604/1384 [11:45<15:16,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 605/1384 [11:45<15:06,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 605/1384 [11:46<15:06,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 606/1384 [11:46<15:07,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 606/1384 [11:47<15:07,  1.17s/it, training_loss=0.418]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 607/1384 [11:47<15:27,  1.19s/it, training_loss=0.418]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 607/1384 [11:48<15:27,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 608/1384 [11:48<15:15,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 608/1384 [11:50<15:15,  1.18s/it, training_loss=0.446]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 609/1384 [11:50<15:08,  1.17s/it, training_loss=0.446]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 609/1384 [11:51<15:08,  1.17s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 610/1384 [11:51<15:11,  1.18s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 610/1384 [11:52<15:11,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 611/1384 [11:52<15:51,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 611/1384 [11:54<15:51,  1.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 612/1384 [11:54<16:24,  1.28s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 612/1384 [11:55<16:24,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 613/1384 [11:55<16:05,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 613/1384 [11:56<16:05,  1.25s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 614/1384 [11:56<15:34,  1.21s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 614/1384 [11:57<15:34,  1.21s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 615/1384 [11:57<15:18,  1.19s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 615/1384 [11:58<15:18,  1.19s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 616/1384 [11:58<15:18,  1.20s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 616/1384 [11:59<15:18,  1.20s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 617/1384 [11:59<14:58,  1.17s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 617/1384 [12:00<14:58,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 618/1384 [12:00<14:49,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 618/1384 [12:02<14:49,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 619/1384 [12:02<14:38,  1.15s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 619/1384 [12:03<14:38,  1.15s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 620/1384 [12:03<14:30,  1.14s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 620/1384 [12:04<14:30,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 621/1384 [12:04<14:26,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 621/1384 [12:05<14:26,  1.14s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 622/1384 [12:05<14:21,  1.13s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 622/1384 [12:06<14:21,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 623/1384 [12:06<14:13,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 623/1384 [12:07<14:13,  1.12s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 624/1384 [12:07<14:05,  1.11s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 624/1384 [12:08<14:05,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 625/1384 [12:08<14:02,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 625/1384 [12:09<14:02,  1.11s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 626/1384 [12:09<14:20,  1.14s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 626/1384 [12:11<14:20,  1.14s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 627/1384 [12:11<14:33,  1.15s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 627/1384 [12:12<14:33,  1.15s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 628/1384 [12:12<14:46,  1.17s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 628/1384 [12:13<14:46,  1.17s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 629/1384 [12:13<14:56,  1.19s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 629/1384 [12:14<14:56,  1.19s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 630/1384 [12:14<15:22,  1.22s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 630/1384 [12:16<15:22,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 631/1384 [12:16<15:27,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 631/1384 [12:17<15:27,  1.23s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 632/1384 [12:17<15:18,  1.22s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 632/1384 [12:18<15:18,  1.22s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 633/1384 [12:18<15:14,  1.22s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 633/1384 [12:19<15:14,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 634/1384 [12:19<15:10,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 634/1384 [12:21<15:10,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 635/1384 [12:21<15:27,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 635/1384 [12:22<15:27,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 636/1384 [12:22<15:37,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 636/1384 [12:23<15:37,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 637/1384 [12:23<16:10,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 637/1384 [12:25<16:10,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 638/1384 [12:25<16:09,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 638/1384 [12:26<16:09,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 639/1384 [12:26<15:56,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 639/1384 [12:27<15:56,  1.28s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 640/1384 [12:27<15:56,  1.29s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 640/1384 [12:28<15:56,  1.29s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 641/1384 [12:28<15:44,  1.27s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 641/1384 [12:30<15:44,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 642/1384 [12:30<15:34,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 642/1384 [12:31<15:34,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 643/1384 [12:31<15:15,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 643/1384 [12:32<15:15,  1.24s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 644/1384 [12:32<15:13,  1.23s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 644/1384 [12:33<15:13,  1.23s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 645/1384 [12:33<15:09,  1.23s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 645/1384 [12:34<15:09,  1.23s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 646/1384 [12:34<14:48,  1.20s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 646/1384 [12:36<14:48,  1.20s/it, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 647/1384 [12:36<15:08,  1.23s/it, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 647/1384 [12:37<15:08,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 648/1384 [12:37<15:04,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 648/1384 [12:38<15:04,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 649/1384 [12:38<14:46,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 649/1384 [12:39<14:46,  1.21s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 650/1384 [12:39<14:37,  1.20s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 650/1384 [12:40<14:37,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 651/1384 [12:40<14:25,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 651/1384 [12:41<14:25,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 652/1384 [12:41<14:02,  1.15s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 652/1384 [12:43<14:02,  1.15s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 653/1384 [12:43<13:51,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 653/1384 [12:44<13:51,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 654/1384 [12:44<13:55,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 654/1384 [12:45<13:55,  1.15s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 655/1384 [12:45<14:05,  1.16s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 655/1384 [12:46<14:05,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 656/1384 [12:46<14:01,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 656/1384 [12:47<14:01,  1.16s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 657/1384 [12:47<14:05,  1.16s/it, training_loss=0.404]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 657/1384 [12:48<14:05,  1.16s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 658/1384 [12:48<14:09,  1.17s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 658/1384 [12:50<14:09,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 659/1384 [12:50<14:33,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 659/1384 [12:51<14:33,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 660/1384 [12:51<15:07,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 660/1384 [12:52<15:07,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 661/1384 [12:52<15:43,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 661/1384 [12:54<15:43,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 662/1384 [12:54<16:11,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 662/1384 [12:55<16:11,  1.34s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 663/1384 [12:55<16:27,  1.37s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 663/1384 [12:57<16:27,  1.37s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 664/1384 [12:57<16:44,  1.39s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 664/1384 [12:58<16:44,  1.39s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 665/1384 [12:58<16:56,  1.41s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 665/1384 [13:00<16:56,  1.41s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 666/1384 [13:00<17:04,  1.43s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 666/1384 [13:01<17:04,  1.43s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 667/1384 [13:01<17:03,  1.43s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 667/1384 [13:03<17:03,  1.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 668/1384 [13:03<17:07,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 668/1384 [13:04<17:07,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 669/1384 [13:04<17:11,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 669/1384 [13:05<17:11,  1.44s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 670/1384 [13:05<17:10,  1.44s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 670/1384 [13:07<17:10,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 671/1384 [13:07<16:55,  1.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 671/1384 [13:08<16:55,  1.42s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 672/1384 [13:08<16:39,  1.40s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 672/1384 [13:10<16:39,  1.40s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 673/1384 [13:10<16:23,  1.38s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 673/1384 [13:11<16:23,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 674/1384 [13:11<16:05,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 674/1384 [13:12<16:05,  1.36s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 675/1384 [13:12<15:53,  1.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 675/1384 [13:13<15:53,  1.34s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 676/1384 [13:13<15:45,  1.33s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 676/1384 [13:15<15:45,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 677/1384 [13:15<15:37,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 677/1384 [13:16<15:37,  1.33s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 678/1384 [13:16<15:22,  1.31s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 678/1384 [13:17<15:22,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 679/1384 [13:17<15:13,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 679/1384 [13:19<15:13,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 680/1384 [13:19<15:09,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 680/1384 [13:20<15:09,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 681/1384 [13:20<15:10,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 681/1384 [13:21<15:10,  1.30s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 682/1384 [13:21<15:05,  1.29s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 682/1384 [13:22<15:05,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 683/1384 [13:22<15:05,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 683/1384 [13:24<15:05,  1.29s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 684/1384 [13:24<15:09,  1.30s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 684/1384 [13:25<15:09,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 685/1384 [13:25<15:09,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 685/1384 [13:26<15:09,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 686/1384 [13:26<15:13,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 686/1384 [13:28<15:13,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 687/1384 [13:28<15:18,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 687/1384 [13:29<15:18,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 688/1384 [13:29<15:18,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 688/1384 [13:30<15:18,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 689/1384 [13:30<15:20,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 689/1384 [13:32<15:20,  1.33s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 690/1384 [13:32<15:22,  1.33s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 690/1384 [13:33<15:22,  1.33s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 691/1384 [13:33<15:30,  1.34s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 691/1384 [13:35<15:30,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 692/1384 [13:35<15:44,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 692/1384 [13:36<15:44,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 693/1384 [13:36<15:39,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 693/1384 [13:37<15:39,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 694/1384 [13:37<15:35,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 694/1384 [13:39<15:35,  1.36s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  50%|█████     | 695/1384 [13:39<15:29,  1.35s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  50%|█████     | 695/1384 [13:40<15:29,  1.35s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  50%|█████     | 696/1384 [13:40<15:23,  1.34s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  50%|█████     | 696/1384 [13:41<15:23,  1.34s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  50%|█████     | 697/1384 [13:41<15:19,  1.34s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  50%|█████     | 697/1384 [13:43<15:19,  1.34s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  50%|█████     | 698/1384 [13:43<15:12,  1.33s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  50%|█████     | 698/1384 [13:44<15:12,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 699/1384 [13:44<15:05,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 699/1384 [13:45<15:05,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  51%|█████     | 700/1384 [13:45<15:04,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  51%|█████     | 700/1384 [13:46<15:04,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  51%|█████     | 701/1384 [13:46<14:59,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  51%|█████     | 701/1384 [13:48<14:59,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 702/1384 [13:48<14:47,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 702/1384 [13:49<14:47,  1.30s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  51%|█████     | 703/1384 [13:49<14:38,  1.29s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  51%|█████     | 703/1384 [13:50<14:38,  1.29s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  51%|█████     | 704/1384 [13:50<14:35,  1.29s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  51%|█████     | 704/1384 [13:52<14:35,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 705/1384 [13:52<14:32,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 705/1384 [13:53<14:32,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 706/1384 [13:53<14:32,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 706/1384 [13:54<14:32,  1.29s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 2:  51%|█████     | 707/1384 [13:54<14:35,  1.29s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 2:  51%|█████     | 707/1384 [13:55<14:35,  1.29s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 2:  51%|█████     | 708/1384 [13:55<14:37,  1.30s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 2:  51%|█████     | 708/1384 [13:57<14:37,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 709/1384 [13:57<14:40,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 709/1384 [13:58<14:40,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 710/1384 [13:58<14:45,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 710/1384 [14:00<14:45,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 711/1384 [14:00<15:11,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 711/1384 [14:01<15:11,  1.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 712/1384 [14:01<15:25,  1.38s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 712/1384 [14:02<15:25,  1.38s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 713/1384 [14:02<15:24,  1.38s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 713/1384 [14:04<15:24,  1.38s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 714/1384 [14:04<14:39,  1.31s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 714/1384 [14:05<14:39,  1.31s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 715/1384 [14:05<14:21,  1.29s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 715/1384 [14:06<14:21,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 716/1384 [14:06<13:52,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 716/1384 [14:07<13:52,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 717/1384 [14:07<13:15,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 717/1384 [14:08<13:15,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 718/1384 [14:08<12:51,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 718/1384 [14:09<12:51,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 719/1384 [14:09<12:36,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 719/1384 [14:10<12:36,  1.14s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 720/1384 [14:10<12:57,  1.17s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 720/1384 [14:12<12:57,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 721/1384 [14:12<13:53,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 721/1384 [14:13<13:53,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 722/1384 [14:13<13:22,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 722/1384 [14:14<13:22,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 723/1384 [14:14<12:53,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 723/1384 [14:15<12:53,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 724/1384 [14:15<12:54,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 724/1384 [14:16<12:54,  1.17s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 725/1384 [14:16<12:57,  1.18s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 725/1384 [14:18<12:57,  1.18s/it, training_loss=0.422]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 726/1384 [14:18<12:44,  1.16s/it, training_loss=0.422]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 726/1384 [14:19<12:44,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 727/1384 [14:19<12:38,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 727/1384 [14:20<12:38,  1.15s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 728/1384 [14:20<12:43,  1.16s/it, training_loss=0.414]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 728/1384 [14:21<12:43,  1.16s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 729/1384 [14:21<12:35,  1.15s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 729/1384 [14:22<12:35,  1.15s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 730/1384 [14:22<12:38,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 730/1384 [14:24<12:38,  1.16s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 731/1384 [14:24<13:38,  1.25s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 731/1384 [14:25<13:38,  1.25s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 732/1384 [14:25<13:52,  1.28s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 732/1384 [14:26<13:52,  1.28s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 733/1384 [14:26<14:26,  1.33s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 733/1384 [14:28<14:26,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 734/1384 [14:28<14:38,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 734/1384 [14:29<14:38,  1.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 735/1384 [14:29<14:29,  1.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 735/1384 [14:30<14:29,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 736/1384 [14:30<13:55,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 736/1384 [14:31<13:55,  1.29s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 737/1384 [14:31<13:27,  1.25s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 737/1384 [14:33<13:27,  1.25s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 738/1384 [14:33<13:57,  1.30s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 738/1384 [14:34<13:57,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 739/1384 [14:34<14:25,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 739/1384 [14:36<14:25,  1.34s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 740/1384 [14:36<14:15,  1.33s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 740/1384 [14:37<14:15,  1.33s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 741/1384 [14:37<14:28,  1.35s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 741/1384 [14:38<14:28,  1.35s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 742/1384 [14:38<14:32,  1.36s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 742/1384 [14:40<14:32,  1.36s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 743/1384 [14:40<14:13,  1.33s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 743/1384 [14:41<14:13,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 744/1384 [14:41<13:46,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 744/1384 [14:42<13:46,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 745/1384 [14:42<13:31,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 745/1384 [14:43<13:31,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 746/1384 [14:43<13:18,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 746/1384 [14:44<13:18,  1.25s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 747/1384 [14:44<13:01,  1.23s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 747/1384 [14:46<13:01,  1.23s/it, training_loss=0.757]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 748/1384 [14:46<12:41,  1.20s/it, training_loss=0.757]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 748/1384 [14:47<12:41,  1.20s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 749/1384 [14:47<12:19,  1.16s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 749/1384 [14:48<12:19,  1.16s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 750/1384 [14:48<12:05,  1.14s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 750/1384 [14:49<12:05,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 751/1384 [14:49<11:46,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 751/1384 [14:50<11:46,  1.12s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 752/1384 [14:50<11:34,  1.10s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 752/1384 [14:51<11:34,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 753/1384 [14:51<11:29,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 753/1384 [14:52<11:29,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 754/1384 [14:52<11:30,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 754/1384 [14:53<11:30,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 755/1384 [14:53<11:32,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 755/1384 [14:54<11:32,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 756/1384 [14:54<11:30,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 756/1384 [14:55<11:30,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 757/1384 [14:55<11:29,  1.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 757/1384 [14:56<11:29,  1.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 758/1384 [14:56<11:20,  1.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 758/1384 [14:58<11:20,  1.09s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 759/1384 [14:58<11:17,  1.08s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 759/1384 [14:59<11:17,  1.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 760/1384 [14:59<11:09,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 760/1384 [15:00<11:09,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 761/1384 [15:00<11:02,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 761/1384 [15:01<11:02,  1.06s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 762/1384 [15:01<11:13,  1.08s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 762/1384 [15:02<11:13,  1.08s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 763/1384 [15:02<11:08,  1.08s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 763/1384 [15:03<11:08,  1.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 764/1384 [15:03<11:02,  1.07s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 764/1384 [15:04<11:02,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 765/1384 [15:04<10:58,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 765/1384 [15:05<10:58,  1.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 766/1384 [15:05<10:55,  1.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 766/1384 [15:06<10:55,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 767/1384 [15:06<10:56,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 767/1384 [15:07<10:56,  1.06s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 768/1384 [15:07<10:57,  1.07s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 768/1384 [15:08<10:57,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 769/1384 [15:08<10:59,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 769/1384 [15:09<10:59,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 770/1384 [15:09<10:55,  1.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 770/1384 [15:10<10:55,  1.07s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 771/1384 [15:10<10:51,  1.06s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 771/1384 [15:11<10:51,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 772/1384 [15:11<10:48,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 772/1384 [15:12<10:48,  1.06s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 773/1384 [15:12<10:44,  1.05s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 773/1384 [15:13<10:44,  1.05s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 774/1384 [15:13<10:43,  1.05s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 774/1384 [15:14<10:43,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 775/1384 [15:14<10:40,  1.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 775/1384 [15:16<10:40,  1.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 776/1384 [15:16<10:38,  1.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 776/1384 [15:17<10:38,  1.05s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 777/1384 [15:17<10:34,  1.05s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 777/1384 [15:18<10:34,  1.05s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 778/1384 [15:18<10:36,  1.05s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 778/1384 [15:19<10:36,  1.05s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 779/1384 [15:19<10:35,  1.05s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 779/1384 [15:20<10:35,  1.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 780/1384 [15:20<10:37,  1.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 780/1384 [15:21<10:37,  1.06s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 781/1384 [15:21<10:51,  1.08s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 781/1384 [15:22<10:51,  1.08s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 782/1384 [15:22<11:10,  1.11s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 782/1384 [15:23<11:10,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 783/1384 [15:23<11:19,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 783/1384 [15:24<11:19,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 784/1384 [15:24<11:21,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 784/1384 [15:26<11:21,  1.14s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 785/1384 [15:26<11:17,  1.13s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 785/1384 [15:27<11:17,  1.13s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 786/1384 [15:27<11:19,  1.14s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 786/1384 [15:28<11:19,  1.14s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 787/1384 [15:28<11:52,  1.19s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 787/1384 [15:29<11:52,  1.19s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 788/1384 [15:29<12:19,  1.24s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 788/1384 [15:31<12:19,  1.24s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 789/1384 [15:31<12:37,  1.27s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 789/1384 [15:32<12:37,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 790/1384 [15:32<12:46,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 790/1384 [15:33<12:46,  1.29s/it, training_loss=0.511]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 791/1384 [15:33<12:32,  1.27s/it, training_loss=0.511]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 791/1384 [15:35<12:32,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 792/1384 [15:35<12:35,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 792/1384 [15:36<12:35,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 793/1384 [15:36<13:02,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 793/1384 [15:37<13:02,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 794/1384 [15:37<13:14,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 794/1384 [15:39<13:14,  1.35s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 795/1384 [15:39<13:14,  1.35s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 795/1384 [15:40<13:14,  1.35s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 796/1384 [15:40<13:13,  1.35s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 796/1384 [15:41<13:13,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 797/1384 [15:41<13:09,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 797/1384 [15:43<13:09,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 798/1384 [15:43<12:48,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 798/1384 [15:44<12:48,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 799/1384 [15:44<12:34,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 799/1384 [15:45<12:34,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 800/1384 [15:45<12:55,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 800/1384 [15:47<12:55,  1.33s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 801/1384 [15:47<12:48,  1.32s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 801/1384 [15:48<12:48,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 802/1384 [15:48<12:41,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 802/1384 [15:49<12:41,  1.31s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 803/1384 [15:49<12:26,  1.29s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 803/1384 [15:50<12:26,  1.29s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 804/1384 [15:50<11:57,  1.24s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 804/1384 [15:51<11:57,  1.24s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 805/1384 [15:51<11:50,  1.23s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 805/1384 [15:53<11:50,  1.23s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 806/1384 [15:53<11:30,  1.19s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 806/1384 [15:54<11:30,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 807/1384 [15:54<11:12,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 807/1384 [15:55<11:12,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 808/1384 [15:55<11:12,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 808/1384 [15:56<11:12,  1.17s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 809/1384 [15:56<11:36,  1.21s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 809/1384 [15:57<11:36,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 810/1384 [15:57<11:27,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 810/1384 [15:58<11:27,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 811/1384 [15:58<11:11,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 811/1384 [15:59<11:11,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 812/1384 [15:59<10:55,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 812/1384 [16:01<10:55,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 813/1384 [16:01<10:48,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 813/1384 [16:02<10:48,  1.14s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 814/1384 [16:02<10:50,  1.14s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 814/1384 [16:03<10:50,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 815/1384 [16:03<10:47,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 815/1384 [16:04<10:47,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 816/1384 [16:04<10:35,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 816/1384 [16:05<10:35,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 817/1384 [16:05<10:39,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 817/1384 [16:06<10:39,  1.13s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 818/1384 [16:06<10:52,  1.15s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 818/1384 [16:07<10:52,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 819/1384 [16:07<10:54,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 819/1384 [16:09<10:54,  1.16s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 820/1384 [16:09<11:02,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 820/1384 [16:10<11:02,  1.17s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 821/1384 [16:10<12:15,  1.31s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 821/1384 [16:12<12:15,  1.31s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 822/1384 [16:12<12:30,  1.33s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 822/1384 [16:13<12:30,  1.33s/it, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 823/1384 [16:13<12:41,  1.36s/it, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 823/1384 [16:15<12:41,  1.36s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 824/1384 [16:15<13:02,  1.40s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 824/1384 [16:16<13:02,  1.40s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 825/1384 [16:16<13:35,  1.46s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 825/1384 [16:18<13:35,  1.46s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 826/1384 [16:18<13:30,  1.45s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 826/1384 [16:19<13:30,  1.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 827/1384 [16:19<13:02,  1.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 827/1384 [16:20<13:02,  1.41s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 828/1384 [16:20<12:34,  1.36s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 828/1384 [16:22<12:34,  1.36s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 829/1384 [16:22<12:55,  1.40s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 829/1384 [16:23<12:55,  1.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 830/1384 [16:23<13:15,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 830/1384 [16:25<13:15,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 831/1384 [16:25<13:17,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 831/1384 [16:26<13:17,  1.44s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 2:  60%|██████    | 832/1384 [16:26<13:02,  1.42s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 2:  60%|██████    | 832/1384 [16:27<13:02,  1.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 833/1384 [16:27<12:36,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|██████    | 833/1384 [16:28<12:36,  1.37s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  60%|██████    | 834/1384 [16:28<12:02,  1.31s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  60%|██████    | 834/1384 [16:30<12:02,  1.31s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 2:  60%|██████    | 835/1384 [16:30<12:01,  1.31s/it, training_loss=0.447]\u001b[A\n",
      "Epoch 2:  60%|██████    | 835/1384 [16:31<12:01,  1.31s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  60%|██████    | 836/1384 [16:31<12:18,  1.35s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  60%|██████    | 836/1384 [16:32<12:18,  1.35s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  60%|██████    | 837/1384 [16:32<11:51,  1.30s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  60%|██████    | 837/1384 [16:34<11:51,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 838/1384 [16:34<11:55,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 838/1384 [16:35<11:55,  1.31s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  61%|██████    | 839/1384 [16:35<12:08,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  61%|██████    | 839/1384 [16:37<12:08,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  61%|██████    | 840/1384 [16:37<12:12,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  61%|██████    | 840/1384 [16:38<12:12,  1.35s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  61%|██████    | 841/1384 [16:38<12:25,  1.37s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  61%|██████    | 841/1384 [16:39<12:25,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 842/1384 [16:39<12:05,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 842/1384 [16:40<12:05,  1.34s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 2:  61%|██████    | 843/1384 [16:40<11:42,  1.30s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 2:  61%|██████    | 843/1384 [16:42<11:42,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 844/1384 [16:42<11:16,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 844/1384 [16:43<11:16,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  61%|██████    | 845/1384 [16:43<10:56,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  61%|██████    | 845/1384 [16:44<10:56,  1.22s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  61%|██████    | 846/1384 [16:44<10:41,  1.19s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  61%|██████    | 846/1384 [16:45<10:41,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 847/1384 [16:45<10:29,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 847/1384 [16:46<10:29,  1.17s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 848/1384 [16:46<10:38,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 848/1384 [16:47<10:38,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 849/1384 [16:47<10:49,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 849/1384 [16:49<10:49,  1.21s/it, training_loss=0.477]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 850/1384 [16:49<10:50,  1.22s/it, training_loss=0.477]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 850/1384 [16:50<10:50,  1.22s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 851/1384 [16:50<10:51,  1.22s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 851/1384 [16:51<10:51,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 852/1384 [16:51<11:02,  1.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 852/1384 [16:52<11:02,  1.24s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 853/1384 [16:52<10:52,  1.23s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 853/1384 [16:54<10:52,  1.23s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 854/1384 [16:54<10:50,  1.23s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 854/1384 [16:55<10:50,  1.23s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 855/1384 [16:55<10:49,  1.23s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 855/1384 [16:56<10:49,  1.23s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 856/1384 [16:56<10:41,  1.22s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 856/1384 [16:57<10:41,  1.22s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 857/1384 [16:57<10:41,  1.22s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 857/1384 [16:59<10:41,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 858/1384 [16:59<10:55,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 858/1384 [17:00<10:55,  1.25s/it, training_loss=0.429]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 859/1384 [17:00<10:45,  1.23s/it, training_loss=0.429]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 859/1384 [17:01<10:45,  1.23s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 860/1384 [17:01<10:51,  1.24s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 860/1384 [17:02<10:51,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 861/1384 [17:02<10:39,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 861/1384 [17:03<10:39,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 862/1384 [17:03<10:24,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 862/1384 [17:05<10:24,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 863/1384 [17:05<10:17,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 863/1384 [17:06<10:17,  1.19s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 864/1384 [17:06<10:20,  1.19s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 864/1384 [17:07<10:20,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▎   | 865/1384 [17:07<10:15,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▎   | 865/1384 [17:08<10:15,  1.19s/it, training_loss=0.442]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 866/1384 [17:08<10:15,  1.19s/it, training_loss=0.442]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 866/1384 [17:09<10:15,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 867/1384 [17:09<10:07,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 867/1384 [17:10<10:07,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 868/1384 [17:10<10:00,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 868/1384 [17:12<10:00,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 869/1384 [17:12<10:10,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 869/1384 [17:13<10:10,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 870/1384 [17:13<10:11,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 870/1384 [17:14<10:11,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 871/1384 [17:14<10:19,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 871/1384 [17:15<10:19,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 872/1384 [17:15<10:22,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 872/1384 [17:17<10:22,  1.22s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 873/1384 [17:17<10:23,  1.22s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 873/1384 [17:18<10:23,  1.22s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 874/1384 [17:18<10:37,  1.25s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 874/1384 [17:19<10:37,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 875/1384 [17:19<10:53,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 875/1384 [17:21<10:53,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 876/1384 [17:21<11:11,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 876/1384 [17:22<11:11,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 877/1384 [17:22<11:33,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 877/1384 [17:23<11:33,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 878/1384 [17:23<11:28,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 878/1384 [17:25<11:28,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 879/1384 [17:25<11:02,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 879/1384 [17:26<11:02,  1.31s/it, training_loss=0.639]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 880/1384 [17:26<10:41,  1.27s/it, training_loss=0.639]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 880/1384 [17:27<10:41,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 881/1384 [17:27<10:25,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 881/1384 [17:28<10:25,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 882/1384 [17:28<10:17,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 882/1384 [17:29<10:17,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 883/1384 [17:29<10:04,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 883/1384 [17:31<10:04,  1.21s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 884/1384 [17:31<09:57,  1.20s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 884/1384 [17:32<09:57,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 885/1384 [17:32<09:44,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 885/1384 [17:33<09:44,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 886/1384 [17:33<09:33,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 886/1384 [17:34<09:33,  1.15s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 887/1384 [17:34<09:29,  1.15s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 887/1384 [17:35<09:29,  1.15s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 888/1384 [17:35<09:27,  1.14s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 888/1384 [17:36<09:27,  1.14s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 889/1384 [17:36<09:14,  1.12s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 889/1384 [17:37<09:14,  1.12s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 890/1384 [17:37<09:10,  1.11s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 890/1384 [17:38<09:10,  1.11s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 891/1384 [17:38<09:10,  1.12s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 891/1384 [17:39<09:10,  1.12s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 892/1384 [17:39<09:14,  1.13s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 892/1384 [17:41<09:14,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 893/1384 [17:41<09:14,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 893/1384 [17:42<09:14,  1.13s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 894/1384 [17:42<09:16,  1.14s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 894/1384 [17:43<09:16,  1.14s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 895/1384 [17:43<09:09,  1.12s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 895/1384 [17:44<09:09,  1.12s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 896/1384 [17:44<09:11,  1.13s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 896/1384 [17:45<09:11,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 897/1384 [17:45<09:09,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 897/1384 [17:46<09:09,  1.13s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 898/1384 [17:46<09:08,  1.13s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 898/1384 [17:47<09:08,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 899/1384 [17:47<09:00,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 899/1384 [17:48<09:00,  1.11s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 900/1384 [17:48<08:52,  1.10s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 900/1384 [17:49<08:52,  1.10s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 901/1384 [17:49<08:49,  1.10s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 901/1384 [17:51<08:49,  1.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 902/1384 [17:51<08:59,  1.12s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 902/1384 [17:52<08:59,  1.12s/it, training_loss=0.455]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 903/1384 [17:52<09:08,  1.14s/it, training_loss=0.455]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 903/1384 [17:53<09:08,  1.14s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 904/1384 [17:53<10:02,  1.26s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 904/1384 [17:55<10:02,  1.26s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 905/1384 [17:55<10:03,  1.26s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 905/1384 [17:56<10:03,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 906/1384 [17:56<10:24,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 906/1384 [17:57<10:24,  1.31s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 907/1384 [17:57<10:11,  1.28s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 907/1384 [17:59<10:11,  1.28s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 908/1384 [17:59<11:06,  1.40s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 908/1384 [18:00<11:06,  1.40s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 909/1384 [18:00<10:45,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 909/1384 [18:02<10:45,  1.36s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 910/1384 [18:02<10:52,  1.38s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 910/1384 [18:03<10:52,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 911/1384 [18:03<10:32,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 911/1384 [18:04<10:32,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 912/1384 [18:04<10:25,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 912/1384 [18:05<10:25,  1.32s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 913/1384 [18:05<10:15,  1.31s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 913/1384 [18:07<10:15,  1.31s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 914/1384 [18:07<10:05,  1.29s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 914/1384 [18:08<10:05,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 915/1384 [18:08<09:54,  1.27s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 915/1384 [18:09<09:54,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 916/1384 [18:09<09:49,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 916/1384 [18:10<09:49,  1.26s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 917/1384 [18:10<09:43,  1.25s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 917/1384 [18:11<09:43,  1.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 918/1384 [18:11<09:19,  1.20s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 918/1384 [18:13<09:19,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 919/1384 [18:13<09:16,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 919/1384 [18:14<09:16,  1.20s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 920/1384 [18:14<09:06,  1.18s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 920/1384 [18:15<09:06,  1.18s/it, training_loss=0.438]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 921/1384 [18:15<09:05,  1.18s/it, training_loss=0.438]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 921/1384 [18:16<09:05,  1.18s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 922/1384 [18:16<08:59,  1.17s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 922/1384 [18:17<08:59,  1.17s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 923/1384 [18:17<08:56,  1.16s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 923/1384 [18:18<08:56,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 924/1384 [18:18<09:03,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 924/1384 [18:20<09:03,  1.18s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 925/1384 [18:20<09:05,  1.19s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 925/1384 [18:21<09:05,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 926/1384 [18:21<08:58,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 926/1384 [18:22<08:58,  1.18s/it, training_loss=0.462]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 927/1384 [18:22<08:49,  1.16s/it, training_loss=0.462]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 927/1384 [18:23<08:49,  1.16s/it, training_loss=0.498]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 928/1384 [18:23<08:47,  1.16s/it, training_loss=0.498]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 928/1384 [18:24<08:47,  1.16s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 929/1384 [18:24<08:52,  1.17s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 929/1384 [18:26<08:52,  1.17s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 930/1384 [18:26<09:00,  1.19s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 930/1384 [18:27<09:00,  1.19s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 931/1384 [18:27<08:52,  1.18s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 931/1384 [18:28<08:52,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 932/1384 [18:28<08:43,  1.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 932/1384 [18:29<08:43,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 933/1384 [18:29<08:48,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 933/1384 [18:30<08:48,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 934/1384 [18:30<08:53,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 934/1384 [18:31<08:53,  1.19s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 935/1384 [18:31<09:00,  1.20s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 935/1384 [18:33<09:00,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 936/1384 [18:33<09:04,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 936/1384 [18:34<09:04,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 937/1384 [18:34<08:56,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 937/1384 [18:35<08:56,  1.20s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 938/1384 [18:35<08:55,  1.20s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 938/1384 [18:36<08:55,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 939/1384 [18:36<08:53,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 939/1384 [18:37<08:53,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 940/1384 [18:37<08:54,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 940/1384 [18:39<08:54,  1.20s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 941/1384 [18:39<08:57,  1.21s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 941/1384 [18:40<08:57,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 942/1384 [18:40<08:56,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 942/1384 [18:41<08:56,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 943/1384 [18:41<08:59,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 943/1384 [18:42<08:59,  1.22s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 944/1384 [18:42<08:50,  1.21s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 944/1384 [18:43<08:50,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 945/1384 [18:43<08:44,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 945/1384 [18:45<08:44,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 946/1384 [18:45<08:42,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 946/1384 [18:46<08:42,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 947/1384 [18:46<08:46,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 947/1384 [18:47<08:46,  1.21s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 948/1384 [18:47<08:37,  1.19s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 948/1384 [18:48<08:37,  1.19s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 949/1384 [18:48<08:28,  1.17s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 949/1384 [18:49<08:28,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 950/1384 [18:49<08:19,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 950/1384 [18:50<08:19,  1.15s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 951/1384 [18:50<08:12,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 951/1384 [18:52<08:12,  1.14s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 952/1384 [18:52<08:12,  1.14s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 952/1384 [18:53<08:12,  1.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 953/1384 [18:53<08:13,  1.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 953/1384 [18:54<08:13,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 954/1384 [18:54<08:16,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 954/1384 [18:55<08:16,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 955/1384 [18:55<08:15,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 955/1384 [18:56<08:15,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 956/1384 [18:56<08:13,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 956/1384 [18:57<08:13,  1.15s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 957/1384 [18:57<08:13,  1.16s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 957/1384 [18:58<08:13,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 958/1384 [18:58<08:03,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 958/1384 [19:00<08:03,  1.14s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 959/1384 [19:00<08:07,  1.15s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 959/1384 [19:01<08:07,  1.15s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 960/1384 [19:01<08:17,  1.17s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 960/1384 [19:02<08:17,  1.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 961/1384 [19:02<08:20,  1.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 961/1384 [19:03<08:20,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 962/1384 [19:03<08:26,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 962/1384 [19:04<08:26,  1.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 963/1384 [19:04<08:22,  1.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 963/1384 [19:06<08:22,  1.19s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 964/1384 [19:06<08:32,  1.22s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 964/1384 [19:07<08:32,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 965/1384 [19:07<08:37,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 965/1384 [19:08<08:37,  1.24s/it, training_loss=0.492]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 966/1384 [19:08<08:37,  1.24s/it, training_loss=0.492]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 966/1384 [19:09<08:37,  1.24s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 967/1384 [19:09<08:30,  1.22s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 967/1384 [19:11<08:30,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 968/1384 [19:11<08:39,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 968/1384 [19:12<08:39,  1.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  70%|███████   | 969/1384 [19:12<08:28,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  70%|███████   | 969/1384 [19:13<08:28,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 970/1384 [19:13<08:17,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 970/1384 [19:14<08:17,  1.20s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  70%|███████   | 971/1384 [19:14<08:16,  1.20s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  70%|███████   | 971/1384 [19:15<08:16,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 972/1384 [19:15<08:10,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 972/1384 [19:17<08:10,  1.19s/it, training_loss=0.434]\u001b[A\n",
      "Epoch 2:  70%|███████   | 973/1384 [19:17<08:02,  1.17s/it, training_loss=0.434]\u001b[A\n",
      "Epoch 2:  70%|███████   | 973/1384 [19:18<08:02,  1.17s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  70%|███████   | 974/1384 [19:18<08:06,  1.19s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  70%|███████   | 974/1384 [19:19<08:06,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 975/1384 [19:19<08:35,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 975/1384 [19:21<08:35,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 976/1384 [19:21<08:51,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 976/1384 [19:22<08:51,  1.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  71%|███████   | 977/1384 [19:22<09:08,  1.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  71%|███████   | 977/1384 [19:24<09:08,  1.35s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 2:  71%|███████   | 978/1384 [19:24<09:18,  1.38s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 2:  71%|███████   | 978/1384 [19:25<09:18,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 979/1384 [19:25<09:49,  1.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 979/1384 [19:27<09:49,  1.45s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  71%|███████   | 980/1384 [19:27<10:18,  1.53s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  71%|███████   | 980/1384 [19:28<10:18,  1.53s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 981/1384 [19:28<10:21,  1.54s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 981/1384 [19:30<10:21,  1.54s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████   | 982/1384 [19:30<10:13,  1.53s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████   | 982/1384 [19:31<10:13,  1.53s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  71%|███████   | 983/1384 [19:31<10:01,  1.50s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  71%|███████   | 983/1384 [19:33<10:01,  1.50s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 984/1384 [19:33<09:30,  1.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 984/1384 [19:34<09:30,  1.43s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  71%|███████   | 985/1384 [19:34<09:06,  1.37s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  71%|███████   | 985/1384 [19:35<09:06,  1.37s/it, training_loss=0.491]\u001b[A\n",
      "Epoch 2:  71%|███████   | 986/1384 [19:35<08:47,  1.33s/it, training_loss=0.491]\u001b[A\n",
      "Epoch 2:  71%|███████   | 986/1384 [19:36<08:47,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 987/1384 [19:36<08:28,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 987/1384 [19:37<08:28,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 988/1384 [19:37<08:08,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 988/1384 [19:39<08:08,  1.23s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 989/1384 [19:39<07:56,  1.21s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 989/1384 [19:40<07:56,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 990/1384 [19:40<07:41,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 990/1384 [19:41<07:41,  1.17s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 991/1384 [19:41<07:27,  1.14s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 991/1384 [19:42<07:27,  1.14s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 992/1384 [19:42<07:18,  1.12s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 992/1384 [19:43<07:18,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 993/1384 [19:43<07:13,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 993/1384 [19:44<07:13,  1.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 994/1384 [19:44<07:18,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 994/1384 [19:45<07:18,  1.13s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 995/1384 [19:45<07:17,  1.12s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 995/1384 [19:46<07:17,  1.12s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 996/1384 [19:46<07:17,  1.13s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 996/1384 [19:47<07:17,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 997/1384 [19:47<07:24,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 997/1384 [19:49<07:24,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 998/1384 [19:49<07:21,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 998/1384 [19:50<07:21,  1.14s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 999/1384 [19:50<07:13,  1.13s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 999/1384 [19:51<07:13,  1.13s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1000/1384 [19:51<07:12,  1.13s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1000/1384 [19:52<07:12,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1001/1384 [19:52<07:15,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1001/1384 [19:53<07:15,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1002/1384 [19:53<07:14,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1002/1384 [19:54<07:14,  1.14s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1003/1384 [19:54<07:14,  1.14s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 1003/1384 [19:55<07:14,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1004/1384 [19:55<07:07,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1004/1384 [19:56<07:07,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1005/1384 [19:56<07:04,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1005/1384 [19:58<07:04,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1006/1384 [19:58<07:02,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1006/1384 [19:59<07:02,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1007/1384 [19:59<07:04,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1007/1384 [20:00<07:04,  1.13s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1008/1384 [20:00<07:16,  1.16s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1008/1384 [20:01<07:16,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1009/1384 [20:01<07:18,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1009/1384 [20:02<07:18,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1010/1384 [20:02<07:23,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1010/1384 [20:04<07:23,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1011/1384 [20:04<07:24,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1011/1384 [20:05<07:24,  1.19s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1012/1384 [20:05<07:22,  1.19s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1012/1384 [20:06<07:22,  1.19s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1013/1384 [20:06<07:31,  1.22s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1013/1384 [20:07<07:31,  1.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1014/1384 [20:07<07:34,  1.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1014/1384 [20:09<07:34,  1.23s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1015/1384 [20:09<07:38,  1.24s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1015/1384 [20:10<07:38,  1.24s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1016/1384 [20:10<08:00,  1.31s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1016/1384 [20:11<08:00,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1017/1384 [20:11<08:12,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 1017/1384 [20:13<08:12,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  74%|██████▌  | 1018/1384 [20:13<08:16,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  74%|██████▌  | 1018/1384 [20:14<08:16,  1.36s/it, training_loss=0.433]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1019/1384 [20:14<08:21,  1.38s/it, training_loss=0.433]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1019/1384 [20:16<08:21,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1020/1384 [20:16<08:23,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1020/1384 [20:17<08:23,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1021/1384 [20:17<08:21,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1021/1384 [20:18<08:21,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1022/1384 [20:18<08:21,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1022/1384 [20:20<08:21,  1.39s/it, training_loss=0.818]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1023/1384 [20:20<08:19,  1.38s/it, training_loss=0.818]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1023/1384 [20:21<08:19,  1.38s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1024/1384 [20:21<08:17,  1.38s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1024/1384 [20:23<08:17,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1025/1384 [20:23<08:16,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1025/1384 [20:24<08:16,  1.38s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1026/1384 [20:24<08:06,  1.36s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1026/1384 [20:25<08:06,  1.36s/it, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1027/1384 [20:25<08:00,  1.35s/it, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1027/1384 [20:27<08:00,  1.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1028/1384 [20:27<07:57,  1.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1028/1384 [20:28<07:57,  1.34s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1029/1384 [20:28<07:52,  1.33s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1029/1384 [20:29<07:52,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1030/1384 [20:29<07:50,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1030/1384 [20:31<07:50,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1031/1384 [20:31<07:57,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 1031/1384 [20:32<07:57,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1032/1384 [20:32<08:04,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1032/1384 [20:33<08:04,  1.38s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1033/1384 [20:33<07:57,  1.36s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1033/1384 [20:35<07:57,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1034/1384 [20:35<08:24,  1.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1034/1384 [20:36<08:24,  1.44s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1035/1384 [20:36<08:18,  1.43s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1035/1384 [20:38<08:18,  1.43s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1036/1384 [20:38<08:16,  1.43s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1036/1384 [20:39<08:16,  1.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1037/1384 [20:39<08:13,  1.42s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 1037/1384 [20:40<08:13,  1.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1038/1384 [20:40<07:58,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1038/1384 [20:42<07:58,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1039/1384 [20:42<07:57,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1039/1384 [20:43<07:57,  1.38s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1040/1384 [20:43<07:43,  1.35s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1040/1384 [20:44<07:43,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1041/1384 [20:44<07:33,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1041/1384 [20:46<07:33,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1042/1384 [20:46<07:18,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1042/1384 [20:47<07:18,  1.28s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1043/1384 [20:47<07:19,  1.29s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1043/1384 [20:48<07:19,  1.29s/it, training_loss=0.452]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1044/1384 [20:48<07:13,  1.28s/it, training_loss=0.452]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 1044/1384 [20:49<07:13,  1.28s/it, training_loss=0.471]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1045/1384 [20:49<06:54,  1.22s/it, training_loss=0.471]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1045/1384 [20:50<06:54,  1.22s/it, training_loss=0.478]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1046/1384 [20:50<06:38,  1.18s/it, training_loss=0.478]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1046/1384 [20:51<06:38,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1047/1384 [20:51<06:24,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1047/1384 [20:52<06:24,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1048/1384 [20:52<06:13,  1.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1048/1384 [20:54<06:13,  1.11s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1049/1384 [20:54<06:19,  1.13s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1049/1384 [20:55<06:19,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1050/1384 [20:55<06:18,  1.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1050/1384 [20:56<06:18,  1.13s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1051/1384 [20:56<06:18,  1.14s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1051/1384 [20:57<06:18,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1052/1384 [20:57<06:21,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1052/1384 [20:58<06:21,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1053/1384 [20:58<06:19,  1.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1053/1384 [20:59<06:19,  1.15s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1054/1384 [20:59<06:20,  1.15s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1054/1384 [21:01<06:20,  1.15s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1055/1384 [21:01<06:25,  1.17s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1055/1384 [21:02<06:25,  1.17s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1056/1384 [21:02<06:22,  1.17s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1056/1384 [21:03<06:22,  1.17s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1057/1384 [21:03<06:43,  1.23s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 1057/1384 [21:04<06:43,  1.23s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 2:  76%|██████▉  | 1058/1384 [21:04<06:54,  1.27s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 2:  76%|██████▉  | 1058/1384 [21:06<06:54,  1.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1059/1384 [21:06<06:44,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1059/1384 [21:07<06:44,  1.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1060/1384 [21:07<06:34,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1060/1384 [21:08<06:34,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1061/1384 [21:08<06:31,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1061/1384 [21:09<06:31,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1062/1384 [21:09<06:29,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1062/1384 [21:10<06:29,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1063/1384 [21:10<06:19,  1.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1063/1384 [21:11<06:19,  1.18s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1064/1384 [21:11<06:12,  1.16s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1064/1384 [21:13<06:12,  1.16s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1065/1384 [21:13<06:09,  1.16s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1065/1384 [21:14<06:09,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1066/1384 [21:14<06:09,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1066/1384 [21:15<06:09,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1067/1384 [21:15<06:11,  1.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1067/1384 [21:16<06:11,  1.17s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1068/1384 [21:16<06:05,  1.16s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1068/1384 [21:17<06:05,  1.16s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1069/1384 [21:17<05:59,  1.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1069/1384 [21:18<05:59,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1070/1384 [21:18<05:53,  1.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1070/1384 [21:19<05:53,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1071/1384 [21:19<05:53,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1071/1384 [21:21<05:53,  1.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1072/1384 [21:21<06:17,  1.21s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 1072/1384 [21:22<06:17,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1073/1384 [21:22<06:16,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1073/1384 [21:23<06:16,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1074/1384 [21:23<06:15,  1.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1074/1384 [21:24<06:15,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1075/1384 [21:24<06:10,  1.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1075/1384 [21:26<06:10,  1.20s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1076/1384 [21:26<06:02,  1.18s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 1076/1384 [21:27<06:02,  1.18s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1077/1384 [21:27<06:07,  1.20s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1077/1384 [21:28<06:07,  1.20s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1078/1384 [21:28<06:04,  1.19s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1078/1384 [21:29<06:04,  1.19s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1079/1384 [21:29<06:07,  1.21s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1079/1384 [21:30<06:07,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1080/1384 [21:30<06:14,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1080/1384 [21:32<06:14,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1081/1384 [21:32<06:02,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1081/1384 [21:33<06:02,  1.19s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1082/1384 [21:33<05:58,  1.19s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1082/1384 [21:34<05:58,  1.19s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1083/1384 [21:34<05:49,  1.16s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1083/1384 [21:35<05:49,  1.16s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1084/1384 [21:35<05:55,  1.19s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1084/1384 [21:36<05:55,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1085/1384 [21:36<06:00,  1.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1085/1384 [21:38<06:00,  1.21s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1086/1384 [21:38<06:24,  1.29s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 2:  78%|███████  | 1086/1384 [21:39<06:24,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1087/1384 [21:39<06:25,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1087/1384 [21:40<06:25,  1.30s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1088/1384 [21:40<06:10,  1.25s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1088/1384 [21:41<06:10,  1.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1089/1384 [21:41<05:58,  1.22s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1089/1384 [21:43<05:58,  1.22s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1090/1384 [21:43<05:49,  1.19s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1090/1384 [21:44<05:49,  1.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1091/1384 [21:44<05:39,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1091/1384 [21:45<05:39,  1.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1092/1384 [21:45<05:32,  1.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1092/1384 [21:46<05:32,  1.14s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1093/1384 [21:46<05:29,  1.13s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1093/1384 [21:47<05:29,  1.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1094/1384 [21:47<05:25,  1.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1094/1384 [21:48<05:25,  1.12s/it, training_loss=0.408]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1095/1384 [21:48<05:41,  1.18s/it, training_loss=0.408]\u001b[A\n",
      "Epoch 2:  79%|███████  | 1095/1384 [21:49<05:41,  1.18s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1096/1384 [21:49<05:36,  1.17s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1096/1384 [21:51<05:36,  1.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1097/1384 [21:51<05:42,  1.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1097/1384 [21:52<05:42,  1.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1098/1384 [21:52<05:50,  1.23s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1098/1384 [21:53<05:50,  1.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1099/1384 [21:53<05:58,  1.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1099/1384 [21:55<05:58,  1.26s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1100/1384 [21:55<06:05,  1.29s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  79%|███████▏ | 1100/1384 [21:56<06:05,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1101/1384 [21:56<06:08,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1101/1384 [21:57<06:08,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1102/1384 [21:57<06:10,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1102/1384 [21:59<06:10,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1103/1384 [21:59<06:12,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1103/1384 [22:00<06:12,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1104/1384 [22:00<06:19,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1104/1384 [22:02<06:19,  1.35s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1105/1384 [22:02<06:21,  1.37s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1105/1384 [22:03<06:21,  1.37s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1106/1384 [22:03<06:23,  1.38s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1106/1384 [22:04<06:23,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1107/1384 [22:04<06:22,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1107/1384 [22:06<06:22,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1108/1384 [22:06<06:22,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1108/1384 [22:07<06:22,  1.39s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1109/1384 [22:07<06:21,  1.39s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1109/1384 [22:09<06:21,  1.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1110/1384 [22:09<06:21,  1.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1110/1384 [22:10<06:21,  1.39s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1111/1384 [22:10<06:20,  1.39s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1111/1384 [22:11<06:20,  1.39s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1112/1384 [22:11<06:18,  1.39s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1112/1384 [22:13<06:18,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1113/1384 [22:13<06:14,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1113/1384 [22:14<06:14,  1.38s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1114/1384 [22:14<06:10,  1.37s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  80%|███████▏ | 1114/1384 [22:15<06:10,  1.37s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1115/1384 [22:15<06:06,  1.36s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1115/1384 [22:17<06:06,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1116/1384 [22:17<05:59,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1116/1384 [22:18<05:59,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1117/1384 [22:18<05:55,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1117/1384 [22:19<05:55,  1.33s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1118/1384 [22:19<05:51,  1.32s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1118/1384 [22:21<05:51,  1.32s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1119/1384 [22:21<05:49,  1.32s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1119/1384 [22:22<05:49,  1.32s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1120/1384 [22:22<05:46,  1.31s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1120/1384 [22:23<05:46,  1.31s/it, training_loss=0.434]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1121/1384 [22:23<05:44,  1.31s/it, training_loss=0.434]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1121/1384 [22:24<05:44,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1122/1384 [22:24<05:41,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1122/1384 [22:26<05:41,  1.30s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1123/1384 [22:26<05:38,  1.30s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1123/1384 [22:27<05:38,  1.30s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1124/1384 [22:27<05:37,  1.30s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1124/1384 [22:28<05:37,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1125/1384 [22:28<05:36,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1125/1384 [22:30<05:36,  1.30s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1126/1384 [22:30<05:36,  1.30s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1126/1384 [22:31<05:36,  1.30s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1127/1384 [22:31<05:36,  1.31s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  81%|███████▎ | 1127/1384 [22:32<05:36,  1.31s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1128/1384 [22:32<05:34,  1.31s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1128/1384 [22:34<05:34,  1.31s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1129/1384 [22:34<05:31,  1.30s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1129/1384 [22:35<05:31,  1.30s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1130/1384 [22:35<05:32,  1.31s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1130/1384 [22:36<05:32,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1131/1384 [22:36<05:32,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1131/1384 [22:38<05:32,  1.31s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1132/1384 [22:38<05:33,  1.32s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1132/1384 [22:39<05:33,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1133/1384 [22:39<05:33,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1133/1384 [22:40<05:33,  1.33s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1134/1384 [22:40<05:32,  1.33s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  82%|███████▎ | 1134/1384 [22:42<05:32,  1.33s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1135/1384 [22:42<05:29,  1.33s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1135/1384 [22:43<05:29,  1.33s/it, training_loss=0.435]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1136/1384 [22:43<05:29,  1.33s/it, training_loss=0.435]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1136/1384 [22:44<05:29,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1137/1384 [22:44<05:27,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1137/1384 [22:45<05:27,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1138/1384 [22:45<05:25,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1138/1384 [22:47<05:25,  1.32s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1139/1384 [22:47<05:26,  1.33s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1139/1384 [22:48<05:26,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1140/1384 [22:48<05:23,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1140/1384 [22:49<05:23,  1.32s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1141/1384 [22:49<05:22,  1.33s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 1141/1384 [22:51<05:22,  1.33s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1142/1384 [22:51<05:24,  1.34s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1142/1384 [22:52<05:24,  1.34s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1143/1384 [22:52<05:22,  1.34s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1143/1384 [22:54<05:22,  1.34s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1144/1384 [22:54<05:21,  1.34s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1144/1384 [22:55<05:21,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1145/1384 [22:55<05:19,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1145/1384 [22:56<05:19,  1.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1146/1384 [22:56<05:17,  1.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1146/1384 [22:58<05:17,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1147/1384 [22:58<05:17,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1147/1384 [22:59<05:17,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1148/1384 [22:59<05:15,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1148/1384 [23:00<05:15,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1149/1384 [23:00<05:13,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1149/1384 [23:02<05:13,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1150/1384 [23:02<05:10,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1150/1384 [23:03<05:10,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1151/1384 [23:03<05:07,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1151/1384 [23:04<05:07,  1.32s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1152/1384 [23:04<05:05,  1.32s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1152/1384 [23:05<05:05,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1153/1384 [23:05<05:03,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 1153/1384 [23:07<05:03,  1.31s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  83%|███████▌ | 1154/1384 [23:07<05:00,  1.31s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 2:  83%|███████▌ | 1154/1384 [23:08<05:00,  1.31s/it, training_loss=0.396]\u001b[A\n",
      "Epoch 2:  83%|███████▌ | 1155/1384 [23:08<05:00,  1.31s/it, training_loss=0.396]\u001b[A\n",
      "Epoch 2:  83%|███████▌ | 1155/1384 [23:09<05:00,  1.31s/it, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1156/1384 [23:09<05:01,  1.32s/it, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1156/1384 [23:11<05:01,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1157/1384 [23:11<04:59,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1157/1384 [23:12<04:59,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1158/1384 [23:12<04:58,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1158/1384 [23:13<04:58,  1.32s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1159/1384 [23:13<04:54,  1.31s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1159/1384 [23:15<04:54,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1160/1384 [23:15<04:51,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1160/1384 [23:16<04:51,  1.30s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1161/1384 [23:16<04:49,  1.30s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1161/1384 [23:17<04:49,  1.30s/it, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1162/1384 [23:17<04:46,  1.29s/it, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1162/1384 [23:18<04:46,  1.29s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1163/1384 [23:18<04:45,  1.29s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1163/1384 [23:20<04:45,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1164/1384 [23:20<04:43,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1164/1384 [23:21<04:43,  1.29s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1165/1384 [23:21<04:42,  1.29s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1165/1384 [23:22<04:42,  1.29s/it, training_loss=0.473]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1166/1384 [23:22<04:39,  1.28s/it, training_loss=0.473]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1166/1384 [23:24<04:39,  1.28s/it, training_loss=0.486]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1167/1384 [23:24<04:39,  1.29s/it, training_loss=0.486]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1167/1384 [23:25<04:39,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1168/1384 [23:25<04:37,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1168/1384 [23:26<04:37,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1169/1384 [23:26<04:36,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 1169/1384 [23:27<04:36,  1.28s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 1170/1384 [23:27<04:34,  1.28s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 1170/1384 [23:29<04:34,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 1171/1384 [23:29<04:38,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 1171/1384 [23:30<04:38,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 1172/1384 [23:30<04:41,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 1172/1384 [23:31<04:41,  1.33s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1173/1384 [23:31<04:38,  1.32s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1173/1384 [23:33<04:38,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1174/1384 [23:33<04:36,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1174/1384 [23:34<04:36,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1175/1384 [23:34<04:35,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1175/1384 [23:35<04:35,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1176/1384 [23:35<04:36,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1176/1384 [23:37<04:36,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1177/1384 [23:37<04:34,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1177/1384 [23:38<04:34,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1178/1384 [23:38<04:36,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1178/1384 [23:40<04:36,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1179/1384 [23:40<04:36,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1179/1384 [23:41<04:36,  1.35s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1180/1384 [23:41<04:36,  1.36s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1180/1384 [23:42<04:36,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1181/1384 [23:42<04:35,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1181/1384 [23:44<04:35,  1.35s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1182/1384 [23:44<04:34,  1.36s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1182/1384 [23:45<04:34,  1.36s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1183/1384 [23:45<04:32,  1.35s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 1183/1384 [23:46<04:32,  1.35s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1184/1384 [23:46<04:30,  1.35s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1184/1384 [23:48<04:30,  1.35s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1185/1384 [23:48<04:29,  1.35s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1185/1384 [23:49<04:29,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1186/1384 [23:49<04:28,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1186/1384 [23:50<04:28,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1187/1384 [23:50<04:27,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1187/1384 [23:52<04:27,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1188/1384 [23:52<04:30,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1188/1384 [23:53<04:30,  1.38s/it, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1189/1384 [23:53<04:27,  1.37s/it, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1189/1384 [23:55<04:27,  1.37s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1190/1384 [23:55<04:25,  1.37s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1190/1384 [23:56<04:25,  1.37s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1191/1384 [23:56<04:24,  1.37s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 1191/1384 [23:57<04:24,  1.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1192/1384 [23:57<04:20,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1192/1384 [23:59<04:20,  1.36s/it, training_loss=0.608]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1193/1384 [23:59<04:15,  1.34s/it, training_loss=0.608]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1193/1384 [24:00<04:15,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1194/1384 [24:00<04:12,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1194/1384 [24:01<04:12,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1195/1384 [24:01<04:10,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1195/1384 [24:02<04:10,  1.33s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1196/1384 [24:02<04:08,  1.32s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1196/1384 [24:04<04:08,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1197/1384 [24:04<04:06,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 1197/1384 [24:05<04:06,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1198/1384 [24:05<04:06,  1.33s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1198/1384 [24:06<04:06,  1.33s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1199/1384 [24:06<04:06,  1.33s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1199/1384 [24:08<04:06,  1.33s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1200/1384 [24:08<04:05,  1.33s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1200/1384 [24:09<04:05,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1201/1384 [24:09<04:04,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1201/1384 [24:11<04:04,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1202/1384 [24:11<04:04,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1202/1384 [24:12<04:04,  1.34s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1203/1384 [24:12<04:03,  1.35s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1203/1384 [24:13<04:03,  1.35s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1204/1384 [24:13<04:02,  1.35s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1204/1384 [24:15<04:02,  1.35s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1205/1384 [24:15<04:01,  1.35s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1205/1384 [24:16<04:01,  1.35s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1206/1384 [24:16<04:00,  1.35s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1206/1384 [24:17<04:00,  1.35s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1207/1384 [24:17<03:59,  1.35s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1207/1384 [24:19<03:59,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1208/1384 [24:19<03:56,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1208/1384 [24:20<03:56,  1.34s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1209/1384 [24:20<03:53,  1.33s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1209/1384 [24:21<03:53,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1210/1384 [24:21<03:50,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 1210/1384 [24:22<03:50,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1211/1384 [24:22<03:47,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1211/1384 [24:24<03:47,  1.31s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1212/1384 [24:24<03:44,  1.31s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1212/1384 [24:25<03:44,  1.31s/it, training_loss=0.739]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1213/1384 [24:25<03:42,  1.30s/it, training_loss=0.739]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1213/1384 [24:26<03:42,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1214/1384 [24:26<03:39,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1214/1384 [24:28<03:39,  1.29s/it, training_loss=0.437]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1215/1384 [24:28<03:36,  1.28s/it, training_loss=0.437]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1215/1384 [24:29<03:36,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1216/1384 [24:29<03:35,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1216/1384 [24:30<03:35,  1.28s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1217/1384 [24:30<03:34,  1.28s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1217/1384 [24:31<03:34,  1.28s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1218/1384 [24:31<03:33,  1.29s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1218/1384 [24:33<03:33,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1219/1384 [24:33<03:33,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1219/1384 [24:34<03:33,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1220/1384 [24:34<03:34,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1220/1384 [24:35<03:34,  1.31s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1221/1384 [24:35<03:34,  1.31s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1221/1384 [24:37<03:34,  1.31s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1222/1384 [24:37<03:33,  1.32s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1222/1384 [24:38<03:33,  1.32s/it, training_loss=0.482]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1223/1384 [24:38<03:34,  1.33s/it, training_loss=0.482]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1223/1384 [24:39<03:34,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1224/1384 [24:39<03:34,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 1224/1384 [24:41<03:34,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1225/1384 [24:41<03:33,  1.34s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1225/1384 [24:42<03:33,  1.34s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1226/1384 [24:42<03:32,  1.34s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1226/1384 [24:44<03:32,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1227/1384 [24:44<03:32,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1227/1384 [24:45<03:32,  1.35s/it, training_loss=0.620]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1228/1384 [24:45<03:31,  1.35s/it, training_loss=0.620]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1228/1384 [24:46<03:31,  1.35s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1229/1384 [24:46<03:29,  1.35s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1229/1384 [24:48<03:29,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1230/1384 [24:48<03:27,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 1230/1384 [24:49<03:27,  1.34s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1231/1384 [24:49<03:24,  1.34s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1231/1384 [24:50<03:24,  1.34s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1232/1384 [24:50<03:22,  1.33s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1232/1384 [24:52<03:22,  1.33s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1233/1384 [24:52<03:19,  1.32s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1233/1384 [24:53<03:19,  1.32s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1234/1384 [24:53<03:16,  1.31s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1234/1384 [24:54<03:16,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1235/1384 [24:54<03:14,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1235/1384 [24:55<03:14,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1236/1384 [24:55<03:12,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1236/1384 [24:57<03:12,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1237/1384 [24:57<03:11,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1237/1384 [24:58<03:11,  1.30s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1238/1384 [24:58<03:09,  1.30s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  89%|████████ | 1238/1384 [24:59<03:09,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1239/1384 [24:59<03:08,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1239/1384 [25:01<03:08,  1.30s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1240/1384 [25:01<03:08,  1.31s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1240/1384 [25:02<03:08,  1.31s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1241/1384 [25:02<03:06,  1.31s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1241/1384 [25:03<03:06,  1.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1242/1384 [25:03<03:04,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1242/1384 [25:05<03:04,  1.30s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1243/1384 [25:05<03:04,  1.31s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1243/1384 [25:06<03:04,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1244/1384 [25:06<03:03,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1244/1384 [25:07<03:03,  1.31s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1245/1384 [25:07<03:03,  1.32s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1245/1384 [25:09<03:03,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1246/1384 [25:09<03:05,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1246/1384 [25:10<03:05,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1247/1384 [25:10<03:05,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1247/1384 [25:11<03:05,  1.35s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1248/1384 [25:11<03:04,  1.36s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1248/1384 [25:13<03:04,  1.36s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1249/1384 [25:13<03:03,  1.36s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  90%|████████ | 1249/1384 [25:14<03:03,  1.36s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 1250/1384 [25:14<03:02,  1.36s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 1250/1384 [25:15<03:02,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 1251/1384 [25:15<03:00,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 1251/1384 [25:17<03:00,  1.36s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 1252/1384 [25:17<02:59,  1.36s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 1252/1384 [25:18<02:59,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1253/1384 [25:18<02:57,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1253/1384 [25:19<02:57,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1254/1384 [25:19<02:55,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1254/1384 [25:21<02:55,  1.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1255/1384 [25:21<02:53,  1.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1255/1384 [25:22<02:53,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1256/1384 [25:22<02:50,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1256/1384 [25:23<02:50,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1257/1384 [25:23<02:47,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1257/1384 [25:25<02:47,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1258/1384 [25:25<02:45,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1258/1384 [25:26<02:45,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1259/1384 [25:26<02:42,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1259/1384 [25:27<02:42,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1260/1384 [25:27<02:40,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1260/1384 [25:29<02:40,  1.30s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1261/1384 [25:29<02:38,  1.29s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1261/1384 [25:30<02:38,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1262/1384 [25:30<02:36,  1.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1262/1384 [25:31<02:36,  1.28s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1263/1384 [25:31<02:34,  1.28s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1263/1384 [25:32<02:34,  1.28s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1264/1384 [25:32<02:33,  1.28s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1264/1384 [25:34<02:33,  1.28s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1265/1384 [25:34<02:33,  1.29s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1265/1384 [25:35<02:33,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1266/1384 [25:35<02:33,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 1266/1384 [25:36<02:33,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▏| 1267/1384 [25:36<02:33,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▏| 1267/1384 [25:38<02:33,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▏| 1268/1384 [25:38<02:32,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▏| 1268/1384 [25:39<02:32,  1.32s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1269/1384 [25:39<02:33,  1.33s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1269/1384 [25:40<02:33,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1270/1384 [25:40<02:32,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1270/1384 [25:42<02:32,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1271/1384 [25:42<02:32,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1271/1384 [25:43<02:32,  1.35s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1272/1384 [25:43<02:33,  1.37s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1272/1384 [25:45<02:33,  1.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1273/1384 [25:45<02:33,  1.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1273/1384 [25:46<02:33,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1274/1384 [25:46<02:32,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1274/1384 [25:47<02:32,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1275/1384 [25:47<02:31,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1275/1384 [25:49<02:31,  1.39s/it, training_loss=0.521]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1276/1384 [25:49<02:29,  1.38s/it, training_loss=0.521]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1276/1384 [25:50<02:29,  1.38s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1277/1384 [25:50<02:26,  1.37s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1277/1384 [25:51<02:26,  1.37s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1278/1384 [25:51<02:24,  1.36s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1278/1384 [25:53<02:24,  1.36s/it, training_loss=0.462]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1279/1384 [25:53<02:21,  1.35s/it, training_loss=0.462]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1279/1384 [25:54<02:21,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1280/1384 [25:54<02:19,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 1280/1384 [25:55<02:19,  1.34s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1281/1384 [25:55<02:15,  1.31s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1281/1384 [25:57<02:15,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1282/1384 [25:57<02:12,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1282/1384 [25:58<02:12,  1.30s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1283/1384 [25:58<02:11,  1.30s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1283/1384 [25:59<02:11,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1284/1384 [25:59<02:08,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1284/1384 [26:00<02:08,  1.29s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1285/1384 [26:00<02:07,  1.29s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1285/1384 [26:02<02:07,  1.29s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1286/1384 [26:02<02:06,  1.29s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1286/1384 [26:03<02:06,  1.29s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1287/1384 [26:03<02:04,  1.29s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 1287/1384 [26:04<02:04,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1288/1384 [26:04<02:05,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1288/1384 [26:06<02:05,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1289/1384 [26:06<02:05,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1289/1384 [26:07<02:05,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1290/1384 [26:07<02:05,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1290/1384 [26:08<02:05,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1291/1384 [26:08<02:05,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1291/1384 [26:10<02:05,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1292/1384 [26:10<02:04,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1292/1384 [26:11<02:04,  1.36s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1293/1384 [26:11<02:04,  1.37s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1293/1384 [26:13<02:04,  1.37s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1294/1384 [26:13<02:04,  1.38s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 1294/1384 [26:14<02:04,  1.38s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1295/1384 [26:14<02:03,  1.38s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1295/1384 [26:15<02:03,  1.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1296/1384 [26:15<02:02,  1.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1296/1384 [26:17<02:02,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1297/1384 [26:17<02:01,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1297/1384 [26:18<02:01,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1298/1384 [26:18<01:59,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1298/1384 [26:20<01:59,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1299/1384 [26:20<01:57,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1299/1384 [26:21<01:57,  1.39s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1300/1384 [26:21<01:55,  1.38s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1300/1384 [26:22<01:55,  1.38s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1301/1384 [26:22<01:53,  1.37s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1301/1384 [26:24<01:53,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1302/1384 [26:24<01:51,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1302/1384 [26:25<01:51,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1303/1384 [26:25<01:49,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1303/1384 [26:26<01:49,  1.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1304/1384 [26:26<01:47,  1.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1304/1384 [26:28<01:47,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1305/1384 [26:28<01:46,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1305/1384 [26:29<01:46,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1306/1384 [26:29<01:46,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1306/1384 [26:30<01:46,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1307/1384 [26:30<01:44,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 1307/1384 [26:32<01:44,  1.35s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1308/1384 [26:32<01:42,  1.35s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1308/1384 [26:33<01:42,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1309/1384 [26:33<01:41,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1309/1384 [26:34<01:41,  1.35s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1310/1384 [26:34<01:40,  1.36s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1310/1384 [26:36<01:40,  1.36s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1311/1384 [26:36<01:39,  1.37s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1311/1384 [26:37<01:39,  1.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1312/1384 [26:37<01:38,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1312/1384 [26:39<01:38,  1.36s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1313/1384 [26:39<01:36,  1.36s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1313/1384 [26:40<01:36,  1.36s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1314/1384 [26:40<01:35,  1.36s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1314/1384 [26:41<01:35,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1315/1384 [26:41<01:33,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1315/1384 [26:43<01:33,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1316/1384 [26:43<01:32,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1316/1384 [26:44<01:32,  1.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1317/1384 [26:44<01:30,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1317/1384 [26:45<01:30,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1318/1384 [26:45<01:28,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1318/1384 [26:47<01:28,  1.34s/it, training_loss=0.756]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1319/1384 [26:47<01:25,  1.32s/it, training_loss=0.756]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1319/1384 [26:48<01:25,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1320/1384 [26:48<01:23,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1320/1384 [26:49<01:23,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1321/1384 [26:49<01:22,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 1321/1384 [26:50<01:22,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1322/1384 [26:50<01:20,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1322/1384 [26:52<01:20,  1.30s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1323/1384 [26:52<01:19,  1.30s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1323/1384 [26:53<01:19,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1324/1384 [26:53<01:17,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1324/1384 [26:54<01:17,  1.30s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1325/1384 [26:54<01:16,  1.30s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1325/1384 [26:56<01:16,  1.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1326/1384 [26:56<01:14,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 1326/1384 [26:57<01:14,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1327/1384 [26:57<01:13,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1327/1384 [26:58<01:13,  1.29s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1328/1384 [26:58<01:12,  1.29s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1328/1384 [26:59<01:12,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1329/1384 [26:59<01:10,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1329/1384 [27:01<01:10,  1.29s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1330/1384 [27:01<01:10,  1.31s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1330/1384 [27:02<01:10,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1331/1384 [27:02<01:09,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1331/1384 [27:03<01:09,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1332/1384 [27:03<01:08,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1332/1384 [27:05<01:08,  1.32s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1333/1384 [27:05<01:07,  1.33s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1333/1384 [27:06<01:07,  1.33s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1334/1384 [27:06<01:06,  1.33s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1334/1384 [27:07<01:06,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1335/1384 [27:07<01:05,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 1335/1384 [27:09<01:05,  1.33s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1336/1384 [27:09<01:03,  1.33s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1336/1384 [27:10<01:03,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1337/1384 [27:10<01:03,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1337/1384 [27:12<01:03,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1338/1384 [27:12<01:02,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1338/1384 [27:13<01:02,  1.35s/it, training_loss=0.469]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1339/1384 [27:13<01:01,  1.36s/it, training_loss=0.469]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1339/1384 [27:14<01:01,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1340/1384 [27:14<00:59,  1.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1340/1384 [27:16<00:59,  1.36s/it, training_loss=0.647]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1341/1384 [27:16<00:58,  1.36s/it, training_loss=0.647]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1341/1384 [27:17<00:58,  1.36s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1342/1384 [27:17<00:57,  1.36s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1342/1384 [27:18<00:57,  1.36s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1343/1384 [27:18<00:55,  1.35s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1343/1384 [27:20<00:55,  1.35s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1344/1384 [27:20<00:54,  1.35s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1344/1384 [27:21<00:54,  1.35s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1345/1384 [27:21<00:52,  1.34s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 1345/1384 [27:22<00:52,  1.34s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1346/1384 [27:22<00:50,  1.34s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1346/1384 [27:24<00:50,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1347/1384 [27:24<00:49,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1347/1384 [27:25<00:49,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1348/1384 [27:25<00:47,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1348/1384 [27:26<00:47,  1.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1349/1384 [27:26<00:46,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  97%|████████▊| 1349/1384 [27:28<00:46,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1350/1384 [27:28<00:44,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1350/1384 [27:29<00:44,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1351/1384 [27:29<00:43,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1351/1384 [27:30<00:43,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1352/1384 [27:30<00:42,  1.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1352/1384 [27:32<00:42,  1.32s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1353/1384 [27:32<00:40,  1.32s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1353/1384 [27:33<00:40,  1.32s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1354/1384 [27:33<00:39,  1.32s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1354/1384 [27:34<00:39,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1355/1384 [27:34<00:38,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1355/1384 [27:36<00:38,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1356/1384 [27:36<00:36,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1356/1384 [27:37<00:36,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1357/1384 [27:37<00:35,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1357/1384 [27:38<00:35,  1.32s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1358/1384 [27:38<00:34,  1.31s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1358/1384 [27:39<00:34,  1.31s/it, training_loss=0.662]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1359/1384 [27:39<00:32,  1.30s/it, training_loss=0.662]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1359/1384 [27:41<00:32,  1.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1360/1384 [27:41<00:31,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1360/1384 [27:42<00:31,  1.29s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1361/1384 [27:42<00:29,  1.29s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1361/1384 [27:43<00:29,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1362/1384 [27:43<00:28,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1362/1384 [27:45<00:28,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1363/1384 [27:45<00:26,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 1363/1384 [27:46<00:26,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▊| 1364/1384 [27:46<00:25,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▊| 1364/1384 [27:47<00:25,  1.28s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1365/1384 [27:47<00:24,  1.29s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1365/1384 [27:48<00:24,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1366/1384 [27:48<00:23,  1.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1366/1384 [27:50<00:23,  1.29s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1367/1384 [27:50<00:21,  1.28s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1367/1384 [27:51<00:21,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1368/1384 [27:51<00:20,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1368/1384 [27:52<00:20,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1369/1384 [27:52<00:19,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1369/1384 [27:53<00:19,  1.28s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1370/1384 [27:53<00:17,  1.28s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1370/1384 [27:55<00:17,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1371/1384 [27:55<00:16,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1371/1384 [27:56<00:16,  1.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1372/1384 [27:56<00:15,  1.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1372/1384 [27:57<00:15,  1.29s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1373/1384 [27:57<00:14,  1.28s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1373/1384 [27:59<00:14,  1.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1374/1384 [27:59<00:13,  1.31s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1374/1384 [28:00<00:13,  1.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1375/1384 [28:00<00:11,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1375/1384 [28:01<00:11,  1.33s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1376/1384 [28:01<00:10,  1.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1376/1384 [28:03<00:10,  1.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1377/1384 [28:03<00:09,  1.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 1377/1384 [28:04<00:09,  1.33s/it, training_loss=0.444]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1378/1384 [28:04<00:08,  1.34s/it, training_loss=0.444]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1378/1384 [28:05<00:08,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1379/1384 [28:05<00:06,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1379/1384 [28:07<00:06,  1.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1380/1384 [28:07<00:05,  1.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1380/1384 [28:08<00:05,  1.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1381/1384 [28:08<00:04,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1381/1384 [28:10<00:04,  1.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1382/1384 [28:10<00:02,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1382/1384 [28:11<00:02,  1.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1383/1384 [28:11<00:01,  1.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 1383/1384 [28:12<00:01,  1.38s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2: 100%|█████████| 1384/1384 [28:12<00:00,  1.30s/it, training_loss=0.004]\u001b[A\n",
      " 50%|█████████████████████▌                     | 1/2 [56:57<28:43, 1723.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.2801739092586687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 2/2 [57:52<00:00, 1736.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.47523442352884354\n",
      "F1 Score (Weighted): 0.8851760033703517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "seed_test = 2022\n",
    "random.seed(seed_test)\n",
    "np.random.seed(seed_test)\n",
    "torch.manual_seed(seed_test)\n",
    "torch.cuda.manual_seed_all(seed_test)\n",
    " \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    " \n",
    "for epoch in tqdm(range(1, epochs+1)): \n",
    "    model.train()  \n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()    \n",
    "        batch = tuple(b.to(device) for b in batch)     \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    " \n",
    "        outputs = model(**inputs)  \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()     \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})          \n",
    "    torch.save(model.state_dict(), f'finetuned_finBERT_epoch_{epoch}.model')\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3316b8-b288-4d4a-b11d-03ff7b228539",
   "metadata": {},
   "source": [
    "In this scenario, we observe a decrease in the training loss from the first to the second epoch, suggesting that the model continues to learn from the training data. However, there is a slight increase in the validation loss between the first and second epochs. This discrepancy between the training and validation losses indicates that the model may be overfitting to the training data, as it performs well on the training data but fails to generalize effectively to the validation data.\n",
    "\n",
    "Therefore, based on the trends in the losses, it appears that the model may be experiencing overfitting after the second epoch. To address overfitting, strategies such as early stopping or regularization techniques can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e230d714-e982-4d4c-b096-1d4d17836b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: positive\n",
      "Accuracy: 466/511\n",
      "\n",
      "Label: negative\n",
      "Accuracy: 566/612\n",
      "\n",
      "Label: indecisive\n",
      "Accuracy: 52/98\n",
      "\n",
      "accuracy:  0.8877968877968878\n"
     ]
    }
   ],
   "source": [
    "# stop at epoch 1\n",
    "sentiment_dict = {'positive': 0, 'negative': 1, 'indecisive': 2}\n",
    "sentiment_dict_inverse = dict(zip(sentiment_dict.values(), sentiment_dict.keys()))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\",\n",
    "                                                          num_labels=len(sentiment_dict),\n",
    "                                                          output_attentions=False,\n",
    "                                                          output_hidden_states=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./finetuned_finBERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2edd1e",
   "metadata": {},
   "source": [
    "Predict sentiments of the new titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0679055-5939-49bc-9cec-c557cb216b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 587/587 [00:00<00:00, 2814.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Max sequence length 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_title_df = pd.read_csv('new_titles.csv')\n",
    "\n",
    "headlines_sequence_lengths_pred = get_headlines_len(new_title_df)\n",
    "show_headline_distribution(headlines_sequence_lengths_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e1bb677-70c0-4523-b3d7-ae88506dd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "encoded_data_pred = finbert_tokenizer.batch_encode_plus(\n",
    "    new_title_df.Title.values, \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length',\n",
    "    max_length=41, \n",
    "    truncation=True \n",
    ")\n",
    "\n",
    "\n",
    "input_ids_pred = encoded_data_pred['input_ids']\n",
    "attention_masks_pred = encoded_data_pred['attention_mask']\n",
    "dataset_pred = TensorDataset(input_ids_pred, attention_masks_pred)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {\n",
    "        'input_ids': encoded_data_pred['input_ids'].to(device),\n",
    "        'attention_mask': encoded_data_pred['attention_mask'].to(device)\n",
    "    }\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "sentiment_dict_inverse = dict(zip(sentiment_dict.values(), sentiment_dict.keys()))\n",
    "for title, label_id in zip(new_title_df.Title.values, predicted_labels):\n",
    "    sentiment = sentiment_dict_inverse[label_id]\n",
    "    new_title_df['Sentiment'] = new_title_df['Sentiment'].astype(str)\n",
    "    new_title_df.loc[new_title_df['Title'] == title, 'Sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f710da9-a39b-4832-b1d2-4f865a82e27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04 08:00:00+00:00</td>\n",
       "      <td>Wall St. Extends '09 Rally into New Year - CBS...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 08:00:00+00:00</td>\n",
       "      <td>Warren Buffett weighs into Kraft's battle for ...</td>\n",
       "      <td>indecisive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-07 08:00:00+00:00</td>\n",
       "      <td>Fear of the dragon - The Economist</td>\n",
       "      <td>indecisive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-10 08:00:00+00:00</td>\n",
       "      <td>Fundamental Opportunities in Emerging Markets ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-11 08:00:00+00:00</td>\n",
       "      <td>How News Happens - Pew Research Center</td>\n",
       "      <td>indecisive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2010-01-04 08:00:00+00:00   \n",
       "1  2010-01-05 08:00:00+00:00   \n",
       "2  2010-01-07 08:00:00+00:00   \n",
       "3  2010-01-10 08:00:00+00:00   \n",
       "4  2010-01-11 08:00:00+00:00   \n",
       "\n",
       "                                               Title   Sentiment  \n",
       "0  Wall St. Extends '09 Rally into New Year - CBS...    positive  \n",
       "1  Warren Buffett weighs into Kraft's battle for ...  indecisive  \n",
       "2                 Fear of the dragon - The Economist  indecisive  \n",
       "3  Fundamental Opportunities in Emerging Markets ...    positive  \n",
       "4             How News Happens - Pew Research Center  indecisive  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2328fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title_df.to_excel('SA_Finber_for_new_titles.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
